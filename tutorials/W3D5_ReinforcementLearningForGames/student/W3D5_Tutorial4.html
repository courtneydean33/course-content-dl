
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Bonus Tutorial: Planning with Monte Carlo — Neuromatch Academy: Deep Learning</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-dl-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D5_BonusLecture.html" rel="next" title="Bonus Lecture: Amita Kapoor"/>
<link href="W3D5_Tutorial3.html" rel="prev" title="Tutorial 3: Policy-based Player"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/DeepLearning.html">
   Prerequisites and preparatory materials for NMA Deep Learning
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Basics Module
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">
     Bonus Lecture: Yoshua Bengio
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Fine Tuning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Optimization/chapter_title.html">
   Optimization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Optimization/student/W1D5_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_Regularization/chapter_title.html">
   Regularization (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/FineTuning.html">
   Deep Learning: The Basics and Fine Tuning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/chapter_title.html">
   Convnets And Dl Thinking (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">
     Tutorial 2: Deep Learning Thinking 1: Cost Functions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">
     Bonus Lecture: Kyunghyun Cho
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial2.html">
     Bonus Tutorial: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_GenerativeModels/chapter_title.html">
   Generative Models (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial2.html">
     Tutorial 2: Introduction to GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial4.html">
     Bonus Tutorial: Deploying Neural Networks on the Web
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_BonusLecture.html">
     Bonus Lecture: Geoffrey Hinton
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
   Time Series And Natural Language Processing (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial1.html">
     Tutorial 1: Introduction to processing time series
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.html">
     Tutorial 2: Time series for Language
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial3.html">
     Bonus Tutorial: Multilingual Embeddings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/student/W3D1_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_DlThinking2/chapter_title.html">
   Dl Thinking2 (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_DlThinking2/student/W3D2_Tutorial1.html">
     Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/NaturalLanguageProcessing.html">
   Deep Learning: Convnets and NLP
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">
     Bonus Lecture: Melanie Mitchell
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial5.html">
     Bonus Tutorial: Function approximation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">
     Bonus Lecture: Chealsea Finn
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Reinforcement Learning For Games (W3D5)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W3D5_Tutorial1.html">
     Tutorial 1: Game Set-Up and Random Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D5_Tutorial2.html">
     Tutorial 2: Value-Based Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D5_Tutorial3.html">
     Tutorial 3: Policy-based Player
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Bonus Tutorial: Planning with Monte Carlo
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D5_BonusLecture.html">
     Bonus Lecture: Amita Kapoor
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/ReinforcementLearning.html">
   Deep Learning: Reinforcement Learning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial4.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial4.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Bonus Tutorial: Planning with Monte Carlo
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-the-modules">
     Download the modules
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions-from-previous-tutorials">
     Helper functions from previous tutorials
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-plan-using-monte-carlo-rollouts">
   Section 1: Plan using Monte Carlo Rollouts
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-play-using-monte-carlo-rollouts">
     Video 1: Play using Monte-Carlo rollouts
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-montecarlo">
     Coding Exercise 1:
     <code class="docutils literal notranslate">
<span class="pre">
       MonteCarlo
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-use-monte-carlo-simulations-to-play-games">
   Section 2: Use Monte Carlo simulations to play games
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-play-with-planning">
     Video 2: Play with planning
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-monte-carlo-simulations">
     Coding Exercise 2: Monte-Carlo simulations
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#monte-carlo-player-against-value-based-player">
       Monte-Carlo player against Value-based player
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#monte-carlo-player-against-policy-based-player">
       Monte-Carlo player against Policy-based player
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-outro">
     Video 3: Outro
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-plan-using-monte-carlo-tree-search-mcts">
   Bonus 1: Plan using Monte Carlo Tree Search (MCTS)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-plan-with-mcts">
     Video 4: Plan with MCTS
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-1-mcts-planner">
     Bonus Coding Exercise 1: MCTS planner
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-use-mcts-to-play-games">
   Bonus 2: Use MCTS to play games
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-play-with-mcts">
     Video 5: Play with MCTS
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-2-agent-that-uses-an-mcts-planner">
     Bonus Coding Exercise 2: Agent that uses an MCTS planner
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#mcts-player-against-value-based-player">
       MCTS player against Value-based player
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#mcts-player-against-policy-based-player">
       MCTS player against Policy-based player
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Bonus Tutorial: Planning with Monte Carlo</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Bonus Tutorial: Planning with Monte Carlo
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-the-modules">
     Download the modules
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions-from-previous-tutorials">
     Helper functions from previous tutorials
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-plan-using-monte-carlo-rollouts">
   Section 1: Plan using Monte Carlo Rollouts
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-play-using-monte-carlo-rollouts">
     Video 1: Play using Monte-Carlo rollouts
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-montecarlo">
     Coding Exercise 1:
     <code class="docutils literal notranslate">
<span class="pre">
       MonteCarlo
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-use-monte-carlo-simulations-to-play-games">
   Section 2: Use Monte Carlo simulations to play games
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-play-with-planning">
     Video 2: Play with planning
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-monte-carlo-simulations">
     Coding Exercise 2: Monte-Carlo simulations
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#monte-carlo-player-against-value-based-player">
       Monte-Carlo player against Value-based player
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#monte-carlo-player-against-policy-based-player">
       Monte-Carlo player against Policy-based player
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-outro">
     Video 3: Outro
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-plan-using-monte-carlo-tree-search-mcts">
   Bonus 1: Plan using Monte Carlo Tree Search (MCTS)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-plan-with-mcts">
     Video 4: Plan with MCTS
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-1-mcts-planner">
     Bonus Coding Exercise 1: MCTS planner
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-use-mcts-to-play-games">
   Bonus 2: Use MCTS to play games
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-play-with-mcts">
     Video 5: Play with MCTS
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-2-agent-that-uses-an-mcts-planner">
     Bonus Coding Exercise 2: Agent that uses an MCTS planner
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#mcts-player-against-value-based-player">
       MCTS player against Value-based player
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#mcts-player-against-policy-based-player">
       MCTS player against Policy-based player
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial4.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial4.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="bonus-tutorial-planning-with-monte-carlo">
<h1>Bonus Tutorial: Planning with Monte Carlo<a class="headerlink" href="#bonus-tutorial-planning-with-monte-carlo" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 5: Reinforcement Learning for Games</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Mandana Samiei, Raymond Chua, Tim Lilicrap, Blake Richards</p>
<p><strong>Content reviewers:</strong> Arush Tagade, Lily Cheng, Melvin Selim Atay, Kelson Shilling-Scrivo</p>
<p><strong>Content editors:</strong> Melvin Selim Atay, Spiros Chavlis, Gunnar Blohm</p>
<p><strong>Production editors:</strong> Namrata Bafna, Gagana B, Spiros Chavlis</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, you will learn how to implement a game loop and improve the performance of a random player.</p>
<p>The specific objectives for this tutorial:</p>
<ul class="simple">
<li><p>Understand the format of two-players games</p></li>
<li><p>Learn about value network and policy network</p></li>
</ul>
<p>In the Bonus sections you will learn about Monte Carlo Tree Search (MCTS) and compare its performance to policy-based and value-based players.</p>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/h4utj/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
<p>These are the slides for the videos in the tutorial. If you want to locally download the slides, click <a class="reference external" href="https://osf.io/h4utj/download">here</a>.</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>coloredlogs<span class="w"> </span>--quiet

<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/NeuromatchAcademy/evaltools<span class="w"> </span>--quiet
<span class="kn">from</span> <span class="nn">evaltools.airtable</span> <span class="kn">import</span> <span class="n">AirtableForm</span>

<span class="c1"># generate airtable form</span>
<span class="n">atform</span> <span class="o">=</span> <span class="n">AirtableForm</span><span class="p">(</span><span class="s1">'appn7VdPRseSoMXEG'</span><span class="p">,</span> <span class="s1">'W3D5_T4'</span><span class="p">,</span> <span class="s1">'95651a47-083f-406e-a6cd-8af24670c5bc'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">coloredlogs</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<span class="n">coloredlogs</span><span class="o">.</span><span class="n">install</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="s1">'INFO'</span><span class="p">)</span>  <span class="c1"># Change this to DEBUG to see more info.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># For DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Function that controls randomness. NumPy and random modules must be imported.</span>

<span class="sd">  Args:</span>
<span class="sd">    seed : Integer</span>
<span class="sd">      A non-negative integer that defines the random state. Default is `None`.</span>
<span class="sd">    seed_torch : Boolean</span>
<span class="sd">      If `True` sets the random seed for pytorch tensors, so pytorch module</span>
<span class="sd">      must be imported. Default is `True`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  DataLoader will reseed workers following randomness in</span>
<span class="sd">  multi-process data loading algorithm.</span>

<span class="sd">  Args:</span>
<span class="sd">    worker_id: integer</span>
<span class="sd">      ID of subprocess to seed. 0 means that</span>
<span class="sd">      the data will be loaded in the main process</span>
<span class="sd">      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># Inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Set the device. CUDA if available, CPU otherwise</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="download-the-modules">
<h2>Download the modules<a class="headerlink" href="#download-the-modules" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download the modules</span>

<span class="c1"># @markdown Run this cell!</span>

<span class="c1"># @markdown Download from OSF. The original repo is https://github.com/raymondchua/nma_rl_games.git</span>

<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">io</span><span class="o">,</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">shutil</span><span class="o">,</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="kn">import</span> <span class="n">urlopen</span>

<span class="c1"># download from github repo directly</span>
<span class="c1">#!git clone git://github.com/raymondchua/nma_rl_games.git --quiet</span>
<span class="n">REPO_PATH</span> <span class="o">=</span> <span class="s1">'nma_rl_games'</span>

<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">REPO_PATH</span><span class="p">):</span>
  <span class="n">download_string</span> <span class="o">=</span> <span class="s2">"Redownloading"</span>
  <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">REPO_PATH</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">download_string</span> <span class="o">=</span> <span class="s2">"Downloading"</span>

<span class="n">zipurl</span> <span class="o">=</span> <span class="s1">'https://osf.io/kf4p9/download'</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">download_string</span><span class="si">}</span><span class="s2"> and unzipping the file... Please wait."</span><span class="p">)</span>
<span class="k">with</span> <span class="n">urlopen</span><span class="p">(</span><span class="n">zipurl</span><span class="p">)</span> <span class="k">as</span> <span class="n">zipresp</span><span class="p">:</span>
  <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">zipresp</span><span class="o">.</span><span class="n">read</span><span class="p">()))</span> <span class="k">as</span> <span class="n">zfile</span><span class="p">:</span>
    <span class="n">zfile</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Download completed."</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Add the </span><span class="si">{</span><span class="n">REPO_PATH</span><span class="si">}</span><span class="s2"> in the path and import the modules."</span><span class="p">)</span>
<span class="c1"># add the repo in the path</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">'nma_rl_games/alpha-zero'</span><span class="p">)</span>

<span class="c1"># @markdown Import modules designed for use in this notebook</span>
<span class="kn">import</span> <span class="nn">Arena</span>

<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">Game</span> <span class="kn">import</span> <span class="n">Game</span>
<span class="kn">from</span> <span class="nn">MCTS</span> <span class="kn">import</span> <span class="n">MCTS</span>
<span class="kn">from</span> <span class="nn">NeuralNet</span> <span class="kn">import</span> <span class="n">NeuralNet</span>

<span class="c1"># from othello.OthelloPlayers import *</span>
<span class="kn">from</span> <span class="nn">othello.OthelloLogic</span> <span class="kn">import</span> <span class="n">Board</span>
<span class="c1"># from othello.OthelloGame import OthelloGame</span>
<span class="kn">from</span> <span class="nn">othello.pytorch.NNet</span> <span class="kn">import</span> <span class="n">NNetWrapper</span> <span class="k">as</span> <span class="n">NNet</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Redownloading and unzipping the file... Please wait.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Download completed.
Add the nma_rl_games in the path and import the modules.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions-from-previous-tutorials">
<h2>Helper functions from previous tutorials<a class="headerlink" href="#helper-functions-from-previous-tutorials" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions from previous tutorials</span>
<span class="k">class</span> <span class="nc">OthelloGame</span><span class="p">(</span><span class="n">Game</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Instantiate Othello Game</span>
<span class="sd">  """</span>
  <span class="n">square_content</span> <span class="o">=</span> <span class="p">{</span>
      <span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="s2">"X"</span><span class="p">,</span>
      <span class="o">+</span><span class="mi">0</span><span class="p">:</span> <span class="s2">"-"</span><span class="p">,</span>
      <span class="o">+</span><span class="mi">1</span><span class="p">:</span> <span class="s2">"O"</span>
      <span class="p">}</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">getSquarePiece</span><span class="p">(</span><span class="n">piece</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">OthelloGame</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">piece</span><span class="p">]</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span>

  <span class="k">def</span> <span class="nf">getInitBoard</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Return initial board (numpy board)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">pieces</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getBoardSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># (a,b) tuple</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getActionSize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Return number of actions, n is the board size and +1 is for no-op action</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span>

  <span class="k">def</span> <span class="nf">getCanonicalForm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="c1"># Return state if player==1, else return -state if player==-1</span>
    <span class="k">return</span> <span class="n">player</span><span class="o">*</span><span class="n">board</span>

  <span class="k">def</span> <span class="nf">stringRepresentation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">board</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">stringRepresentationReadable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
    <span class="n">board_s</span> <span class="o">=</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">square</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">board</span> <span class="k">for</span> <span class="n">square</span> <span class="ow">in</span> <span class="n">row</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">board_s</span>

  <span class="k">def</span> <span class="nf">getScore</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">b</span><span class="o">.</span><span class="n">countDiff</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">display</span><span class="p">(</span><span class="n">board</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"   "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">"|"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>    <span class="c1"># Print the row</span>
      <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">piece</span> <span class="o">=</span> <span class="n">board</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span>    <span class="c1"># Get the piece to print</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">piece</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"|"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">displayValidMoves</span><span class="p">(</span><span class="n">moves</span><span class="p">):</span>
      <span class="c1"># Display possible moves</span>
      <span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">moves</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">board</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="n">n</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"  "</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"possible moves"</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"   "</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">"|"</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">""</span><span class="p">)</span>    <span class="c1"># Print the row</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
          <span class="n">piece</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">y</span><span class="p">][</span><span class="n">x</span><span class="p">]</span>    <span class="c1"># Get the piece to print</span>
          <span class="nb">print</span><span class="p">(</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">square_content</span><span class="p">[</span><span class="n">piece</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s2">" "</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"|"</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"-----------------------"</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getNextState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Helper function to make valid move</span>
<span class="sd">    If player takes action on board, return next (board,player)</span>
<span class="sd">    and action must be a valid move</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      player: Integer</span>
<span class="sd">        ID of current player</span>
<span class="sd">      action: np.ndarray</span>
<span class="sd">        Space of actions</span>

<span class="sd">    Returns:</span>
<span class="sd">      (board,player) tuple signifying next state</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="o">-</span><span class="n">player</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="n">move</span> <span class="o">=</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">action</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">),</span> <span class="n">action</span><span class="o">%</span><span class="k">self</span>.n)
    <span class="n">b</span><span class="o">.</span><span class="n">execute_move</span><span class="p">(</span><span class="n">move</span><span class="p">,</span> <span class="n">player</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">pieces</span><span class="p">,</span> <span class="o">-</span><span class="n">player</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getValidMoves</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Helper function to make valid move</span>
<span class="sd">    If player takes action on board, return next (board,player)</span>
<span class="sd">    and action must be a valid move</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      player: Integer</span>
<span class="sd">        ID of current player</span>
<span class="sd">      action: np.ndarray</span>
<span class="sd">        Space of action</span>

<span class="sd">    Returns:</span>
<span class="sd">      valids: np.ndarray</span>
<span class="sd">        Returns a fixed size binary vector</span>
<span class="sd">    """</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="n">legalMoves</span> <span class="o">=</span>  <span class="n">b</span><span class="o">.</span><span class="n">get_legal_moves</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">legalMoves</span><span class="p">)</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
      <span class="n">valids</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valids</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">legalMoves</span><span class="p">:</span>
      <span class="n">valids</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">]</span><span class="o">=</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valids</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getGameEnded</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Helper function to signify if game has ended</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      player: Integer</span>
<span class="sd">        ID of current player</span>

<span class="sd">    Returns:</span>
<span class="sd">      0 if not ended, 1 if player 1 won, -1 if player 1 lost</span>
<span class="sd">    """</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">Board</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">b</span><span class="o">.</span><span class="n">pieces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">has_legal_moves</span><span class="p">(</span><span class="n">player</span><span class="p">):</span>
      <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">has_legal_moves</span><span class="p">(</span><span class="o">-</span><span class="n">player</span><span class="p">):</span>
      <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">countDiff</span><span class="p">(</span><span class="n">player</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">def</span> <span class="nf">getSymmetries</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">,</span> <span class="n">pi</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Get mirror/rotational configurations of board</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>
<span class="sd">      pi: np.ndarray</span>
<span class="sd">        Dimension of board</span>

<span class="sd">    Returns:</span>
<span class="sd">      l: list</span>
<span class="sd">        90 degree of board, 90 degree of pi_board</span>
<span class="sd">    """</span>
    <span class="k">assert</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 1 for pass</span>
    <span class="n">pi_board</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pi</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
        <span class="n">newB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">newPi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">pi_board</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">j</span><span class="p">:</span>
          <span class="n">newB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">newB</span><span class="p">)</span>
          <span class="n">newPi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">newPi</span><span class="p">)</span>
        <span class="n">l</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">newB</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">newPi</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">pi</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])]</span>
    <span class="k">return</span> <span class="n">l</span>

<span class="k">class</span> <span class="nc">RandomPlayer</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Simulates Random Player</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Simulates game play</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      a: int</span>
<span class="sd">        Randomly chosen move</span>
<span class="sd">    """</span>

    <span class="c1"># Compute the valid moves using getValidMoves()</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Compute the probability of each move being played (random player means this should</span>
    <span class="c1"># be uniform for valid moves, 0 for others)</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">valids</span><span class="o">/</span><span class="n">valids</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># Pick an action based on the probabilities (hint: np.choice is useful)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="n">prob</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span>

<span class="k">class</span> <span class="nc">OthelloNNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Instantiate Othello Neural Net with following configuration</span>
<span class="sd">  nn.Conv2d(1, args.num_channels, 3, stride=1, padding=1) # Convolutional Layer 1</span>
<span class="sd">  nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1, padding=1) # Convolutional Layer 2</span>
<span class="sd">  nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1) # Convolutional Layer 3</span>
<span class="sd">  nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1) # Convolutional Layer 4</span>
<span class="sd">  nn.BatchNorm2d(args.num_channels) X 4</span>
<span class="sd">  nn.Linear(args.num_channels * (self.board_x - 4) * (self.board_y - 4), 1024) # Fully-connected Layer 1</span>
<span class="sd">  nn.Linear(1024, 512) # Fully-connected Layer 2</span>
<span class="sd">  nn.Linear(512, self.action_size) # Fully-connected Layer 3</span>
<span class="sd">  nn.Linear(512, 1) # Fully-connected Layer 4</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise game parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      args: dictionary</span>
<span class="sd">        Instantiates number of iterations and episodes, controls temperature threshold, queue length,</span>
<span class="sd">        arena, checkpointing, and neural network parameters:</span>
<span class="sd">        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,</span>
<span class="sd">        num_channels: 512</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getBoardSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">OthelloNNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bn4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_x</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">-</span> <span class="mi">4</span><span class="p">),</span> <span class="mi">1024</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc_bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc_bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Controls forward pass of OthelloNNet</span>

<span class="sd">    Args:</span>
<span class="sd">      s: np.ndarray</span>
<span class="sd">        Array of size (batch_size x board_x x board_y)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Probability distribution over actions at the current state and the value of the current state.</span>
<span class="sd">    """</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span><span class="p">)</span>                <span class="c1"># batch_size x 1 x board_x x board_y</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x board_x x board_y</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x board_x x board_y</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x (board_x-2) x (board_y-2)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn4</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>                          <span class="c1"># batch_size x num_channels x (board_x-4) x (board_y-4)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_x</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">-</span> <span class="mi">4</span><span class="p">))</span> <span class="c1"># reshaping of</span>

    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_bn1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">s</span><span class="p">))),</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>  <span class="c1"># batch_size x 1024</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc_bn2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">s</span><span class="p">))),</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>  <span class="c1"># batch_size x 512</span>

    <span class="n">pi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># batch_size x action_size</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc4</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>   <span class="c1"># batch_size x 1</span>

    <span class="c1"># Returns probability distribution over actions at the current state and the value of the current state.</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">pi</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ValueBasedPlayer</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Simulate Value Based Player</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">vnet</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise value based player parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      vnet: Value Network instance</span>
<span class="sd">        Instance of the Value Network class above;</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vnet</span> <span class="o">=</span> <span class="n">vnet</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Simulate game play</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      candidates: List</span>
<span class="sd">        Collection of tuples describing action and values of future predicted states</span>
<span class="sd">    """</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">max_num_actions</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">va</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">valids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">va_list</span> <span class="o">=</span> <span class="n">va</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">va_list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">va_list</span><span class="p">:</span>
      <span class="c1"># Return next board state using getNextState() function</span>
      <span class="n">nextBoard</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getNextState</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
      <span class="c1"># Predict the value of next state using value network</span>
      <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">nextBoard</span><span class="p">)</span>
      <span class="c1"># Add the value and the action as a tuple to the candidate lists, note that you might need to change the sign of the value based on the player</span>
      <span class="n">candidates</span> <span class="o">+=</span> <span class="p">[(</span><span class="o">-</span><span class="n">value</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span>

      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">candidates</span><span class="p">)</span> <span class="o">==</span> <span class="n">max_num_actions</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Sort by the values</span>
    <span class="n">candidates</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

    <span class="c1"># Return action associated with highest value</span>
    <span class="k">return</span> <span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">ValueNetwork</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Initiates the Value Network</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise network parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">OthelloNNet</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getBoardSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">games</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Function to train value network</span>

<span class="sd">    Args:</span>
<span class="sd">      games: list</span>
<span class="sd">        List of examples with each example is of form (board, pi, v)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">examples</span> <span class="ow">in</span> <span class="n">games</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'EPOCH ::: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">v_losses</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># To store the losses per epoch</span>
        <span class="n">batch_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># len(examples)=200, batch-size=64, batch_count=3</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch_count</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Training Value Network'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
          <span class="n">sample_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># Read the ground truth information from MCTS simulation using the loaded examples</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">pis</span><span class="p">,</span> <span class="n">vs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample_ids</span><span class="p">]))</span>  <span class="c1"># Length of boards, pis, vis = 64</span>
          <span class="n">boards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
          <span class="n">target_vs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vs</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>

          <span class="c1"># Predict</span>
          <span class="c1"># To run on GPU if available</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">target_vs</span> <span class="o">=</span> <span class="n">boards</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target_vs</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

          <span class="c1"># Compute output</span>
          <span class="n">_</span><span class="p">,</span> <span class="n">out_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span>
          <span class="n">l_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_v</span><span class="p">(</span><span class="n">target_vs</span><span class="p">,</span> <span class="n">out_v</span><span class="p">)</span>  <span class="c1"># Total loss</span>

          <span class="c1"># Record loss</span>
          <span class="n">v_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l_v</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
          <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Loss_v</span><span class="o">=</span><span class="n">l_v</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

          <span class="c1"># Compute gradient and do SGD step</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="n">l_v</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Function to perform prediction</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      v: OthelloNet instance</span>
<span class="sd">        Data of the OthelloNet class instance above;</span>
<span class="sd">    """</span>
    <span class="c1"># Timing</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Preparing input</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">board</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">loss_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculates Mean squared error</span>

<span class="sd">    Args:</span>
<span class="sd">      targets: np.ndarray</span>
<span class="sd">        Ground Truth variables corresponding to input</span>
<span class="sd">      outputs: np.ndarray</span>
<span class="sd">        Predictions of Network</span>

<span class="sd">    Returns:</span>
<span class="sd">      MSE Loss calculated as: square of the difference between your model's predictions</span>
<span class="sd">      and the ground truth and average across the whole dataset</span>
<span class="sd">    """</span>
    <span class="c1"># Mean squared error (MSE)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">targets</span> <span class="o">-</span> <span class="n">outputs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Code Checkpointing</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory does not exist! Making directory </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">folder</span><span class="p">))</span>
      <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory exists! "</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'state_dict'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),},</span> <span class="n">filepath</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved! "</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Load code checkpoint</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="c1"># https://github.com/pytorch/examples/blob/master/imagenet/main.py#L98</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
      <span class="k">raise</span> <span class="p">(</span><span class="s2">"No model in path </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>

    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">])</span>

<span class="k">class</span> <span class="nc">PolicyBasedPlayer</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Simulate Policy Based Player</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">,</span> <span class="n">greedy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize Policy based player parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      pnet: Policy Network instance</span>
<span class="sd">        Instance of the Policy Network class above</span>
<span class="sd">      greedy: Boolean</span>
<span class="sd">        If true, implement greedy approach</span>
<span class="sd">        Else, implement random sample policy based player</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pnet</span> <span class="o">=</span> <span class="n">pnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">greedy</span> <span class="o">=</span> <span class="n">greedy</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Simulate game play</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      a: np.ndarray</span>
<span class="sd">        If greedy, implement greedy policy player</span>
<span class="sd">        Else, implement random sample policy based player</span>
<span class="sd">    """</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">action_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="n">vap</span> <span class="o">=</span> <span class="n">action_probs</span><span class="o">*</span><span class="n">valids</span>  <span class="c1"># Masking invalid moves</span>
    <span class="n">sum_vap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vap</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sum_vap</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">vap</span> <span class="o">/=</span> <span class="n">sum_vap</span>  <span class="c1"># Renormalize</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If all valid moves were masked we make all valid moves equally probable</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"All valid moves were masked, doing a workaround."</span><span class="p">)</span>
      <span class="n">vap</span> <span class="o">=</span> <span class="n">vap</span> <span class="o">+</span> <span class="n">valids</span>
      <span class="n">vap</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vap</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greedy</span><span class="p">:</span>
      <span class="c1"># Greedy policy player</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">vap</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">vap</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Sample-based policy player</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">(),</span> <span class="n">p</span><span class="o">=</span><span class="n">vap</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">a</span>
<span class="k">class</span> <span class="nc">PolicyNetwork</span><span class="p">(</span><span class="n">NeuralNet</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Initialise Policy Network</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initalise policy network paramaters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">OthelloNNet</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getBoardSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">games</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Function for Policy Network Training</span>

<span class="sd">    Args:</span>
<span class="sd">      games: list</span>
<span class="sd">        List of examples where each example is of form (board, pi, v)</span>

<span class="sd">    Return:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">examples</span> <span class="ow">in</span> <span class="n">games</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'EPOCH ::: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">pi_losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">batch_count</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>

        <span class="n">t</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">batch_count</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Training Policy Network'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
          <span class="n">sample_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">examples</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">pis</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">examples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sample_ids</span><span class="p">]))</span>
          <span class="n">boards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
          <span class="n">target_pis</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pis</span><span class="p">))</span>

          <span class="c1"># Predict</span>
          <span class="n">boards</span><span class="p">,</span> <span class="n">target_pis</span> <span class="o">=</span> <span class="n">boards</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">target_pis</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

          <span class="c1"># Compute output</span>
          <span class="n">out_pi</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">boards</span><span class="p">)</span>
          <span class="n">l_pi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_pi</span><span class="p">(</span><span class="n">target_pis</span><span class="p">,</span> <span class="n">out_pi</span><span class="p">)</span>

          <span class="c1"># Record loss</span>
          <span class="n">pi_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l_pi</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
          <span class="n">t</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">Loss_pi</span><span class="o">=</span><span class="n">l_pi</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

          <span class="c1"># Compute gradient and do SGD step</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
          <span class="n">l_pi</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
          <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">board</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Function to perform prediction</span>

<span class="sd">    Args:</span>
<span class="sd">      board: np.ndarray</span>
<span class="sd">        Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      Data from the OthelloNet class instance above;</span>
<span class="sd">    """</span>
    <span class="c1"># Timing</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Preparing input</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">board</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">board</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">board_y</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">pi</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">loss_pi</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Calculates Negative Log Likelihood(NLL) of Targets</span>

<span class="sd">    Args:</span>
<span class="sd">      targets: np.ndarray</span>
<span class="sd">        Ground Truth variables corresponding to input</span>
<span class="sd">      outputs: np.ndarray</span>
<span class="sd">        Predictions of Network</span>

<span class="sd">    Returns:</span>
<span class="sd">      Negative Log Likelihood calculated as: When training a model, we aspire to find the minima of a</span>
<span class="sd">      loss function given a set of parameters (in a neural network, these are the weights and biases).</span>
<span class="sd">      Sum the loss function to all the correct classes. So, whenever the network assigns high confidence at</span>
<span class="sd">      the correct class, the NLL is low, but when the network assigns low confidence at the correct class,</span>
<span class="sd">      the NLL is high.</span>
<span class="sd">    """</span>
    <span class="c1">## To implement the loss function, please compute and return the negative log likelihood of targets.</span>
    <span class="c1">## For more information, here is a reference that connects the expression to the neg-log-prob: https://gombru.github.io/2018/05/23/cross_entropy_loss/</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">targets</span> <span class="o">*</span> <span class="n">outputs</span><span class="p">)</span> <span class="o">/</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Code Checkpointing</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory does not exist! Making directory </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">folder</span><span class="p">))</span>
      <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"Checkpoint Directory exists! "</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'state_dict'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),},</span> <span class="n">filepath</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved! "</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s1">'checkpoint'</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint.pth.tar'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Load code checkpoint</span>

<span class="sd">    Args:</span>
<span class="sd">      folder: string</span>
<span class="sd">        Path specifying training examples</span>
<span class="sd">      filename: string</span>
<span class="sd">        File name of training examples</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="c1"># https://github.com/pytorch/examples/blob/master/imagenet/main.py#L98</span>
    <span class="n">filepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
      <span class="k">raise</span> <span class="p">(</span><span class="s2">"No model in path </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>

    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'state_dict'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>The hyperparameters used throughout the notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">args</span> <span class="o">=</span> <span class="n">dotdict</span><span class="p">({</span>
    <span class="s1">'numIters'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># In training, number of iterations = 1000 and num of episodes = 100</span>
    <span class="s1">'numEps'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1"># Number of complete self-play games to simulate during a new iteration.</span>
    <span class="s1">'tempThreshold'</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>  <span class="c1"># To control exploration and exploitation</span>
    <span class="s1">'updateThreshold'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>  <span class="c1"># During arena playoff, new neural net will be accepted if threshold or more of games are won.</span>
    <span class="s1">'maxlenOfQueue'</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>  <span class="c1"># Number of game examples to train the neural networks.</span>
    <span class="s1">'numMCTSSims'</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span>  <span class="c1"># Number of games moves for MCTS to simulate.</span>
    <span class="s1">'arenaCompare'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>  <span class="c1"># Number of games to play during arena play to determine if new net will be accepted.</span>
    <span class="s1">'cpuct'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'maxDepth'</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># Maximum number of rollouts</span>
    <span class="s1">'numMCsims'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>  <span class="c1"># Number of monte carlo simulations</span>
    <span class="s1">'mc_topk'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>  <span class="c1"># Top k actions for monte carlo rollout</span>

    <span class="s1">'checkpoint'</span><span class="p">:</span> <span class="s1">'./temp/'</span><span class="p">,</span>
    <span class="s1">'load_model'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">'load_folder_file'</span><span class="p">:</span> <span class="p">(</span><span class="s1">'/dev/models/8x100x50'</span><span class="p">,</span><span class="s1">'best.pth.tar'</span><span class="p">),</span>
    <span class="s1">'numItersForTrainExamplesHistory'</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>

    <span class="c1"># Define neural network arguments</span>
    <span class="s1">'lr'</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>  <span class="c1"># learning rate</span>
    <span class="s1">'dropout'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'device'</span><span class="p">:</span> <span class="n">DEVICE</span><span class="p">,</span>
    <span class="s1">'num_channels'</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>Load in trained value and policy networks</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Load in trained value and policy networks</span>
<span class="n">model_save_name</span> <span class="o">=</span> <span class="s1">'ValueNetwork.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">vnet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
<span class="n">vnet</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">model_save_name</span><span class="p">)</span>


<span class="n">model_save_name</span> <span class="o">=</span> <span class="s1">'PolicyNetwork.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">pnet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
<span class="n">pnet</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">model_save_name</span><span class="p">)</span>


<span class="c1"># Alternative if the downloading of trained model didn't work (will train the model)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s1">'nma_rl_games/alpha-zero/pretrained_models/models/'</span><span class="p">):</span>

    <span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/data/"</span>
    <span class="n">loaded_games</span> <span class="o">=</span> <span class="n">loadTrainExamples</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">'checkpoint_1.pth.tar'</span><span class="p">)</span>

    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">vnet</span> <span class="o">=</span> <span class="n">ValueNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
    <span class="n">vnet</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">loaded_games</span><span class="p">)</span>

    <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">pnet</span> <span class="o">=</span> <span class="n">PolicyNetwork</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>
    <span class="n">pnet</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">loaded_games</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p>A reminder of the network architecture</p>
<figure>
<img src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W3D5_ReinforcementLearningForGames/static/CNN.jpg"/>
</figure></div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-plan-using-monte-carlo-rollouts">
<h1>Section 1: Plan using Monte Carlo Rollouts<a class="headerlink" href="#section-1-plan-using-monte-carlo-rollouts" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~15mins</em></p>
<p><strong>Goal</strong>: Teach the students the core idea behind using simulated rollouts to understand the future and value actions.</p>
<p><strong>Exercise</strong>:</p>
<ul class="simple">
<li><p>Build a loop to run Monte Carlo simulations using the policy network.</p></li>
<li><p>Use this to obtain better estimates of the value of moves.</p></li>
</ul>
<div class="section" id="video-1-play-using-monte-carlo-rollouts">
<h2>Video 1: Play using Monte-Carlo rollouts<a class="headerlink" href="#video-1-play-using-monte-carlo-rollouts" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d430791c63414bf2a747a0bb7c7d9d9a"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-1-montecarlo">
<h2>Coding Exercise 1: <code class="docutils literal notranslate"><span class="pre">MonteCarlo</span></code><a class="headerlink" href="#coding-exercise-1-montecarlo" title="Permalink to this headline">¶</a></h2>
<p>To recapitulate, the goal of the Monte Carlo algorithm here is to evaluate the outcome of different plans according to the policy used, i.e., what future Value function do we expect to end up with. So we will iterate the game forward in time (according to the game rules and with specific strategies) and return the Value function output at the end of that iteration.</p>
<p>Here, we will first set up the Monte Carlo planner.</p>
<p><strong>Note</strong>: because we will be simulating different actions into the future (planning), we want to distinguish potential board positions from actual ones that are taken. Therefore, the current (actual) position of the board that is used as a starting point for Monte-Carlo simulations will be labeled “canonical board” to avoid confusion.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MonteCarlo</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Implementation of Monte Carlo Algorithm</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">nnet</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize Monte Carlo Parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      nnet: OthelloNet instance</span>
<span class="sd">        Instance of the OthelloNNet class above;</span>
<span class="sd">      args: dictionary</span>
<span class="sd">        Instantiates number of iterations and episodes, controls temperature threshold, queue length,</span>
<span class="sd">        arena, checkpointing, and neural network parameters:</span>
<span class="sd">        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,</span>
<span class="sd">        num_channels: 512</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">nnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores initial policy (returned by neural net)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Es</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores game.getGameEnded ended for board s</span>

  <span class="c1"># Call this rollout</span>
  <span class="k">def</span> <span class="nf">simulate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonicalBoard</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Helper function to simulate one Monte Carlo rollout</span>

<span class="sd">    Args:</span>
<span class="sd">      canonicalBoard: np.ndarray</span>
<span class="sd">        Canonical Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      temp_v:</span>
<span class="sd">        Terminal State</span>
<span class="sd">    """</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">stringRepresentation</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
    <span class="n">init_start_state</span> <span class="o">=</span> <span class="n">s</span>
    <span class="n">temp_v</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">isfirstAction</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">current_player</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>  <span class="c1"># opponent's turn (the agent has already taken an action before the simulation)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">maxDepth</span><span class="p">):</span>  <span class="c1"># maxDepth</span>

      <span class="k">if</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getGameEnded</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Terminal state</span>
        <span class="n">temp_v</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">current_player</span>
        <span class="k">break</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
      <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">valids</span>  <span class="c1"># Masking invalid moves</span>
      <span class="n">sum_Ps_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>

      <span class="k">if</span> <span class="n">sum_Ps_s</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">/=</span> <span class="n">sum_Ps_s</span>  <span class="c1"># Renormalize</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># If all valid moves were masked make all valid moves equally probable</span>
        <span class="c1"># NB! All valid moves may be masked if either your NNet architecture is insufficient or you've get overfitting or something else.</span>
        <span class="c1"># If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.</span>
        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"All valid moves were masked, doing a workaround."</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">+</span> <span class="n">valids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>

      <span class="c1">##########################################################################</span>
      <span class="c1">## TODO for students: Take a random action.</span>
      <span class="c1">#  1. Take the random action.</span>
      <span class="c1">#  2. Find the next state and the next player from the environment.</span>
      <span class="c1">#  3. Get the canonical form of the next state.</span>
      <span class="c1"># Fill out function and remove</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Take the action, find the next state"</span><span class="p">)</span>
      <span class="c1">##########################################################################</span>
      <span class="c1"># Take a random action</span>
      <span class="n">a</span> <span class="o">=</span> <span class="o">...</span>
      <span class="c1"># Find the next state and the next player</span>
      <span class="n">next_s</span><span class="p">,</span> <span class="n">next_player</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getNextState</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
      <span class="n">canonicalBoard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getCanonicalForm</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
      <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">stringRepresentation</span><span class="p">(</span><span class="n">next_s</span><span class="p">)</span>
      <span class="n">current_player</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
      <span class="c1"># Initial policy</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
      <span class="n">temp_v</span> <span class="o">=</span> <span class="n">v</span>

    <span class="k">return</span> <span class="n">temp_v</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 1: MonteCarlo'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial4_Solution_de99f3b2.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-use-monte-carlo-simulations-to-play-games">
<h1>Section 2: Use Monte Carlo simulations to play games<a class="headerlink" href="#section-2-use-monte-carlo-simulations-to-play-games" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~20mins</em></p>
<p><strong>Goal:</strong> Teach students how to use simple Monte Carlo planning to play games.</p>
<div class="section" id="video-2-play-with-planning">
<h2>Video 2: Play with planning<a class="headerlink" href="#video-2-play-with-planning" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "6499e6cef004401fa9366c50e4d945b1"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-2-monte-carlo-simulations">
<h2>Coding Exercise 2: Monte-Carlo simulations<a class="headerlink" href="#coding-exercise-2-monte-carlo-simulations" title="Permalink to this headline">¶</a></h2>
<p>Now we can run Monte-Carlo simulations. We essentially evaluate for a given action taken now what the potential future outcome will be. So we want to choose different future actions according to the policy (random vs. value-based vs. policy-based) and evaluate the outcomes. We will simulate potential future outcomes and compute their value and then average those values to get a sense of the averge value of our policy used for a given immediate (current) action. This iteration (rollout) can be expressed in the following pseudo-code:</p>
<p>for i in 1 to k:</p>
<ol class="simple">
<li><p>Choose the ith ranked action <span class="math notranslate nohighlight">\(a^i\)</span> for the current state <span class="math notranslate nohighlight">\(s_t\)</span> according to our specific policy function.</p></li>
<li><p>Run N Monte Carlo rollouts from <span class="math notranslate nohighlight">\(s_{t+1}\)</span> following the application of <span class="math notranslate nohighlight">\(a^i\)</span>, <span class="math notranslate nohighlight">\(j\)</span> steps into the future (depth)</p></li>
<li><p>Average the estimated values for each rollout to get: <span class="math notranslate nohighlight">\(V_{i}^{AVG}\)</span></p></li>
<li><p>Build an array of <span class="math notranslate nohighlight">\([V_{i}^{AVG}, a^i]\)</span> pairs.</p></li>
</ol>
<p>To act, choose the action associated with the highest average value, i.e., <span class="math notranslate nohighlight">\(\underset{a^i}{\operatorname{argmax}}(V_{i}^{AVG})\)</span>. We will use <span class="math notranslate nohighlight">\(k=3\)</span>, <span class="math notranslate nohighlight">\(j=3\)</span> and <span class="math notranslate nohighlight">\(N=10\)</span>.</p>
<br/>
<p><strong>Exercise</strong>:</p>
<ul class="simple">
<li><p>Incorporate Monte Carlo simulations into an agent.</p></li>
<li><p>Run the resulting player versus the random, value-based, and policy-based players.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load MC model from the repository</span>
<span class="n">mc_model_save_name</span> <span class="o">=</span> <span class="s1">'MC.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MonteCarloBasedPlayer</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Simulate Player based on Monte Carlo Algorithm</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">nnet</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize Monte Carlo Parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      nnet: OthelloNet instance</span>
<span class="sd">        Instance of the OthelloNNet class above;</span>
<span class="sd">      args: dictionary</span>
<span class="sd">        Instantiates number of iterations and episodes, controls temperature threshold, queue length,</span>
<span class="sd">        arena, checkpointing, and neural network parameters:</span>
<span class="sd">        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,</span>
<span class="sd">        num_channels: 512</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">nnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
    <span class="c1">############################################################################</span>
    <span class="c1">## TODO for students: Instantiate the Monte Carlo class.</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Use Monte Carlo!"</span><span class="p">)</span>
    <span class="c1">############################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mc</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">mc_topk</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonicalBoard</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Simulate Play on Canonical Board</span>

<span class="sd">    Args:</span>
<span class="sd">      canonicalBoard: np.ndarray</span>
<span class="sd">        Canonical Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">      best_action: tuple</span>
<span class="sd">        (avg_value, action) i.e., Average value associated with corresponding action</span>
<span class="sd">        i.e., Action with the highest topK probability</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">qsa</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">stringRepresentation</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
    <span class="n">Ps</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Ps</span> <span class="o">=</span> <span class="n">Ps</span> <span class="o">*</span> <span class="n">valids</span>  <span class="c1"># Masking invalid moves</span>
    <span class="n">sum_Ps_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Ps</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sum_Ps_s</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">Ps</span> <span class="o">/=</span> <span class="n">sum_Ps_s</span>  <span class="c1"># Renormalize</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If all valid moves were masked make all valid moves equally probable</span>
      <span class="c1"># NB! All valid moves may be masked if either your NNet architecture is insufficient or you've get overfitting or something else.</span>
      <span class="c1"># If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.</span>
      <span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
      <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"All valid moves were masked, doing a workaround."</span><span class="p">)</span>
      <span class="n">Ps</span> <span class="o">=</span> <span class="n">Ps</span> <span class="o">+</span> <span class="n">valids</span>
      <span class="n">Ps</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Ps</span><span class="p">)</span>

    <span class="n">num_valid_actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">Ps</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">num_valid_actions</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">:</span>
      <span class="n">top_k_actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">Ps</span><span class="p">,</span><span class="o">-</span><span class="n">num_valid_actions</span><span class="p">)[</span><span class="o">-</span><span class="n">num_valid_actions</span><span class="p">:]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">top_k_actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argpartition</span><span class="p">(</span><span class="n">Ps</span><span class="p">,</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">)[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">K</span><span class="p">:]</span>  <span class="c1"># To get actions that belongs to top k prob</span>
    <span class="c1">############################################################################</span>
    <span class="c1">## TODO for students:</span>
    <span class="c1">#  1. For each action in the top-k actions</span>
    <span class="c1">#  2. Get the next state using getNextState() function.</span>
    <span class="c1">#     You can find the implementation of this function in Tutorial 1 in</span>
    <span class="c1">#     `OthelloGame()` class.</span>
    <span class="c1">#  3. Get the canonical form of the getNextState().</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Loop for the top actions"</span><span class="p">)</span>
    <span class="c1">############################################################################</span>
    <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="o">...</span><span class="p">:</span>
      <span class="n">next_s</span><span class="p">,</span> <span class="n">next_player</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getNextState</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
      <span class="n">next_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getCanonicalForm</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>

      <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>

      <span class="c1"># Do some rollouts</span>
      <span class="k">for</span> <span class="n">rollout</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">numMCsims</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

      <span class="c1"># Average out values</span>
      <span class="n">avg_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">qsa</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">avg_value</span><span class="p">,</span> <span class="n">action</span><span class="p">))</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">qsa</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">qsa</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
    <span class="n">best_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qsa</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">best_action</span>

  <span class="k">def</span> <span class="nf">getActionProb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonicalBoard</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Helper function to get probabilities associated with each action</span>

<span class="sd">    Args:</span>
<span class="sd">      canonicalBoard: np.ndarray</span>
<span class="sd">        Canonical Board of size n x n [6x6 in this case]</span>
<span class="sd">      temp: Integer</span>
<span class="sd">        Signifies if game is in terminal state</span>

<span class="sd">    Returns:</span>
<span class="sd">      action_probs: List</span>
<span class="sd">        Probability associated with corresponding action</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getGameEnded</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()))</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="n">action_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()))</span>
      <span class="n">best_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
      <span class="n">action_probs</span><span class="p">[</span><span class="n">best_action</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">action_probs</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 7: MonteCarlo siumulations'</span><span class="p">)</span>

<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="c1"># Run the resulting player versus the random player</span>
<span class="n">rp</span> <span class="o">=</span> <span class="n">RandomPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>
<span class="n">num_games</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Feel free to change this number</span>

<span class="n">n1</span> <span class="o">=</span> <span class="n">NNet</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>  <span class="c1"># nNet players</span>
<span class="n">n1</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">mc_model_save_name</span><span class="p">)</span>
<span class="n">args1</span> <span class="o">=</span> <span class="n">dotdict</span><span class="p">({</span><span class="s1">'numMCsims'</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">'maxRollouts'</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s1">'maxDepth'</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="s1">'mc_topk'</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>

<span class="c1">## Uncomment below to check Monte Carlo agent!</span>
<span class="c1"># print('\n******MC player versus random player******')</span>
<span class="c1"># mc1 = MonteCarloBasedPlayer(game, n1, args1)</span>
<span class="c1"># n1p = lambda x: np.argmax(mc1.getActionProb(x))</span>
<span class="c1"># arena = Arena.Arena(n1p, rp, game, display=OthelloGame.display)</span>
<span class="c1"># MC_result = arena.playGames(num_games, verbose=False)</span>
<span class="c1"># print(f"\n\n{MC_result}")</span>
<span class="c1"># print(f"\nNumber of games won by player1 = {MC_result[0]}, "</span>
<span class="c1">#       f"number of games won by player2 = {MC_result[1]}, out of {num_games} games")</span>
<span class="c1"># win_rate_player1 = MC_result[0]/num_games</span>
<span class="c1"># print(f"\nWin rate for player1 over {num_games} games: {round(win_rate_player1*100, 1)}%")</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial4_Solution_d28a1896.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player1</span> <span class="o">=</span> <span class="mi">13</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player2</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">20</span> <span class="n">games</span>

<span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">player1</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">65.0</span><span class="o">%</span>
</pre></div>
</div>
<p><strong>Note</strong>: the Monte-Carlo player doesn’t seem to be doing much better than the random player… This is because training of a good MC player is VERY compute intensive and we have not done extensive training here. In Bonus 2 below, you can play with a Monte-Carlo Tree Search (MCTS) player that has been trained well and you’ll see that it performs much better!</p>
<div class="section" id="monte-carlo-player-against-value-based-player">
<h3>Monte-Carlo player against Value-based player<a class="headerlink" href="#monte-carlo-player-against-value-based-player" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">******MC player versus value-based player******'</span><span class="p">)</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">vp</span> <span class="o">=</span> <span class="n">ValueBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">vnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>  <span class="c1"># Value-based player</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">n1p</span><span class="p">,</span> <span class="n">vp</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">MC_result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">MC_result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Number of games won by player1 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, "</span>
      <span class="sa">f</span><span class="s2">"number of games won by player2 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, out of </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games"</span><span class="p">)</span>
<span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Win rate for player1 over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player1</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player2</span> <span class="o">=</span> <span class="mi">11</span><span class="p">,</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">20</span> <span class="n">games</span>

<span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">player1</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">45.0</span><span class="o">%</span>
</pre></div>
</div>
</div>
<div class="section" id="monte-carlo-player-against-policy-based-player">
<h3>Monte-Carlo player against Policy-based player<a class="headerlink" href="#monte-carlo-player-against-policy-based-player" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">******MC player versus policy-based player******'</span><span class="p">)</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>  <span class="c1"># Policy player</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">n1p</span><span class="p">,</span> <span class="n">pp</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">MC_result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">MC_result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Number of games won by player1 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, "</span>
      <span class="sa">f</span><span class="s2">"number of games won by player2 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, out of </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games"</span><span class="p">)</span>
<span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Win rate for player1 over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player1</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player2</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">20</span> <span class="n">games</span>

<span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">player1</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">25.0</span><span class="o">%</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-3-outro">
<h2>Video 3: Outro<a class="headerlink" href="#video-3-outro" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "fc597337590648f186430745c52ad3c9"}
</script></div>
</div>
</div>
<div class="section" id="airtable-submission-link">
<h2>Airtable Submission Link<a class="headerlink" href="#airtable-submission-link" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Airtable Submission Link</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPydisplay</span>
<span class="n">IPydisplay</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span>
   <span class="sa">f</span><span class="s2">"""</span>
<span class="s2"> &lt;div&gt;</span>
<span class="s2">   &lt;a href= "</span><span class="si">{</span><span class="n">atform</span><span class="o">.</span><span class="n">url</span><span class="p">()</span><span class="si">}</span><span class="s2">" target="_blank"&gt;</span>
<span class="s2">   &lt;img src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1"</span>
<span class="s2"> alt="button link end of day Survey" style="width:410px"&gt;&lt;/a&gt;</span>
<span class="s2">   &lt;/div&gt;"""</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
<a href="95651a47-083f-406e-a6cd-8af24670c5bc?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzNENV9UNCIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTY3NDY0OTY1OS4yNDY1Njd9LCB7ImV2ZW50IjogIlZpZGVvIDE6IFBsYXkgdXNpbmcgTW9udGUtQ2FybG8gcm9sbG91dHMiLCAidHMiOiAxNjc0NjQ5NjcyLjg0NTA4NDd9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSAxOiBNb250ZUNhcmxvIiwgInRzIjogMTY3NDY0OTY3Mi44Njk2NzMzfSwgeyJldmVudCI6ICJWaWRlbyAyOiBQbGF5IHdpdGggcGxhbm5pbmciLCAidHMiOiAxNjc0NjQ5NjcyLjk4NTE0ODR9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSA3OiBNb250ZUNhcmxvIHNpdW11bGF0aW9ucyIsICJ0cyI6IDE2NzQ2NDk2NzMuMDMwOTQ1NX0sIHsiZXZlbnQiOiAiVmlkZW8gOTogT3V0cm8iLCAidHMiOiAxNjc0NjQ5NjczLjQ1MDUxMzF9LCB7ImV2ZW50IjogInVybCBnZW5lcmF0ZWQiLCAidHMiOiAxNjc0NjQ5NjczLjQ3MzAxMn1dfQ%3D%3D" target="_blank">
<img alt="button link end of day Survey" src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1" style="width:410px"/></a>
</div></div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-1-plan-using-monte-carlo-tree-search-mcts">
<h1>Bonus 1: Plan using Monte Carlo Tree Search (MCTS)<a class="headerlink" href="#bonus-1-plan-using-monte-carlo-tree-search-mcts" title="Permalink to this headline">¶</a></h1>
<p>*Time estimate: ~30mins</p>
<p><strong>Goal:</strong> Teach students to understand the core ideas behind Monte Carlo Tree Search (MCTS).</p>
<div class="section" id="video-4-plan-with-mcts">
<h2>Video 4: Plan with MCTS<a class="headerlink" href="#video-4-plan-with-mcts" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "071dbe8d25384d54afa4b9ae5c7c6f67"}
</script></div>
</div>
</div>
<div class="section" id="bonus-coding-exercise-1-mcts-planner">
<h2>Bonus Coding Exercise 1: MCTS planner<a class="headerlink" href="#bonus-coding-exercise-1-mcts-planner" title="Permalink to this headline">¶</a></h2>
<p>In building the MCTS planner, we will focus on the action selection part, particularly the objective function used. MCTS will use a combination of the current action-value function <span class="math notranslate nohighlight">\(Q\)</span> and the policy prior as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0fa11144-2084-4d8e-81f7-90ea542a95b6">
<span class="eqno">(132)<a class="headerlink" href="#equation-0fa11144-2084-4d8e-81f7-90ea542a95b6" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\underset{a}{\operatorname{argmax}} (Q(s_t, a)+u(s_t, a))
\end{equation}\]</div>
<p>with <span class="math notranslate nohighlight">\(u(s_t, a)=c_{puct} \cdot P(s,a) \cdot \frac{\sqrt{\sum_b N(s,b)}}{1+N(s,a)}\)</span>. This effectively implements an Upper Confidence bound applied to Trees (UCT). UCT balances exploration and exploitation by taking the values stored from the MCTS into account. The trade-off is parametrized by <span class="math notranslate nohighlight">\(c_{puct}\)</span>.</p>
<p><strong>Note</strong>: Polynomial Upper Confidence Trees (PUCT) is the technical term for the alorithm below in which we sequentially run MCTS and store/use information from previous runs to explore and find optimal actions).</p>
<br/>
<p><strong>Exercise</strong>:</p>
<ul class="simple">
<li><p>Finish the MCTS planner by using UCT to select actions to build the tree.</p></li>
<li><p>Deploy the MCTS planner to build a tree search for a given board position, producing value estimates and action counts for that position.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MCTS</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  This class handles MCTS (Monte Carlo Tree Search).</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">nnet</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize parameters of MCTS</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      nnet: OthelloNet instance</span>
<span class="sd">        Instance of the OthelloNNet class above;</span>
<span class="sd">      args: dictionary</span>
<span class="sd">        Instantiates number of iterations and episodes, controls temperature threshold, queue length,</span>
<span class="sd">        arena, checkpointing, and neural network parameters:</span>
<span class="sd">        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,</span>
<span class="sd">        num_channels: 512</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">nnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Qsa</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores Q values for s,a (as defined in the paper)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores #times edge s,a was visited</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Ns</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores #times board s was visited</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores initial policy (returned by neural net)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Es</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores game.getGameEnded ended for board s</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Vs</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Stores game.getValidMoves for board s</span>

  <span class="k">def</span> <span class="nf">search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonicalBoard</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This function performs one iteration of MCTS. It is recursively called</span>
<span class="sd">    till a leaf node is found. The action chosen at each node is one that</span>
<span class="sd">    has the maximum upper confidence bound as in the paper.</span>
<span class="sd">    Once a leaf node is found, the neural network is called to return an</span>
<span class="sd">    initial policy P and a value v for the state. This value is propagated</span>
<span class="sd">    up the search path. In case the leaf node is a terminal state, the</span>
<span class="sd">    outcome is propagated up the search path. The values of Ns, Nsa, Qsa are</span>
<span class="sd">    updated.</span>
<span class="sd">    NOTE: the return values are the negative of the value of the current</span>
<span class="sd">    state. This is done since v is in [-1,1] and if v is the value of a</span>
<span class="sd">    state for the current player, then its value is -v for the other player.</span>

<span class="sd">    Args:</span>
<span class="sd">      canonicalBoard: np.ndarray</span>
<span class="sd">        Canonical Board of size n x n [6x6 in this case]</span>

<span class="sd">    Returns:</span>
<span class="sd">        v: Float</span>
<span class="sd">          The negative of the value of the current canonicalBoard</span>
<span class="sd">    """</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">stringRepresentation</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getGameEnded</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="c1"># Terminal node</span>
      <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">Es</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">:</span>
      <span class="c1"># Leaf node</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
      <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getValidMoves</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">*</span> <span class="n">valids</span>  <span class="c1"># Masking invalid moves</span>
      <span class="n">sum_Ps_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">sum_Ps_s</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">/=</span> <span class="n">sum_Ps_s</span>  <span class="c1"># Renormalize</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># If all valid moves were masked make all valid moves equally probable</span>
        <span class="c1"># NB! All valid moves may be masked if either your NNet architecture is</span>
        <span class="c1"># insufficient or you've get overfitting or something else.</span>
        <span class="c1"># If you have got dozens or hundreds of these messages you should</span>
        <span class="c1"># pay attention to your NNet and/or training process.</span>
        <span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"All valid moves were masked, doing a workaround."</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">+</span> <span class="n">valids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Ps</span><span class="p">[</span><span class="n">s</span><span class="p">])</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">Vs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">valids</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Ns</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

      <span class="k">return</span> <span class="o">-</span><span class="n">v</span>

    <span class="n">valids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Vs</span><span class="p">[</span><span class="n">s</span><span class="p">]</span>
    <span class="n">cur_best</span> <span class="o">=</span> <span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>
    <span class="n">best_act</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="c1">############################################################################</span>
    <span class="c1">## TODO for students:</span>
    <span class="c1">#  Implement the highest upper confidence bound depending whether we observed</span>
    <span class="c1">#  the state-action pair which is stored in self.Qsa[(s, a)].</span>
    <span class="c1">#  You can find the formula in the slide 52 in video 8 above.</span>
    <span class="c1">#  Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Complete the for loop"</span><span class="p">)</span>
    <span class="c1">############################################################################</span>
    <span class="c1"># Pick the action with the highest upper confidence bound</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()):</span>
      <span class="k">if</span> <span class="n">valids</span><span class="p">[</span><span class="n">a</span><span class="p">]:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qsa</span><span class="p">:</span>
          <span class="n">u</span> <span class="o">=</span> <span class="o">...</span> <span class="o">+</span> <span class="o">...</span> <span class="o">*</span> <span class="o">...</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="o">...</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">u</span> <span class="o">=</span> <span class="o">...</span> <span class="o">*</span> <span class="o">...</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">...</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">u</span> <span class="o">&gt;</span> <span class="n">cur_best</span><span class="p">:</span>
          <span class="n">cur_best</span> <span class="o">=</span> <span class="n">u</span>
          <span class="n">best_act</span> <span class="o">=</span> <span class="n">a</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">best_act</span>
    <span class="n">next_s</span><span class="p">,</span> <span class="n">next_player</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getNextState</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">next_s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getCanonicalForm</span><span class="p">(</span><span class="n">next_s</span><span class="p">,</span> <span class="n">next_player</span><span class="p">)</span>

    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">next_s</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qsa</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Qsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Qsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">+</span> <span class="n">v</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Qsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="n">v</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">Ns</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">v</span>

  <span class="k">def</span> <span class="nf">getNsa</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial4_Solution_8e0c5067.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-2-use-mcts-to-play-games">
<h1>Bonus 2: Use MCTS to play games<a class="headerlink" href="#bonus-2-use-mcts-to-play-games" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~10mins</em></p>
<p><strong>Goal:</strong> Learn how to use the results of MCTS to play games.</p>
<p><strong>Exercise:</strong></p>
<ul class="simple">
<li><p>Plug the MCTS planner into an agent.</p></li>
<li><p>Play games against other agents.</p></li>
<li><p>Explore the contributions of prior network, value function, number of simulations/time to play and explore/exploit parameters.</p></li>
</ul>
<div class="section" id="video-5-play-with-mcts">
<h2>Video 5: Play with MCTS<a class="headerlink" href="#video-5-play-with-mcts" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d49cd4ef7bea45c9a743d8fbf4906dd3"}
</script></div>
</div>
</div>
<div class="section" id="bonus-coding-exercise-2-agent-that-uses-an-mcts-planner">
<h2>Bonus Coding Exercise 2: Agent that uses an MCTS planner<a class="headerlink" href="#bonus-coding-exercise-2-agent-that-uses-an-mcts-planner" title="Permalink to this headline">¶</a></h2>
<p>Now we can use the MCTS planner and play the game! We will again let the MCTS planner play against players with other policies.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load MCTS model from the repository</span>
<span class="n">mcts_model_save_name</span> <span class="o">=</span> <span class="s1">'MCTS.pth.tar'</span>
<span class="n">path</span> <span class="o">=</span> <span class="s2">"nma_rl_games/alpha-zero/pretrained_models/models/"</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MonteCarloTreeSearchBasedPlayer</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Simulate Player based on MCTS</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">nnet</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize parameters of MCTS</span>

<span class="sd">    Args:</span>
<span class="sd">      game: OthelloGame instance</span>
<span class="sd">        Instance of the OthelloGame class above;</span>
<span class="sd">      nnet: OthelloNet instance</span>
<span class="sd">        Instance of the OthelloNNet class above;</span>
<span class="sd">      args: dictionary</span>
<span class="sd">        Instantiates number of iterations and episodes, controls temperature threshold, queue length,</span>
<span class="sd">        arena, checkpointing, and neural network parameters:</span>
<span class="sd">        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,</span>
<span class="sd">        num_channels: 512</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">game</span> <span class="o">=</span> <span class="n">game</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nnet</span> <span class="o">=</span> <span class="n">nnet</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mcts</span> <span class="o">=</span> <span class="n">MCTS</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">nnet</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">play</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonicalBoard</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Simulate Play on Canonical Board</span>

<span class="sd">    Args:</span>
<span class="sd">      canonicalBoard: np.ndarray</span>
<span class="sd">        Canonical Board of size n x n [6x6 in this case]</span>
<span class="sd">      temp: Integer</span>
<span class="sd">        Signifies if game is in terminal state</span>

<span class="sd">    Returns:</span>
<span class="sd">      List of probabilities for all actions if temp is 0</span>
<span class="sd">      Best action based on max probability otherwise</span>
<span class="sd">    """</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">numMCTSSims</span><span class="p">):</span>

      <span class="c1">##########################################################################</span>
      <span class="c1">## TODO for students:</span>
      <span class="c1">#  Run MCTS search function.</span>
      <span class="c1">#  Fill out function and remove</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Plug the planner"</span><span class="p">)</span>
      <span class="c1">##########################################################################</span>
      <span class="o">...</span>

    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">stringRepresentation</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
    <span class="c1">############################################################################</span>
    <span class="c1">## TODO for students:</span>
    <span class="c1">#  Call the Nsa function from MCTS class and store it in the self.Nsa</span>
    <span class="c1">#  Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Compute Nsa (number of times edge s,a was visited)"</span><span class="p">)</span>
    <span class="c1">############################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span><span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)]</span> <span class="k">if</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">Nsa</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">())]</span>

    <span class="k">if</span> <span class="n">temp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">bestAs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">)))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
      <span class="n">bestA</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">bestAs</span><span class="p">)</span>
      <span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">)</span>
      <span class="n">probs</span><span class="p">[</span><span class="n">bestA</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">return</span> <span class="n">probs</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">counts</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">temp</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">counts_sum</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">))</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">counts_sum</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">counts</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">getActionProb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">canonicalBoard</span><span class="p">,</span> <span class="n">temp</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Helper function to get probabilities associated with each action</span>

<span class="sd">    Args:</span>
<span class="sd">      canonicalBoard: np.ndarray</span>
<span class="sd">        Canonical Board of size n x n [6x6 in this case]</span>
<span class="sd">      temp: Integer</span>
<span class="sd">        Signifies if game is in terminal state</span>

<span class="sd">    Returns:</span>
<span class="sd">      action_probs: List</span>
<span class="sd">        Probability associated with corresponding action</span>
<span class="sd">    """</span>
    <span class="n">action_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">game</span><span class="o">.</span><span class="n">getActionSize</span><span class="p">()))</span>
    <span class="n">best_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">canonicalBoard</span><span class="p">)</span>
    <span class="n">action_probs</span><span class="p">[</span><span class="n">best_action</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">action_probs</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">game</span> <span class="o">=</span> <span class="n">OthelloGame</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">rp</span> <span class="o">=</span> <span class="n">RandomPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>  <span class="c1"># All players</span>
<span class="n">num_games</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Games</span>
<span class="n">n1</span> <span class="o">=</span> <span class="n">NNet</span><span class="p">(</span><span class="n">game</span><span class="p">)</span>  <span class="c1"># nnet players</span>
<span class="n">n1</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">mcts_model_save_name</span><span class="p">)</span>
<span class="n">args1</span> <span class="o">=</span> <span class="n">dotdict</span><span class="p">({</span><span class="s1">'numMCTSSims'</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">'cpuct'</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>

<span class="c1">## Uncomment below to check your agent!</span>
<span class="c1"># print('\n******MCTS player versus random player******')</span>
<span class="c1"># mcts1 = MonteCarloTreeSearchBasedPlayer(game, n1, args1)</span>
<span class="c1"># n1p = lambda x: np.argmax(mcts1.getActionProb(x, temp=0))</span>
<span class="c1"># arena = Arena.Arena(n1p, rp, game, display=OthelloGame.display)</span>
<span class="c1"># MCTS_result = arena.playGames(num_games, verbose=False)</span>
<span class="c1"># print(f"\n\n{MCTS_result}")</span>
<span class="c1"># print(f"\nNumber of games won by player1 = {MCTS_result[0]}, "</span>
<span class="c1">#       f"number of games won by player2 = {MCTS_result[1]}, out of {num_games} games")</span>
<span class="c1"># win_rate_player1 = MCTS_result[0]/num_games</span>
<span class="c1"># print(f"\nWin rate for player1 over {num_games} games: {round(win_rate_player1*100, 1)}%")</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D5_ReinforcementLearningForGames/solutions/W3D5_Tutorial4_Solution_ad43a5d4.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player1</span> <span class="o">=</span> <span class="mi">19</span><span class="p">,</span> <span class="n">num</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player2</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">20</span> <span class="n">games</span>

<span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">player1</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">95.0</span><span class="o">%</span>
</pre></div>
</div>
<div class="section" id="mcts-player-against-value-based-player">
<h3>MCTS player against Value-based player<a class="headerlink" href="#mcts-player-against-value-based-player" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">******MCTS player versus value-based player******'</span><span class="p">)</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">vp</span> <span class="o">=</span> <span class="n">ValueBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">vnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>  <span class="c1"># Value-based player</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">n1p</span><span class="p">,</span> <span class="n">vp</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">MC_result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">MC_result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Number of games won by player1 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, "</span>
      <span class="sa">f</span><span class="s2">"number of games won by player2 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, out of </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games"</span><span class="p">)</span>
<span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Win rate for player1 over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player1</span> <span class="o">=</span> <span class="mi">14</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player2</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">20</span> <span class="n">games</span>

<span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">player1</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">70.0</span><span class="o">%</span>
</pre></div>
</div>
</div>
<div class="section" id="mcts-player-against-policy-based-player">
<h3>MCTS player against Policy-based player<a class="headerlink" href="#mcts-player-against-policy-based-player" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">******MCTS player versus policy-based player******'</span><span class="p">)</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">pp</span> <span class="o">=</span> <span class="n">PolicyBasedPlayer</span><span class="p">(</span><span class="n">game</span><span class="p">,</span> <span class="n">pnet</span><span class="p">)</span><span class="o">.</span><span class="n">play</span>  <span class="c1"># Policy-based player</span>
<span class="n">arena</span> <span class="o">=</span> <span class="n">Arena</span><span class="o">.</span><span class="n">Arena</span><span class="p">(</span><span class="n">n1p</span><span class="p">,</span> <span class="n">pp</span><span class="p">,</span> <span class="n">game</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="n">OthelloGame</span><span class="o">.</span><span class="n">display</span><span class="p">)</span>
<span class="n">MC_result</span> <span class="o">=</span> <span class="n">arena</span><span class="o">.</span><span class="n">playGames</span><span class="p">(</span><span class="n">num_games</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n\n</span><span class="si">{</span><span class="n">MC_result</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Number of games won by player1 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, "</span>
      <span class="sa">f</span><span class="s2">"number of games won by player2 = </span><span class="si">{</span><span class="n">MC_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, out of </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games"</span><span class="p">)</span>
<span class="n">win_rate_player1</span> <span class="o">=</span> <span class="n">MC_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">num_games</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Win rate for player1 over </span><span class="si">{</span><span class="n">num_games</span><span class="si">}</span><span class="s2"> games: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">win_rate_player1</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player1</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">games</span> <span class="n">won</span> <span class="n">by</span> <span class="n">player2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">out</span> <span class="n">of</span> <span class="mi">20</span> <span class="n">games</span>

<span class="n">Win</span> <span class="n">rate</span> <span class="k">for</span> <span class="n">player1</span> <span class="n">over</span> <span class="mi">20</span> <span class="n">games</span><span class="p">:</span> <span class="mf">100.0</span><span class="o">%</span>
</pre></div>
</div>
</div>
</div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {"bc7113fddea046ababfffc18a26c4ad0": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f3a903c251d94baea86012a99c1f8f18": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_bc7113fddea046ababfffc18a26c4ad0", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1Rb4y1U7BW\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7fc97b534410>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1Rb4y1U7BW&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "1ab3f11363be4878ae50bfcfab337026": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b611081852e14305b735a6665895d61a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_1ab3f11363be4878ae50bfcfab337026", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=DtCWDIlSo18\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7fca44338b10>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/DtCWDIlSo18?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "96901822105949c4a95750fef07da8cc": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d430791c63414bf2a747a0bb7c7d9d9a": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_b611081852e14305b735a6665895d61a", "IPY_MODEL_f3a903c251d94baea86012a99c1f8f18"], "layout": "IPY_MODEL_96901822105949c4a95750fef07da8cc", "selected_index": 0}}, "af13d3df75be4c7582e2d6e31d20a000": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "61378850c4bf44a5b7fdda3565eaf88a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_af13d3df75be4c7582e2d6e31d20a000", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1bh411B7S4\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7fc97b467e50>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1bh411B7S4&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "4895057ad53a440ba29c49da86f46fd5": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "28e2fb0dec784c8da9ad77d07a037464": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_4895057ad53a440ba29c49da86f46fd5", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=plmFzAy3H5s\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7fc97b467a50>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/plmFzAy3H5s?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "6cc329409a1c49f1b56770e92000f02f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6499e6cef004401fa9366c50e4d945b1": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_28e2fb0dec784c8da9ad77d07a037464", "IPY_MODEL_61378850c4bf44a5b7fdda3565eaf88a"], "layout": "IPY_MODEL_6cc329409a1c49f1b56770e92000f02f", "selected_index": 0}}, "373bb84af268475180ac667e765bbb5c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "04744eb8ccf247eea9275c614e31467a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_373bb84af268475180ac667e765bbb5c", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1a64y1s7Sh\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7fca442e8190>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1a64y1s7Sh&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "51c54f45a44c49d181dc2dc9133ff6fc": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "01e46e65a0bd40dbb6d44fb877d190c9": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_51c54f45a44c49d181dc2dc9133ff6fc", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=uQ26iIUzmtw\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7fc97b535090>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/uQ26iIUzmtw?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "5da4d3893143418ead0f8d1e85fc2c26": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fc597337590648f186430745c52ad3c9": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_01e46e65a0bd40dbb6d44fb877d190c9", "IPY_MODEL_04744eb8ccf247eea9275c614e31467a"], "layout": "IPY_MODEL_5da4d3893143418ead0f8d1e85fc2c26", "selected_index": 0}}, "a5148cb9f2404b35a0e0faa098d03638": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "341fd2659fc748ddbe00d70e4b59df94": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_a5148cb9f2404b35a0e0faa098d03638", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1yQ4y127Sr\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7fc9781a2510>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1yQ4y127Sr&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "6d70148ca52b48169027c3a0601a7f03": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "44664d7c8b1e42a7aa4bab4a2de6ced5": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_6d70148ca52b48169027c3a0601a7f03", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=Hhw6Ed0Zmco\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7fc97b534910>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/Hhw6Ed0Zmco?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "0ba7d7a36d7a45039551f20fe60ecfab": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "071dbe8d25384d54afa4b9ae5c7c6f67": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_44664d7c8b1e42a7aa4bab4a2de6ced5", "IPY_MODEL_341fd2659fc748ddbe00d70e4b59df94"], "layout": "IPY_MODEL_0ba7d7a36d7a45039551f20fe60ecfab", "selected_index": 0}}, "d739cfcc6c9241fb87ec273fb2199719": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fe943971af9e4af18586665c363aaece": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_d739cfcc6c9241fb87ec273fb2199719", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV13q4y1H7H6\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7fc978194910>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV13q4y1H7H6&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "68d29c47d62e4d2e830fecd5b534c14d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b9a94ece0fe84b9fb1ba781c0890073a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_68d29c47d62e4d2e830fecd5b534c14d", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=1BRXb-igKAU\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7fc9781a21d0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/1BRXb-igKAU?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "7d59b37f91174feaa7881acf958a2e43": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d49cd4ef7bea45c9a743d8fbf4906dd3": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_b9a94ece0fe84b9fb1ba781c0890073a", "IPY_MODEL_fe943971af9e4af18586665c363aaece"], "layout": "IPY_MODEL_7d59b37f91174feaa7881acf958a2e43", "selected_index": 0}}}, "version_major": 2, "version_minor": 0}
</script>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D5_ReinforcementLearningForGames/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W3D5_Tutorial3.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 3: Policy-based Player</p>
</div>
</a>
<a class="right-next" href="W3D5_BonusLecture.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Bonus Lecture: Amita Kapoor</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</br></p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>