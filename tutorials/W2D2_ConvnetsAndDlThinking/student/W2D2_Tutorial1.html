
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 1: Introduction to CNNs — Neuromatch Academy: Deep Learning</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-dl-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D2_Tutorial2.html" rel="next" title="Tutorial 2: Deep Learning Thinking 1: Cost Functions"/>
<link href="../chapter_title.html" rel="prev" title="Convnets And Dl Thinking"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/DeepLearning.html">
   Prerequisites and preparatory materials for NMA Deep Learning
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Basics Module
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">
     Bonus Lecture: Yoshua Bengio
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Fine Tuning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Optimization/chapter_title.html">
   Optimization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Optimization/student/W1D5_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_Regularization/chapter_title.html">
   Regularization (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/FineTuning.html">
   Deep Learning: The Basics and Fine Tuning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Convnets And Dl Thinking (W2D2)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W2D2_Tutorial2.html">
     Tutorial 2: Deep Learning Thinking 1: Cost Functions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W2D2_BonusLecture.html">
     Bonus Lecture: Kyunghyun Cho
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial2.html">
     Bonus Tutorial: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_GenerativeModels/chapter_title.html">
   Generative Models (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial2.html">
     Tutorial 2: Introduction to GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial4.html">
     Bonus Tutorial: Deploying Neural Networks on the Web
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_BonusLecture.html">
     Bonus Lecture: Geoffrey Hinton
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/chapter_title.html">
   Time Series And Natural Language Processing (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial1.html">
     Tutorial 1: Introduction to processing time series
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.html">
     Tutorial 2: Time series for Language
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial3.html">
     Bonus Tutorial: Multilingual Embeddings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/student/W3D1_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_DlThinking2/chapter_title.html">
   Dl Thinking2 (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_DlThinking2/student/W3D2_Tutorial1.html">
     Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/NaturalLanguageProcessing.html">
   Deep Learning: Convnets and NLP
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">
     Bonus Lecture: Melanie Mitchell
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial5.html">
     Bonus Tutorial: Function approximation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">
     Bonus Lecture: Chealsea Finn
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial1.html">
     Tutorial 1: Game Set-Up and Random Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial2.html">
     Tutorial 2: Value-Based Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial3.html">
     Tutorial 3: Policy-based Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial4.html">
     Bonus Tutorial: Planning with Monte Carlo
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_BonusLecture.html">
     Bonus Lecture: Amita Kapoor
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/ReinforcementLearning.html">
   Deep Learning: Reinforcement Learning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Introduction to CNNs
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-0-recap-the-experience-from-last-week">
   Section 0: Recap the Experience from Last Week
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction-to-cnns-and-rnns">
     Video 1: Introduction to CNNs and RNNs
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-0-regularization-effective-number-of-params">
     Think! 0: Regularization &amp; effective number of params
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#student-response">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-neuroscience-motivation-general-cnn-structure">
   Section 1: Neuroscience motivation, General CNN structure
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-representations-visual-processing-in-the-brain">
     Video 2: Representations &amp; Visual processing in the brain
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-what-makes-a-representation-good">
     Think! 1: What makes a representation good?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-convolutions-and-edge-detection">
   Section 2: Convolutions and Edge Detection
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-details-about-convolution">
     Video 3: Details about Convolution
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-visualization-of-convolution">
       Interactive Demo 2: Visualization of Convolution
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#definitional-note">
         Definitional Note
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-1-convolution-of-a-simple-kernel">
     Coding Exercise 2.1: Convolution of a Simple Kernel
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-2-convolution-output-size">
     Coding Exercise 2.2: Convolution Output Size
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-3-coding-a-convolution">
     Coding Exercise 2.3: Coding a Convolution
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#convolution-on-the-chicago-skyline">
       Convolution on the Chicago Skyline
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-images-run-me">
       Load images (run me)
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-demonstration-of-a-cnn-in-pytorch">
     Section 2.1: Demonstration of a CNN in PyTorch
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-padding-and-edge-detection">
     Section 2.2: Padding and Edge Detection
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-2-visualization-of-convolution-with-padding-and-stride">
       Interactive Demo 2.2: Visualization of Convolution with Padding and Stride
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-2-2-1-edge-detection">
       Think! 2.2.1: Edge Detection
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
         Student Response
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-2-2-2-kernel-structure">
       Think! 2.2.2 Kernel structure
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
         Student Response
        </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-pooling-and-subsampling">
   Section 3: Pooling and Subsampling
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-pooling">
     Video 4: Pooling
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-emnist-dataset">
     Download EMNIST dataset
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#dataset-dataloader-functions-run-me">
     Dataset/DataLoader Functions
     <em>
      (Run me!)
     </em>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-visualization-of-convolution-with-multiple-filters">
     Interactive Demo 3: Visualization of Convolution with Multiple Filters
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-multiple-filters">
     Section 3.1: Multiple Filters
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-1-do-you-see-how-these-filters-would-help-recognize-an-x">
       Think! 3.1: Do you see how these filters would help recognize an
       <code class="docutils literal notranslate">
<span class="pre">
         X
        </span>
</code>
       ?
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
         Student Response
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-relu-after-convolutions">
     Section 3.2: ReLU after convolutions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-3-pooling">
     Section 3.3: Pooling
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-3-the-effect-of-the-stride">
       Interactive Demo 3.3: The effect of the stride
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-3-implement-maxpooling">
       Coding Exercise 3.3: Implement MaxPooling
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-putting-it-all-together">
   Section 4: Putting it all together
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-putting-it-all-together">
     Video 5: Putting it all together
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-number-of-parameters-in-convolutional-vs-fully-connected-models">
     Section 4.1: Number of Parameters in Convolutional vs. Fully-connected Models
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-1-number-of-parameters">
       Interactive Demo 4.1: Number of Parameters
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-implement-your-own-cnn">
         Video 6: Implement your own CNN
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-implement-your-own-cnn">
     Coding Exercise 4: Implement your own CNN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-test-functions-run-me">
       Train/Test Functions (Run Me)
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-write-your-own-training-loop-revisited">
   Bonus 1: Write your own training loop revisited
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-writing-your-own-training-loop">
     Video 7: Writing your own training loop
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-1-understand-the-dataset">
     Bonus 1.1: Understand the Dataset
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-fashion-mnist-dataset">
       Download Fashion MNIST dataset
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#loading-fashion-mnist-data">
       Loading Fashion-MNIST Data
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-the-training-loop">
       Video 8: The Training Loop
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-2-backpropagation-reminder">
     Bonus 1.2: Backpropagation Reminder
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-a-sample-dataset-emnist">
       Load a sample dataset (EMNIST)
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-3-fashion-mnist-dataset">
     Bonus 1.3: Fashion-MNIST dataset
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#getting-the-dataloaders-run-me">
       Getting the DataLoaders (Run Me)
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-bonus-1-code-the-training-loop">
     Coding Exercise Bonus 1: Code the training loop
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-1-overfitting">
     Think! Bonus 1: Overfitting
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-overfitting-symptoms-and-cures">
   Bonus 2: Overfitting - symptoms and cures
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-1-regularization">
     Bonus 2.1: Regularization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-bonus-2-1-adding-regularization">
       Coding Exercise Bonus 2.1: Adding Regularization
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-2-1-regularization">
       Think! Bonus 2.1: Regularization
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-bonus-2-1-dropout-exploration">
       Interactive Demo Bonus 2.1: Dropout exploration
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-bonus-2-2-how-much-does-augmentation-help">
       Coding Exercise Bonus 2.2: How much does augmentation help?
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-fashion-mnist-if-it-has-not-been-downloaded">
         Download Fashion-MNIST, if it has not been downloaded.
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-2-2-data-augmentation">
       Think! Bonus 2.2: Data Augmentation
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 1: Introduction to CNNs</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Introduction to CNNs
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-0-recap-the-experience-from-last-week">
   Section 0: Recap the Experience from Last Week
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction-to-cnns-and-rnns">
     Video 1: Introduction to CNNs and RNNs
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-0-regularization-effective-number-of-params">
     Think! 0: Regularization &amp; effective number of params
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#student-response">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-neuroscience-motivation-general-cnn-structure">
   Section 1: Neuroscience motivation, General CNN structure
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-representations-visual-processing-in-the-brain">
     Video 2: Representations &amp; Visual processing in the brain
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-what-makes-a-representation-good">
     Think! 1: What makes a representation good?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-convolutions-and-edge-detection">
   Section 2: Convolutions and Edge Detection
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-details-about-convolution">
     Video 3: Details about Convolution
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-visualization-of-convolution">
       Interactive Demo 2: Visualization of Convolution
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#definitional-note">
         Definitional Note
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-1-convolution-of-a-simple-kernel">
     Coding Exercise 2.1: Convolution of a Simple Kernel
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-2-convolution-output-size">
     Coding Exercise 2.2: Convolution Output Size
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-3-coding-a-convolution">
     Coding Exercise 2.3: Coding a Convolution
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#convolution-on-the-chicago-skyline">
       Convolution on the Chicago Skyline
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-images-run-me">
       Load images (run me)
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-demonstration-of-a-cnn-in-pytorch">
     Section 2.1: Demonstration of a CNN in PyTorch
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-padding-and-edge-detection">
     Section 2.2: Padding and Edge Detection
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-2-visualization-of-convolution-with-padding-and-stride">
       Interactive Demo 2.2: Visualization of Convolution with Padding and Stride
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-2-2-1-edge-detection">
       Think! 2.2.1: Edge Detection
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
         Student Response
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-2-2-2-kernel-structure">
       Think! 2.2.2 Kernel structure
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
         Student Response
        </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-pooling-and-subsampling">
   Section 3: Pooling and Subsampling
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-pooling">
     Video 4: Pooling
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-emnist-dataset">
     Download EMNIST dataset
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#dataset-dataloader-functions-run-me">
     Dataset/DataLoader Functions
     <em>
      (Run me!)
     </em>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-visualization-of-convolution-with-multiple-filters">
     Interactive Demo 3: Visualization of Convolution with Multiple Filters
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-multiple-filters">
     Section 3.1: Multiple Filters
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-1-do-you-see-how-these-filters-would-help-recognize-an-x">
       Think! 3.1: Do you see how these filters would help recognize an
       <code class="docutils literal notranslate">
<span class="pre">
         X
        </span>
</code>
       ?
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
         Student Response
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-relu-after-convolutions">
     Section 3.2: ReLU after convolutions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-3-pooling">
     Section 3.3: Pooling
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-3-the-effect-of-the-stride">
       Interactive Demo 3.3: The effect of the stride
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-3-implement-maxpooling">
       Coding Exercise 3.3: Implement MaxPooling
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-putting-it-all-together">
   Section 4: Putting it all together
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-putting-it-all-together">
     Video 5: Putting it all together
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-number-of-parameters-in-convolutional-vs-fully-connected-models">
     Section 4.1: Number of Parameters in Convolutional vs. Fully-connected Models
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-1-number-of-parameters">
       Interactive Demo 4.1: Number of Parameters
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-implement-your-own-cnn">
         Video 6: Implement your own CNN
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-implement-your-own-cnn">
     Coding Exercise 4: Implement your own CNN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-test-functions-run-me">
       Train/Test Functions (Run Me)
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-write-your-own-training-loop-revisited">
   Bonus 1: Write your own training loop revisited
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-writing-your-own-training-loop">
     Video 7: Writing your own training loop
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-1-understand-the-dataset">
     Bonus 1.1: Understand the Dataset
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-fashion-mnist-dataset">
       Download Fashion MNIST dataset
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#loading-fashion-mnist-data">
       Loading Fashion-MNIST Data
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-the-training-loop">
       Video 8: The Training Loop
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-2-backpropagation-reminder">
     Bonus 1.2: Backpropagation Reminder
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-a-sample-dataset-emnist">
       Load a sample dataset (EMNIST)
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-3-fashion-mnist-dataset">
     Bonus 1.3: Fashion-MNIST dataset
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#getting-the-dataloaders-run-me">
       Getting the DataLoaders (Run Me)
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-bonus-1-code-the-training-loop">
     Coding Exercise Bonus 1: Code the training loop
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-1-overfitting">
     Think! Bonus 1: Overfitting
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-overfitting-symptoms-and-cures">
   Bonus 2: Overfitting - symptoms and cures
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-1-regularization">
     Bonus 2.1: Regularization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-bonus-2-1-adding-regularization">
       Coding Exercise Bonus 2.1: Adding Regularization
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-2-1-regularization">
       Think! Bonus 2.1: Regularization
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-bonus-2-1-dropout-exploration">
       Interactive Demo Bonus 2.1: Dropout exploration
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-bonus-2-2-how-much-does-augmentation-help">
       Coding Exercise Bonus 2.2: How much does augmentation help?
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-fashion-mnist-if-it-has-not-been-downloaded">
         Download Fashion-MNIST, if it has not been downloaded.
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-2-2-data-augmentation">
       Think! Bonus 2.2: Data Augmentation
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-1-introduction-to-cnns">
<h1>Tutorial 1: Introduction to CNNs<a class="headerlink" href="#tutorial-1-introduction-to-cnns" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 2, Day 2: Convnets and DL Thinking</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Dawn Estes McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi, Alona Fyshe</p>
<p><strong>Content reviewers:</strong> Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva, Bettina Hein, Kelson Shilling-Scrivo</p>
<p><strong>Content editors:</strong> Gagana B, Nina Kudryashova, Anmol Gupta, Xiaoxiong Lin, Spiros Chavlis</p>
<p><strong>Production editors:</strong> Alex Tran-Van-Minh, Gagana B, Spiros Chavlis</p>
<br/>
<p><em>Based on material from:</em> Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>At the end of this tutorial, we will be able to:</p>
<ul class="simple">
<li><p>Define what convolution is</p></li>
<li><p>Implement convolution as an operation</p></li>
</ul>
<p>In the Bonus materials of this tutorial, you will be able to:</p>
<ul class="simple">
<li><p>Train a CNN by writing your own train loop</p></li>
<li><p>Recognize the symptoms of overfitting and how to cure them</p></li>
</ul>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/s8xz5/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
<p>These are the slides for all videos in this tutorial. If you want to download locally the slides, click <a class="reference external" href="https://osf.io/s8xz5/download">here</a>.</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>Pillow<span class="w"> </span>--quiet
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/NeuromatchAcademy/evaltools<span class="w"> </span>--quiet

<span class="kn">from</span> <span class="nn">evaltools.airtable</span> <span class="kn">import</span> <span class="n">AirtableForm</span>
<span class="n">atform</span> <span class="o">=</span> <span class="n">AirtableForm</span><span class="p">(</span><span class="s1">'appn7VdPRseSoMXEG'</span><span class="p">,</span> <span class="s1">'W2D2_T1'</span><span class="p">,</span> <span class="s1">'https://portal.neuromatchacademy.org/api/redirect/to/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># Interactive display</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>
<span class="kn">from</span> <span class="nn">scipy.signal</span> <span class="kn">import</span> <span class="n">correlate2d</span>
<span class="kn">import</span> <span class="nn">zipfile</span><span class="o">,</span> <span class="nn">gzip</span><span class="o">,</span> <span class="nn">shutil</span><span class="o">,</span> <span class="nn">tarfile</span>


<span class="k">def</span> <span class="nf">download_data</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Data downloading from OSF.</span>

<span class="sd">  Args:</span>
<span class="sd">    fname : str</span>
<span class="sd">      The name of the archive</span>
<span class="sd">    folder : str</span>
<span class="sd">      The name of the destination folder</span>
<span class="sd">    url : str</span>
<span class="sd">      The download url</span>
<span class="sd">    tar : boolean</span>
<span class="sd">      `tar=True` the archive is `fname`.tar.gz, `tar=False` is `fname`.zip</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Downloading </span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1"> dataset...'</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
      <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Downloading </span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1"> completed.'</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Extracting the files...</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tar</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fz</span><span class="p">:</span>
        <span class="n">fz</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">ft</span><span class="p">:</span>
        <span class="n">ft</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
    <span class="c1"># Remove the archive</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

    <span class="c1"># Extract all .gz files</span>
    <span class="n">foldername</span> <span class="o">=</span> <span class="n">folder</span> <span class="o">+</span> <span class="s1">'/raw/'</span>
    <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">foldername</span><span class="p">):</span>
      <span class="c1"># Remove the extension</span>
      <span class="n">fname</span> <span class="o">=</span> <span class="n">filename</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'.gz'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
      <span class="c1"># Gunzip all files</span>
      <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">foldername</span> <span class="o">+</span> <span class="n">filename</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_in</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">foldername</span> <span class="o">+</span> <span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_out</span><span class="p">:</span>
          <span class="n">shutil</span><span class="o">.</span><span class="n">copyfileobj</span><span class="p">(</span><span class="n">f_in</span><span class="p">,</span> <span class="n">f_out</span><span class="p">)</span>
          <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">foldername</span><span class="o">+</span><span class="n">filename</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1"> dataset has already been downloaded.</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">check_shape_function</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to check shape implementation</span>

<span class="sd">  Args:</span>
<span class="sd">    func: f.__name__</span>
<span class="sd">      Function name</span>
<span class="sd">    image_shape: tuple</span>
<span class="sd">      Image shape</span>
<span class="sd">    kernel_shape: tuple</span>
<span class="sd">      Kernel shape</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">correct_shape</span> <span class="o">=</span> <span class="n">correlate2d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">image_shape</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">kernel_shape</span><span class="p">),</span> <span class="s2">"valid"</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">user_shape</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">correct_shape</span> <span class="o">!=</span> <span class="n">user_shape</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"❌ Your calculated output shape is not correct."</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"✅ Output for image_shape: </span><span class="si">{</span><span class="n">image_shape</span><span class="si">}</span><span class="s2"> and kernel_shape: </span><span class="si">{</span><span class="n">kernel_shape</span><span class="si">}</span><span class="s2">, output_shape: </span><span class="si">{</span><span class="n">user_shape</span><span class="si">}</span><span class="s2">, is correct."</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">check_conv_function</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to check conv_function</span>

<span class="sd">  Args:</span>
<span class="sd">    func: f.__name__</span>
<span class="sd">      Function name</span>
<span class="sd">    image: np.ndarray</span>
<span class="sd">      Image matrix</span>
<span class="sd">    kernel_shape: np.ndarray</span>
<span class="sd">      Kernel matrix</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">solution_user</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
  <span class="n">solution_scipy</span> <span class="o">=</span> <span class="n">correlate2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="s2">"valid"</span><span class="p">)</span>
  <span class="n">result_right</span> <span class="o">=</span> <span class="p">(</span><span class="n">solution_user</span> <span class="o">==</span> <span class="n">solution_scipy</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">result_right</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"✅ The function calculated the convolution correctly."</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"❌ The function did not produce the right output."</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"For the input matrix:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"and the kernel:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"the function returned:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">solution_user</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"the correct output would be:"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">solution_scipy</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">check_pooling_net</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to check pooling output</span>

<span class="sd">  Args:</span>
<span class="sd">    net: nn.module</span>
<span class="sd">      Net instance</span>
<span class="sd">    device: string</span>
<span class="sd">      GPU/CUDA if available, CPU otherwise.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">x_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">output_x</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x_img</span><span class="p">)</span>
  <span class="n">output_x</span> <span class="o">=</span> <span class="n">output_x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

  <span class="n">right_output</span> <span class="o">=</span> <span class="p">[</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">9.309552</span><span class="p">,</span> <span class="mf">1.6216984</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">2.2708383</span><span class="p">,</span>
      <span class="mf">2.6654134</span><span class="p">,</span> <span class="mf">1.2271233</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">12.873457</span><span class="p">,</span> <span class="mf">13.318945</span><span class="p">,</span> <span class="mf">9.46229</span><span class="p">,</span> <span class="mf">4.663746</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">1.8889914</span><span class="p">,</span>
      <span class="mf">0.31068993</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">8.354934</span><span class="p">,</span> <span class="mf">10.378724</span><span class="p">,</span> <span class="mf">16.882853</span><span class="p">,</span> <span class="mf">18.499334</span><span class="p">,</span> <span class="mf">4.8546696</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">6.29296</span><span class="p">,</span> <span class="mf">5.096506</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.31068993</span><span class="p">,</span> <span class="mf">5.7074604</span><span class="p">,</span> <span class="mf">9.984148</span><span class="p">,</span> <span class="mf">4.12916</span><span class="p">,</span> <span class="mf">8.10037</span><span class="p">,</span>
      <span class="mf">7.667609</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">1.2780352</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">2.436305</span><span class="p">,</span> <span class="mf">3.9764223</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">12.98801</span><span class="p">,</span>
      <span class="mf">17.1756</span><span class="p">,</span> <span class="mf">17.531992</span><span class="p">,</span> <span class="mf">11.664275</span><span class="p">,</span> <span class="mf">1.5453291</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">4.2691708</span><span class="p">,</span> <span class="mf">2.3217516</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">1.3798618</span><span class="p">,</span> <span class="mf">0.05612564</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">11.218788</span><span class="p">,</span> <span class="mf">16.360992</span><span class="p">,</span> <span class="mf">13.980816</span><span class="p">,</span> <span class="mf">8.354935</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">1.8126211</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">2.9199777</span><span class="p">,</span> <span class="mf">3.9382377</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">6.076582</span><span class="p">,</span> <span class="mf">10.035061</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.92164516</span><span class="p">,</span> <span class="mf">4.434638</span><span class="p">,</span> <span class="mf">0.7816348</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.83254766</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span>
      <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="mf">0.000000</span><span class="p">]</span>
  <span class="p">]</span>

  <span class="n">right_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">output_x</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">right_shape</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"❌ Your output does not have the right dimensions. Your output is </span><span class="si">{</span><span class="n">output_x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> the expected output is </span><span class="si">{</span><span class="n">right_shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="k">elif</span> <span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">right_output</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"❌ Your output is not right."</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"✅ Your network produced the correct output."</span><span class="p">)</span>


<span class="c1"># Just returns accuracy on test data</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Test function</span>

<span class="sd">  Args:</span>
<span class="sd">    net: nn.module</span>
<span class="sd">      Net instance</span>
<span class="sd">    device: string</span>
<span class="sd">      GPU/CUDA if available, CPU otherwise.</span>
<span class="sd">    data_loader: torch.loader</span>
<span class="sd">      Test loader</span>

<span class="sd">  Returns:</span>
<span class="sd">    acc: float</span>
<span class="sd">      Test accuracy</span>
<span class="sd">  """</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

  <span class="n">acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
  <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">acc</span><span class="si">}</span><span class="s2">%"</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting Functions</span>

<span class="k">def</span> <span class="nf">display_image_from_greyscale_array</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Display image from greyscale array</span>

<span class="sd">  Args:</span>
<span class="sd">    matrix: np.ndarray</span>
<span class="sd">      Image</span>
<span class="sd">    title: string</span>
<span class="sd">      Title of plot</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">_matrix</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
  <span class="n">_img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">_matrix</span><span class="p">,</span> <span class="s1">'L'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">255</span><span class="p">)</span> <span class="c1"># Using 220 instead of 255 so the examples show up better</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">make_plots</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">actual_convolution</span><span class="p">,</span> <span class="n">solution</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Function to build original image/obtained solution and actual convolution</span>

<span class="sd">  Args:</span>
<span class="sd">    original: np.ndarray</span>
<span class="sd">      Image</span>
<span class="sd">    actual_convolution: np.ndarray</span>
<span class="sd">      Expected convolution output</span>
<span class="sd">    solution: np.ndarray</span>
<span class="sd">      Obtained convolution output</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">display_image_from_greyscale_array</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s2">"Original Image"</span><span class="p">)</span>
  <span class="n">display_image_from_greyscale_array</span><span class="p">(</span><span class="n">actual_convolution</span><span class="p">,</span> <span class="s2">"Convolution result"</span><span class="p">)</span>
  <span class="n">display_image_from_greyscale_array</span><span class="p">(</span><span class="n">solution</span><span class="p">,</span> <span class="s2">"Your solution"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_loss_accuracy</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span>
                       <span class="n">validation_loss</span><span class="p">,</span> <span class="n">validation_acc</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Code to plot loss and accuracy</span>

<span class="sd">  Args:</span>
<span class="sd">    train_loss: list</span>
<span class="sd">      Log of training loss</span>
<span class="sd">    validation_loss: list</span>
<span class="sd">      Log of validation loss</span>
<span class="sd">    train_acc: list</span>
<span class="sd">      Log of training accuracy</span>
<span class="sd">    validation_acc: list</span>
<span class="sd">      Log of validation accuracy</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">epochs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
  <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)),</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)),</span> <span class="n">validation_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation Loss'</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Epoch vs Loss'</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)),</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Accuracy'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)),</span> <span class="n">validation_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Validation Accuracy'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Epoch vs Accuracy'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">15.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># For DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Function that controls randomness.</span>
<span class="sd">  NumPy and random modules must be imported.</span>

<span class="sd">  Args:</span>
<span class="sd">    seed : Integer</span>
<span class="sd">      A non-negative integer that defines the random state. Default is `None`.</span>
<span class="sd">    seed_torch : Boolean</span>
<span class="sd">      If `True` sets the random seed for pytorch tensors, so pytorch module</span>
<span class="sd">      must be imported. Default is `True`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  DataLoader will reseed workers following randomness in</span>
<span class="sd">  multi-process data loading algorithm.</span>

<span class="sd">  Args:</span>
<span class="sd">    worker_id: integer</span>
<span class="sd">      ID of subprocess to seed. 0 means that</span>
<span class="sd">      the data will be loaded in the main process</span>
<span class="sd">      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># Inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Set the device. CUDA if available, CPU otherwise</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-0-recap-the-experience-from-last-week">
<h1>Section 0: Recap the Experience from Last Week<a class="headerlink" href="#section-0-recap-the-experience-from-last-week" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~15mins</em></p>
<p>Last week you learned a lot!  Recall that overparametrized ANNs are efficient universal approximators, but also that ANNs can memorize our data.  However, regularization can help ANNs to better generalize. You were introduced to several regularization techniques such as <em>L1</em>, <em>L2</em>, <em>Data Augmentation</em>, and <em>Dropout</em>.</p>
<p>Today we’ll be talking about other ways to simplify ANNs, by making smart changes to their architecture.</p>
<div class="section" id="video-1-introduction-to-cnns-and-rnns">
<h2>Video 1: Introduction to CNNs and RNNs<a class="headerlink" href="#video-1-introduction-to-cnns-and-rnns" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2052e6bb5f0d4891be3131ef2c51bcd4"}
</script></div>
</div>
</div>
<div class="section" id="think-0-regularization-effective-number-of-params">
<h2>Think! 0: Regularization &amp; effective number of params<a class="headerlink" href="#think-0-regularization-effective-number-of-params" title="Permalink to this headline">¶</a></h2>
<p>Let’s think back to last week, when you learned about regularization.  Recall that regularization comes in several forms. For example, L1 regularization adds a term to the loss function that penalizes based on the sum of the <em>absolute</em> magnitude of the weights. Below are the results from training a simple multilayer perceptron with one hidden layer (b) on a simple toy dataset (a).</p>
<p>Below that are two graphics that show the effect of regularization on both the number of non-zero weights (d), and on the network’s accuracy (c).</p>
<p>What do you notice?</p>
<p><strong>Note</strong>: Dense layers are the same as fully-connected layers.  And pytorch calls them linear layers.  Confusing, but now you know!</p>
<figure>
<img src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/think0.png"/>
<figcaption><b>a.</b> The 2-dimensional inputs of class A (red) and B (green). <b>b.</b>The network architecture. Each Dense layer contains the (batch size, dimension), and below, the number of its trainable parameters. <b>c.</b>The train (blue) and validation (orange) accuracy as function of the regularization strength. <b>d.</b>The number of non-zero parameters as a function of the regularization strength.</figcaption>
</figure><div class="section" id="student-response">
<h3>Student Response<a class="headerlink" href="#student-response" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q1'</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "590cce13dfbc4c6db2f77f29f21a2184"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "225f956246e44546853c777a099c2bfd"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_18b18cac.py"><em>Click for solution</em></a></p>
<p><strong>Coming Up</strong></p>
<p>The rest of these lectures focus on another way to reduce parameters: weight-sharing. Weight-sharing is based on the idea that some sets of weights can be used at multiple points in a network. We will focus mostly on CNNs today, where the weight-sharing is across the 2D space of an image. At the end we will touch briefly on Recurrent Neural Networks (RNNs), which share parameters across time. Both of these weight-sharing techniques (across space and time) can reduce the number of parameters and increase a network’s ability to generalize.</p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-neuroscience-motivation-general-cnn-structure">
<h1>Section 1: Neuroscience motivation, General CNN structure<a class="headerlink" href="#section-1-neuroscience-motivation-general-cnn-structure" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~25mins</em></p>
<div class="section" id="video-2-representations-visual-processing-in-the-brain">
<h2>Video 2: Representations &amp; Visual processing in the brain<a class="headerlink" href="#video-2-representations-visual-processing-in-the-brain" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "c836ab1de3984de6812842e1c9adf9f8"}
</script></div>
</div>
</div>
<div class="section" id="think-1-what-makes-a-representation-good">
<h2>Think! 1: What makes a representation good?<a class="headerlink" href="#think-1-what-makes-a-representation-good" title="Permalink to this headline">¶</a></h2>
<p>Representations have a long and storied history, having been studied by the likes of Aristotle back in 300 BC! Representations are not a new idea, and they certainly don’t exist just in neural networks.</p>
<p>Take a moment with your pod to discuss what would make a good representation, and how that might differ depending on the task you train your CNN to do.</p>
<p>If there’s time, you can also consider how the brain’s representations might differ from a <em>learned</em> representation inside a NN.</p>
<div class="section" id="id1">
<h3>Student Response<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q2'</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "e435ea6165914bd6b82defae61ba4cd5"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "b4f4114bda2a455792df1751fcc6041e"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_82e644f4.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-convolutions-and-edge-detection">
<h1>Section 2: Convolutions and Edge Detection<a class="headerlink" href="#section-2-convolutions-and-edge-detection" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~25mins</em></p>
<p>Fundamental to CNNs are convolutions. After all, that is what the <strong>C</strong> in CNN stands for! In this section, we will define what a convolution is, practice performing a convolution, and implement it in code.</p>
<div class="section" id="video-3-details-about-convolution">
<h2>Video 3: Details about Convolution<a class="headerlink" href="#video-3-details-about-convolution" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "681fd5cb87c1464e90cdc8b8e909aadb"}
</script></div>
</div>
<p>Before jumping into coding exercises, take a moment to look at this animation that steps through the process of convolution.</p>
<p>Recall from the video that convolution involves sliding the kernel across the image, taking the element-wise product, and adding those products together.</p>
<img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/correlation.svg" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/correlation.svg"><p>Adopted from A. Zhang, Z. C. Lipton, M. Li and A. J. Smola, <em><a class="reference external" href="http://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html">Dive into Deep Learning</a></em>.</p>
<br/>
<p><strong>Note:</strong> You need to run the cell to activate the sliders, and again to run once changing the sliders.</p>
<p><strong>Tip:</strong> In this animation, and all the ones that follow, you can hover over the parts of the code underlined in red to change them.</p>
<p><strong>Tip:</strong> Below, the function is called <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> because the convolutional filter is a matrix with two dimensions (2D).  There are also 1D and 3D convolutions, but we won’t talk about them today.</p>
<div class="section" id="interactive-demo-2-visualization-of-convolution">
<h3>Interactive Demo 2: Visualization of Convolution<a class="headerlink" href="#interactive-demo-2-visualization-of-convolution" title="Permalink to this headline">¶</a></h3>
<p><strong>Important:</strong> Change the bool variable <code class="docutils literal notranslate"><span class="pre">run_demo</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution.</p>
<p><em>Run this cell to enable the widget!</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run this cell to enable the widget!*</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">id_html</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo</span><span class="si">{</span><span class="n">id_html</span><span class="si">}</span><span class="s1">.html'</span>
<span class="n">run_demo</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># @param {type:"boolean"}</span>
<span class="k">if</span> <span class="n">run_demo</span><span class="p">:</span>
  <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="definitional-note">
<h4>Definitional Note<a class="headerlink" href="#definitional-note" title="Permalink to this headline">¶</a></h4>
<p>If you have a background in signal processing or math, you may have already heard of convolution. However, the definitions in other domains and the one we use here are slightly different. The more common definition involves flipping the kernel horizontally and vertically before sliding.</p>
<p><strong>For our purposes, no flipping is needed. If you are familiar with conventions involving flipping, just assume the kernel is pre-flipped.</strong></p>
<p>In more general usage, the no-flip operation that we call convolution is known as <em>cross-correlation</em> (hence the usage of <code class="docutils literal notranslate"><span class="pre">scipy.signal.correlate2d</span></code> in the next exercise). Early papers used the more common definition of convolution, but not using a flip is easier to visualize, and in fact the lack of flip does not impact a CNN’s ability to learn.</p>
</div>
</div>
</img></div>
<div class="section" id="coding-exercise-2-1-convolution-of-a-simple-kernel">
<h2>Coding Exercise 2.1: Convolution of a Simple Kernel<a class="headerlink" href="#coding-exercise-2-1-convolution-of-a-simple-kernel" title="Permalink to this headline">¶</a></h2>
<p>At its core, convolution is just repeatedly multiplying a matrix, known as a <em>kernel</em> or <em>filter</em>, with some other, larger matrix (in our case the pixels of an image). Consider the below image and kernel:</p>
<div class="amsmath math notranslate nohighlight" id="equation-fe0fe920-9ede-4d76-888c-22d0bba382cd">
<span class="eqno">(65)<a class="headerlink" href="#equation-fe0fe920-9ede-4d76-888c-22d0bba382cd" title="Permalink to this equation">¶</a></span>\[\begin{align}
\textbf{Image} &amp;= 
\begin{bmatrix}0 &amp; 200 &amp; 200 \\0 &amp; 0 &amp; 200 \\ 0 &amp; 0 &amp; 0  
\end{bmatrix} \\ \\
\textbf{Kernel} &amp;= 
\begin{bmatrix} \frac{1}{4} &amp;\frac{1}{4} \\\frac{1}{4} &amp; \frac{1}{4}
\end{bmatrix} 
\end{align}\]</div>
<p>Perform (by hand) the operations needed to convolve the kernel and image above. Afterwards enter your results in the “solution” section in the code below. Think about what this specific kernel is doing to the original image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv_check</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Demonstration of convolution operation</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    original: np.ndarray</span>
<span class="sd">      Image</span>
<span class="sd">    actual_convolution: np.ndarray</span>
<span class="sd">      Expected convolution output</span>
<span class="sd">    solution: np.ndarray</span>
<span class="sd">      Obtained convolution output</span>
<span class="sd">    kernel: np.ndarray</span>
<span class="sd">      Kernel</span>
<span class="sd">  """</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in missing code below (the elements of the matrix),</span>
  <span class="c1"># then remove or comment the line below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Fill in the solution matrix, then delete this"</span><span class="p">)</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Write the solution array and call the function to verify it!</span>
  <span class="n">solution</span> <span class="o">=</span> <span class="o">...</span>

  <span class="n">original</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
                       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
                       <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                       <span class="p">])</span>

  <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
                     <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span>
                     <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]</span>
                     <span class="p">])</span>

  <span class="n">actual_convolution</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">correlate2d</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"valid"</span><span class="p">)</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">solution</span> <span class="o">==</span> <span class="n">actual_convolution</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"✅ Your solution is correct!</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"❌ Your solution is incorrect.</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">original</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">actual_convolution</span><span class="p">,</span> <span class="n">solution</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 2.1: Convolution of a Simple Kernel'</span><span class="p">)</span>

<span class="c1">## Uncomment to test your solution!</span>
<span class="c1"># original, kernel, actual_convolution, solution = conv_check()</span>
<span class="c1"># make_plots(original, actual_convolution, solution)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_6180cf74.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_6180cf74_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_6180cf74_1.png" style="width: 363.0px; height: 396.0px;"/></a>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_6180cf74_2.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_6180cf74_2.png" style="width: 391.0px; height: 396.0px;"/></a>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_6180cf74_3.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_6180cf74_3.png" style="width: 363.0px; height: 396.0px;"/></a>
</div>
<div class="section" id="coding-exercise-2-2-convolution-output-size">
<h2>Coding Exercise 2.2: Convolution Output Size<a class="headerlink" href="#coding-exercise-2-2-convolution-output-size" title="Permalink to this headline">¶</a></h2>
<p>Now, you have manually calculated a convolution. How did this change the shape of the output? When you know the shapes of the input matrix and kernel, what is the shape of the output?</p>
<p><strong>Hint:</strong> If you have problems figuring out what the output shape should look like, go back to the visualisation and see how the output shape changes as you modify the image and kernel size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_output_shape</span><span class="p">(</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to calculate output shape</span>

<span class="sd">  Args:</span>
<span class="sd">    image_shape: tuple</span>
<span class="sd">      Image shape</span>
<span class="sd">    kernel_shape: tuple</span>
<span class="sd">      Kernel shape</span>

<span class="sd">  Returns:</span>
<span class="sd">    output_height: int</span>
<span class="sd">      Output Height</span>
<span class="sd">    output_width: int</span>
<span class="sd">      Output Width</span>
<span class="sd">  """</span>
  <span class="n">image_height</span><span class="p">,</span> <span class="n">image_width</span> <span class="o">=</span> <span class="n">image_shape</span>
  <span class="n">kernel_height</span><span class="p">,</span> <span class="n">kernel_width</span> <span class="o">=</span> <span class="n">kernel_shape</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in missing code below, then remove or comment the line below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Fill in the lines below, then delete this"</span><span class="p">)</span>
  <span class="c1">####################################################################</span>
  <span class="n">output_height</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">output_width</span> <span class="o">=</span> <span class="o">...</span>
  <span class="k">return</span> <span class="n">output_height</span><span class="p">,</span> <span class="n">output_width</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 2.2: Convolution Output Size'</span><span class="p">)</span>

<span class="c1"># Here we check if your function works correcly by applying it to different image</span>
<span class="c1"># and kernel shapes</span>
<span class="c1"># check_shape_function(calculate_output_shape, image_shape=(3, 3), kernel_shape=(2, 2))</span>
<span class="c1"># check_shape_function(calculate_output_shape, image_shape=(3, 4), kernel_shape=(2, 3))</span>
<span class="c1"># check_shape_function(calculate_output_shape, image_shape=(5, 5), kernel_shape=(5, 5))</span>
<span class="c1"># check_shape_function(calculate_output_shape, image_shape=(10, 20), kernel_shape=(3, 2))</span>
<span class="c1"># check_shape_function(calculate_output_shape, image_shape=(100, 200), kernel_shape=(40, 30))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_d1644130.py"><em>Click for solution</em></a></p>
</div>
<div class="section" id="coding-exercise-2-3-coding-a-convolution">
<h2>Coding Exercise 2.3: Coding a Convolution<a class="headerlink" href="#coding-exercise-2-3-coding-a-convolution" title="Permalink to this headline">¶</a></h2>
<p>Here, we have the skeleton of a function that performs convolution using the provided image and kernel matrices.</p>
<p><em>Exercise:</em> Fill in the missing lines of code. You can test your function by uncommenting the sections beneath it.</p>
<p>Note: in more general situations, once you understand convolutions, you can use functions already available in <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>/<code class="docutils literal notranslate"><span class="pre">numpy</span></code> to perform convolution (such as <code class="docutils literal notranslate"><span class="pre">scipy.signal.correlate2d</span></code> or <code class="docutils literal notranslate"><span class="pre">scipy.signal.convolve2d</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convolution2d</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Convolves a 2D image matrix with a kernel matrix.</span>

<span class="sd">  Args:</span>
<span class="sd">    image: np.ndarray</span>
<span class="sd">      Image</span>
<span class="sd">    kernel: np.ndarray</span>
<span class="sd">      Kernel</span>

<span class="sd">  Returns:</span>
<span class="sd">    output: np.ndarray</span>
<span class="sd">      Output of convolution</span>
<span class="sd">  """</span>

  <span class="c1"># Get the height/width of the image, kernel, and output</span>
  <span class="n">im_h</span><span class="p">,</span> <span class="n">im_w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">ker_h</span><span class="p">,</span> <span class="n">ker_w</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">out_h</span> <span class="o">=</span> <span class="n">im_h</span> <span class="o">-</span> <span class="n">ker_h</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="n">out_w</span> <span class="o">=</span> <span class="n">im_w</span> <span class="o">-</span> <span class="n">ker_w</span> <span class="o">+</span> <span class="mi">1</span>

  <span class="c1"># Create an empty matrix in which to store the output</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">out_h</span><span class="p">,</span> <span class="n">out_w</span><span class="p">))</span>

  <span class="c1"># Iterate over the different positions at which to apply the kernel,</span>
  <span class="c1"># storing the results in the output matrix</span>
  <span class="k">for</span> <span class="n">out_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_h</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">out_col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_w</span><span class="p">):</span>
      <span class="c1"># Overlay the kernel on part of the image</span>
      <span class="c1"># (multiply each element of the kernel with some element of the image, then sum)</span>
      <span class="c1"># to determine the output of the matrix at a point</span>
      <span class="n">current_product</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ker_h</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ker_w</span><span class="p">):</span>
          <span class="c1">####################################################################</span>
          <span class="c1"># Fill in missing code below (...),</span>
          <span class="c1"># then remove or comment the line below to test your function</span>
          <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Implement the convolution function"</span><span class="p">)</span>
          <span class="c1">####################################################################</span>
          <span class="n">current_product</span> <span class="o">+=</span> <span class="o">...</span>

      <span class="n">output</span><span class="p">[</span><span class="n">out_row</span><span class="p">,</span> <span class="n">out_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">current_product</span>

  <span class="k">return</span> <span class="n">output</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 2.3: Coding a Convolution'</span><span class="p">)</span>

<span class="c1">## Tests</span>
<span class="c1"># First, we test the parameters we used before in the manual-calculation example</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">]])</span>
<span class="c1"># check_conv_function(convolution2d, image, kernel)</span>

<span class="c1"># Next, we test with a different input and kernel (the numbers 1-9 and 1-4)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="c1"># check_conv_function(convolution2d, image, kernel)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_a39b0fea.py"><em>Click for solution</em></a></p>
<div class="section" id="convolution-on-the-chicago-skyline">
<h3>Convolution on the Chicago Skyline<a class="headerlink" href="#convolution-on-the-chicago-skyline" title="Permalink to this headline">¶</a></h3>
<p>After you have finished programming the above convolution function, run the coding cell below, which applies two different kernels to a greyscale picture of Chicago and takes the geometric average of the results.</p>
<p><strong>Make sure you remove all print statements from your convolution2d implementation, or this will run for a <em>very</em> long time.</strong> It should take somewhere between 10 seconds and 1 minute.</p>
</div>
<div class="section" id="load-images-run-me">
<h3>Load images (run me)<a class="headerlink" href="#load-images-run-me" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown ### Load images (run me)</span>

<span class="kn">import</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">os</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">'images/'</span><span class="p">):</span>
  <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">'images/'</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/chicago_skyline_shrunk_v2.bmp"</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"images/chicago_skyline_shrunk_v2.bmp"</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fd</span><span class="p">:</span>
  <span class="n">fd</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize the output of your function</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPydisplay</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"images/chicago_skyline_shrunk_v2.bmp"</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">skyline_image_file</span><span class="p">:</span>
  <span class="n">img_skyline_orig</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">skyline_image_file</span><span class="p">)</span>
  <span class="n">img_skyline_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img_skyline_orig</span><span class="p">)</span>
  <span class="n">kernel_ver</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
  <span class="n">kernel_hor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
  <span class="n">img_processed_mat_ver</span> <span class="o">=</span> <span class="n">convolution2d</span><span class="p">(</span><span class="n">img_skyline_mat</span><span class="p">,</span> <span class="n">kernel_ver</span><span class="p">)</span>
  <span class="n">img_processed_mat_hor</span> <span class="o">=</span> <span class="n">convolution2d</span><span class="p">(</span><span class="n">img_skyline_mat</span><span class="p">,</span> <span class="n">kernel_hor</span><span class="p">)</span>
  <span class="n">img_processed_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">img_processed_mat_ver</span><span class="p">,</span>
                                          <span class="n">img_processed_mat_ver</span><span class="p">)</span> <span class="o">+</span> \
                              <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">img_processed_mat_hor</span><span class="p">,</span>
                                          <span class="n">img_processed_mat_hor</span><span class="p">))</span>

  <span class="n">img_processed_mat</span> <span class="o">*=</span> <span class="mf">255.0</span><span class="o">/</span><span class="n">img_processed_mat</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
  <span class="n">img_processed_mat</span> <span class="o">=</span> <span class="n">img_processed_mat</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
  <span class="n">img_processed</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">img_processed_mat</span><span class="p">,</span> <span class="s1">'L'</span><span class="p">)</span>
  <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">img_skyline_orig</span><span class="o">.</span><span class="n">size</span>
  <span class="n">scale</span> <span class="o">=</span> <span class="mf">0.6</span>
  <span class="n">IPydisplay</span><span class="p">(</span><span class="n">img_skyline_orig</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">width</span><span class="o">*</span><span class="n">scale</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">height</span><span class="o">*</span><span class="n">scale</span><span class="p">))),</span>
             <span class="n">Image</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">)</span>
  <span class="n">IPydisplay</span><span class="p">(</span><span class="n">img_processed</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">width</span><span class="o">*</span><span class="n">scale</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">height</span><span class="o">*</span><span class="n">scale</span><span class="p">))),</span>
             <span class="n">Image</span><span class="o">.</span><span class="n">NEAREST</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<p>Pretty cool, right? We will go into more detail on what’s happening in the next section.</p>
</div>
</div>
<div class="section" id="section-2-1-demonstration-of-a-cnn-in-pytorch">
<h2>Section 2.1: Demonstration of a CNN in PyTorch<a class="headerlink" href="#section-2-1-demonstration-of-a-cnn-in-pytorch" title="Permalink to this headline">¶</a></h2>
<p>At this point, you should have a fair idea of how to perform a convolution on an image given a kernel. In the following cell, we provide a code snippet that demonstrates setting up a convolutional network using PyTorch.</p>
<p>We look at the <code class="docutils literal notranslate"><span class="pre">nn</span></code> module in PyTorch. The <code class="docutils literal notranslate"><span class="pre">nn</span></code> module contains a plethora of functions that will make implementing a neural network easier. In particular we will look at the <code class="docutils literal notranslate"><span class="pre">nn.Conv2d()</span></code> function, which creates a convolutional layer that is applied to whatever image that you feed the resulting network.</p>
<p>Look at the code below. In it, we define a <code class="docutils literal notranslate"><span class="pre">Net</span></code> class that you can instantiate with a kernel to create a Neural Network object. When you apply the network object to an image (or anything in the form of a matrix), it convolves the kernel over that image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  A convolutional neural network class.</span>
<span class="sd">  When an instance of it is constructed with a kernel, you can apply that instance</span>
<span class="sd">    to a matrix and it will convolve the kernel over that image.</span>
<span class="sd">  i.e. Net(kernel)(image)</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Summary of the nn.conv2d parameters (you can also get this by hovering</span>
<span class="sd">    over the method):</span>
<span class="sd">    - in_channels (int): Number of channels in the input image</span>
<span class="sd">    - out_channels (int): Number of channels produced by the convolution</span>
<span class="sd">    - kernel_size (int or tuple): Size of the convolving kernel</span>

<span class="sd">    Args:</span>
<span class="sd">      padding: int or tuple, optional</span>
<span class="sd">        Zero-padding added to both sides of the input. Default: 0</span>
<span class="sd">      kernel: np.ndarray</span>
<span class="sd">        Convolving kernel. Default: None</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>

    <span class="c1"># Set up a default kernel if a default one isn't provided</span>
    <span class="k">if</span> <span class="n">kernel</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">kernel</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward Pass of nn.conv2d</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Convolution output</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Format a default 2x2 kernel of numbers from 0 through 3</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="c1"># Prepare the network with that default kernel</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># Set up a 3x3 image matrix of numbers from 0 through 8</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>  <span class="c1"># BatchSize X Channels X Height X Width</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Image:</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Kernel:</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">kernel</span><span class="p">))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># Apply the convolution</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output:</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Image:
tensor([[[[0., 1., 2.],
          [3., 4., 5.],
          [6., 7., 8.]]]])
Kernel:
tensor([[0., 1.],
        [2., 3.]])
Output:
tensor([[[[19., 25.],
          [37., 43.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>As a quick aside, notice the difference in the input and output size. The input had a size of 3×3, and the output is of size 2×2. This is because of the fact that the kernel can’t produce values for the edges of the image - when it slides to an end of the image and is centered on a border pixel, it overlaps space outside of the image that is undefined. If we don’t want to lose that information, we will have to pad the image with some defaults (such as 0s) on the border. This process is, somewhat predictably, called <em>padding</em>. We will talk more about padding in the next section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Image (before padding):</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Kernel:</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">kernel</span><span class="p">))</span>

<span class="c1"># Prepare the network with the aforementioned default kernel, but this</span>
<span class="c1"># time with padding</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># Apply the convolution onto the padded image</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Output:</span><span class="se">\n</span><span class="s2">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Image (before padding):
tensor([[[[0., 1., 2.],
          [3., 4., 5.],
          [6., 7., 8.]]]])
Kernel:
tensor([[0., 1.],
        [2., 3.]])
Output:
tensor([[[[ 0.,  3.,  8.,  4.],
          [ 9., 19., 25., 10.],
          [21., 37., 43., 16.],
          [ 6.,  7.,  8.,  0.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-2-padding-and-edge-detection">
<h2>Section 2.2: Padding and Edge Detection<a class="headerlink" href="#section-2-2-padding-and-edge-detection" title="Permalink to this headline">¶</a></h2>
<p>Before we start in on the exercises, here’s a visualization to help you think about padding.</p>
<div class="section" id="interactive-demo-2-2-visualization-of-convolution-with-padding-and-stride">
<h3>Interactive Demo 2.2: Visualization of Convolution with Padding and Stride<a class="headerlink" href="#interactive-demo-2-2-visualization-of-convolution-with-padding-and-stride" title="Permalink to this headline">¶</a></h3>
<p>Recall that</p>
<ul class="simple">
<li><p>Padding adds rows and columns of zeros to the outside edge of an image</p></li>
<li><p>Stride length adjusts the distance by which a filter is shifted after each convolution.</p></li>
</ul>
<p>Change the padding and stride and see how this affects the shape of the output. How does the padding need to be configured to maintain the shape of the input?</p>
<p><strong>Important:</strong> Change the bool variable <code class="docutils literal notranslate"><span class="pre">run_demo</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution.</p>
<p><em>Run this cell to enable the widget!</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run this cell to enable the widget!*</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">id_html</span> <span class="o">=</span> <span class="mf">2.2</span>
<span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo</span><span class="si">{</span><span class="n">id_html</span><span class="si">}</span><span class="s1">.html'</span>
<span class="n">run_demo</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># @param {type:"boolean"}</span>
<span class="k">if</span> <span class="n">run_demo</span><span class="p">:</span>
  <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="think-2-2-1-edge-detection">
<h3>Think! 2.2.1: Edge Detection<a class="headerlink" href="#think-2-2-1-edge-detection" title="Permalink to this headline">¶</a></h3>
<p>One of the simpler tasks performed by a convolutional layer is edge detection; that is, finding a place in the image where there is a large and abrupt change in color. Edge-detecting filters are usually learned by the first layers in a CNN. Observe the following simple kernel and discuss whether this will detect vertical edges (where the trace of the edge is vertical; i.e. there is a boundary between left and right), or whether it will detect horizontal edges (where the trace of the edge is horizontal; i.e., there is a boundary between top and bottom).</p>
<div class="amsmath math notranslate nohighlight" id="equation-d1f9527e-261b-4d68-b566-9f5461bfdbc4">
<span class="eqno">(66)<a class="headerlink" href="#equation-d1f9527e-261b-4d68-b566-9f5461bfdbc4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\textbf{Kernel} = 
\begin{bmatrix} 1 &amp; -1 \\ 1 &amp; -1
\end{bmatrix} 
\end{equation}\]</div>
<div class="section" id="id2">
<h4>Student Response<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q3'</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2e328af309f141bc9138a08393c14bd2"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "b1136526dc88446185cea678842f9dd3"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_309474b2.py"><em>Click for solution</em></a></p>
<p>Consider the image below, which has a black vertical stripe with white on the side. This is like a very zoomed-in vertical edge within an image!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Prepare an image that's basically just a vertical black stripe</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[1. 1. 0. 0. 0. 0. 1. 1.]
 [1. 1. 0. 0. 0. 0. 1. 1.]
 [1. 1. 0. 0. 0. 0. 1. 1.]
 [1. 1. 0. 0. 0. 0. 1. 1.]
 [1. 1. 0. 0. 0. 0. 1. 1.]
 [1. 1. 0. 0. 0. 0. 1. 1.]]
</pre></div>
</div>
<img alt="../../../_images/W2D2_Tutorial1_81_1.png" src="../../../_images/W2D2_Tutorial1_81_1.png"/>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Format the image that's basically just a vertical stripe</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="c1"># BatchSize X Channels X Height X Width</span>

<span class="c1"># Prepare a 2x2 kernel with 1s in the first column and -1s in the</span>
<span class="c1"># This exact kernel was discussed above!</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">]])</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">)</span>

<span class="c1"># Apply the kernel to the image and prepare for display</span>
<span class="n">processed_image</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">processed_image</span> <span class="o">=</span> <span class="n">processed_image</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">processed_image</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">processed_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[ 0.  2.  0.  0.  0. -2.  0.]
 [ 0.  2.  0.  0.  0. -2.  0.]
 [ 0.  2.  0.  0.  0. -2.  0.]
 [ 0.  2.  0.  0.  0. -2.  0.]
 [ 0.  2.  0.  0.  0. -2.  0.]]
</pre></div>
</div>
<img alt="../../../_images/W2D2_Tutorial1_82_1.png" src="../../../_images/W2D2_Tutorial1_82_1.png"/>
</div>
</div>
<p>As you can see, this kernel detects vertical edges (the black stripe corresponds to a highly positive result, while the white stripe corresponds to a highly negative result. However, to display the image, all the pixels are normalized between 0=black and 1=white).</p>
</div>
</div>
<div class="section" id="think-2-2-2-kernel-structure">
<h3>Think! 2.2.2 Kernel structure<a class="headerlink" href="#think-2-2-2-kernel-structure" title="Permalink to this headline">¶</a></h3>
<p>If the kernel were transposed (i.e., the columns become rows and the rows become columns), what would the kernel detect? What would be produced by running this kernel on the vertical edge image above?</p>
<div class="section" id="id3">
<h4>Student Response<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q4'</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "6d36c9a336a2474480ab4b1d78a5e27d"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "1d4e81934cd34aee930f9aaca51d91b1"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_7cc3340b.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-pooling-and-subsampling">
<h1>Section 3: Pooling and Subsampling<a class="headerlink" href="#section-3-pooling-and-subsampling" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~50mins</em></p>
<div class="section" id="video-4-pooling">
<h2>Video 4: Pooling<a class="headerlink" href="#video-4-pooling" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "fefdff2e58334aa2b79fdd2bbbf6291f"}
</script></div>
</div>
<p>To visualize the various components of a CNN, we will build a simple CNN step by step. Recall that the MNIST dataset consists of binarized images of handwritten digits. This time, we will use the EMNIST letters dataset, which consists of binarized images of handwritten characters <span class="math notranslate nohighlight">\((A, ..., Z)\)</span>.</p>
<p>We will simplify the problem further by only keeping the images that correspond to <span class="math notranslate nohighlight">\(X\)</span> (labeled as <code class="docutils literal notranslate"><span class="pre">24</span></code> in the dataset) and <span class="math notranslate nohighlight">\(O\)</span> (labeled as <code class="docutils literal notranslate"><span class="pre">15</span></code> in the dataset). Then, we will train a CNN to classify an image either an <span class="math notranslate nohighlight">\(X\)</span> or an <span class="math notranslate nohighlight">\(O\)</span>.</p>
</div>
<div class="section" id="download-emnist-dataset">
<h2>Download EMNIST dataset<a class="headerlink" href="#download-emnist-dataset" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">,,</span><span class="c1"># @title Download EMNIST dataset</span>

<span class="c1"># webpage: https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s1">'EMNIST.zip'</span>
<span class="n">folder</span> <span class="o">=</span> <span class="s1">'EMNIST'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/xwfaj/download"</span>
<span class="n">download_data</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">tar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading EMNIST dataset...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading EMNIST completed.

Extracting the files...
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dataset-dataloader-functions-run-me">
<h2>Dataset/DataLoader Functions <em>(Run me!)</em><a class="headerlink" href="#dataset-dataloader-functions-run-me" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Dataset/DataLoader Functions *(Run me!)*</span>

<span class="k">def</span> <span class="nf">get_Xvs0_dataset</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Load Dataset</span>

<span class="sd">  Args:</span>
<span class="sd">    normalize: boolean</span>
<span class="sd">      If true, normalise dataloader</span>
<span class="sd">    download: boolean</span>
<span class="sd">      If true, download dataset</span>

<span class="sd">  Returns:</span>
<span class="sd">    emnist_train: torch.loader</span>
<span class="sd">      Training Data</span>
<span class="sd">    emnist_test: torch.loader</span>
<span class="sd">      Test Data</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
        <span class="p">])</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="p">])</span>

  <span class="n">emnist_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">EMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span>
                                 <span class="n">split</span><span class="o">=</span><span class="s1">'letters'</span><span class="p">,</span>
                                 <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                                 <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
  <span class="n">emnist_test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">EMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span>
                                <span class="n">split</span><span class="o">=</span><span class="s1">'letters'</span><span class="p">,</span>
                                <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                                <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

  <span class="c1"># Only want O (15) and X (24) labels</span>
  <span class="n">train_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">emnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">15</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">emnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">24</span><span class="p">)</span>
  <span class="n">emnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
  <span class="n">emnist_train</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>

  <span class="c1"># Convert Xs predictions to 1, Os predictions to 0</span>
  <span class="n">emnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="p">(</span><span class="n">emnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

  <span class="n">test_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">emnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">15</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">emnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">24</span><span class="p">)</span>
  <span class="n">emnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">emnist_test</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
  <span class="n">emnist_test</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">emnist_test</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

  <span class="c1"># Convert Xs predictions to 1, Os predictions to 0</span>
  <span class="n">emnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="p">(</span><span class="n">emnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">24</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">emnist_train</span><span class="p">,</span> <span class="n">emnist_test</span>


<span class="k">def</span> <span class="nf">get_data_loaders</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">,</span>
                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to fetch dataloaders</span>

<span class="sd">  Args:</span>
<span class="sd">    train_dataset: torch.tensor</span>
<span class="sd">      Training data</span>
<span class="sd">    test_dataset: torch.tensor</span>
<span class="sd">      Test data</span>
<span class="sd">    batch_size: int</span>
<span class="sd">      Batch Size</span>
<span class="sd">    seed: int</span>
<span class="sd">      Set seed for reproducibility</span>

<span class="sd">  Returns:</span>
<span class="sd">    emnist_train: torch.loader</span>
<span class="sd">      Training Data</span>
<span class="sd">    emnist_test: torch.loader</span>
<span class="sd">      Test Data</span>
<span class="sd">  """</span>
  <span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
  <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

  <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                            <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
  <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span>
                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                           <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                           <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">emnist_train</span><span class="p">,</span> <span class="n">emnist_test</span> <span class="o">=</span> <span class="n">get_Xvs0_dataset</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_data_loaders</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">,</span> <span class="n">emnist_test</span><span class="p">,</span>
                                             <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Index of an image in the dataset that corresponds to an X and O</span>
<span class="n">x_img_idx</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">o_img_idx</span> <span class="o">=</span> <span class="mi">15</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s view a couple samples from the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="mi">10</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="mi">4</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="mi">6</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D2_Tutorial1_98_0.png" src="../../../_images/W2D2_Tutorial1_98_0.png"/>
</div>
</div>
</div>
<div class="section" id="interactive-demo-3-visualization-of-convolution-with-multiple-filters">
<h2>Interactive Demo 3: Visualization of Convolution with Multiple Filters<a class="headerlink" href="#interactive-demo-3-visualization-of-convolution-with-multiple-filters" title="Permalink to this headline">¶</a></h2>
<p>Change the number of input channels (e.g., the color channels of an image or the output channels of a previous layer) and the output channels (number of different filters to apply).</p>
<p><strong>Important:</strong> Change the bool variable <code class="docutils literal notranslate"><span class="pre">run_demo</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution.</p>
<p><em>Run this cell to enable the widget!</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run this cell to enable the widget!*</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">id_html</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo</span><span class="si">{</span><span class="n">id_html</span><span class="si">}</span><span class="s1">.html'</span>
<span class="n">run_demo</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># @param {type:"boolean"}</span>
<span class="k">if</span> <span class="n">run_demo</span><span class="p">:</span>
  <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-1-multiple-filters">
<h2>Section 3.1: Multiple Filters<a class="headerlink" href="#section-3-1-multiple-filters" title="Permalink to this headline">¶</a></h2>
<p>The following network sets up 3 filters and runs them on an image of the dataset from the <span class="math notranslate nohighlight">\(X\)</span> class. Note that we are using “thicker” filters than those presented in the videos. Here, the filters are <span class="math notranslate nohighlight">\(5 \times 5\)</span>, whereas in the videos <span class="math notranslate nohighlight">\(3 \times 3\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Neural Network instance</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize parameters of Net2</span>

<span class="sd">    Args:</span>
<span class="sd">      padding: int or tuple, optional</span>
<span class="sd">        Zero-padding added to both sides of the input. Default: 0</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>

    <span class="c1"># First kernel - leading diagonal</span>
    <span class="n">kernel_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span>

    <span class="c1"># Second kernel - other diagonal</span>
    <span class="n">kernel_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]])</span>

    <span class="c1"># tThird kernel - checkerboard pattern</span>
    <span class="n">kernel_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span>


    <span class="c1"># Stack all kernels in one tensor with (3, 1, 5, 5) dimensions</span>
    <span class="n">multiple_kernels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">kernel_1</span><span class="p">,</span> <span class="n">kernel_2</span><span class="p">,</span> <span class="n">kernel_3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">multiple_kernels</span><span class="p">)</span>

    <span class="c1"># Negative bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">]))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward Pass of Net2</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Convolution output</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Note:</strong> We add a negative bias to give a threshold to select the high output value, which corresponds to the features we want to detect (e.g., 45 degree oriented bar).</p>
<p>Now, let’s visualize the filters using the code given below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net2</span> <span class="o">=</span> <span class="n">Net2</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax11</span><span class="p">,</span> <span class="n">ax12</span><span class="p">,</span> <span class="n">ax13</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="c1"># Show the filters</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1"</span><span class="p">)</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net2</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net2</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net2</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.image.AxesImage at 0x7f7e3cb3f110&gt;
</pre></div>
</div>
<img alt="../../../_images/W2D2_Tutorial1_106_1.png" src="../../../_images/W2D2_Tutorial1_106_1.png"/>
</div>
</div>
<div class="section" id="think-3-1-do-you-see-how-these-filters-would-help-recognize-an-x">
<h3>Think! 3.1: Do you see how these filters would help recognize an <code class="docutils literal notranslate"><span class="pre">X</span></code>?<a class="headerlink" href="#think-3-1-do-you-see-how-these-filters-would-help-recognize-an-x" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id4">
<h4>Student Response<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q5'</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "cdf9864aa83d43a8bacc3869e031838d"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "7d18a61a2cca4f069251593b2616e50c"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_800ed014.py"><em>Click for solution</em></a></p>
<p>We apply the filters to the images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net2</span> <span class="o">=</span> <span class="n">Net2</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">x_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output_x</span> <span class="o">=</span> <span class="n">net2</span><span class="p">(</span><span class="n">x_img</span><span class="p">)</span>
<span class="n">output_x</span> <span class="o">=</span> <span class="n">output_x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">o_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output_o</span> <span class="o">=</span> <span class="n">net2</span><span class="p">(</span><span class="n">o_img</span><span class="p">)</span>
<span class="n">output_o</span> <span class="o">=</span> <span class="n">output_o</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let us view the image of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(O\)</span> and what the output of the filters applied to them looks like. Pay special attention to the areas with very high vs. very low output patterns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax11</span><span class="p">,</span> <span class="n">ax12</span><span class="p">,</span> <span class="n">ax13</span><span class="p">,</span> <span class="n">ax14</span><span class="p">),</span>
      <span class="p">(</span><span class="n">ax21</span><span class="p">,</span> <span class="n">ax22</span><span class="p">,</span> <span class="n">ax23</span><span class="p">,</span> <span class="n">ax24</span><span class="p">),</span>
      <span class="p">(</span><span class="n">ax31</span><span class="p">,</span> <span class="n">ax32</span><span class="p">,</span> <span class="n">ax33</span><span class="p">,</span> <span class="n">ax34</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Show the filters</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net2</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net2</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3"</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net2</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>

<span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span>
<span class="c1"># Show x and the filters applied to x</span>
<span class="n">ax21</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"image x"</span><span class="p">)</span>
<span class="n">ax21</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax22</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 1"</span><span class="p">)</span>
<span class="n">ax22</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax23</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 2"</span><span class="p">)</span>
<span class="n">ax23</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax24</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 3"</span><span class="p">)</span>
<span class="n">ax24</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>

<span class="c1"># Show o and the filters applied to o</span>
<span class="n">ax31</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"image o"</span><span class="p">)</span>
<span class="n">ax31</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax32</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 1"</span><span class="p">)</span>
<span class="n">ax32</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax33</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 2"</span><span class="p">)</span>
<span class="n">ax33</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax34</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 3"</span><span class="p">)</span>
<span class="n">ax34</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D2_Tutorial1_114_0.png" src="../../../_images/W2D2_Tutorial1_114_0.png"/>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-2-relu-after-convolutions">
<h2>Section 3.2: ReLU after convolutions<a class="headerlink" href="#section-3-2-relu-after-convolutions" title="Permalink to this headline">¶</a></h2>
<p>Up until now we’ve talked about the convolution operation, which is linear. But the real strength of neural networks comes from the incorporation of non-linear functions.  Furthermore, in the real world, we often have learning problems where the relationship between the input and output is non-linear and complex.</p>
<p>The ReLU (Rectified Linear Unit) introduces non-linearity into our model, allowing us to learn a more complex function that can better predict the class of an image.</p>
<p>The ReLU function is shown below.</p>
<br/>
<figure>
<center><img src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/relu.png" width="400px"/>
<figcaption>The Rectified Linear Unit (ReLU) Activation Function<figcaption>
</figcaption></figcaption></center>
</figure><p>Now let us incorporate ReLU into our previous model and visualize the output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net3</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Neural Network Instance</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize Net3 parameters</span>

<span class="sd">    Args:</span>
<span class="sd">      padding: int or tuple, optional</span>
<span class="sd">        Zero-padding added to both sides of the input. Default: 0</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net3</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                           <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>

    <span class="c1"># First kernel - leading diagonal</span>
    <span class="n">kernel_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span>

    <span class="c1"># Second kernel - other diagonal</span>
    <span class="n">kernel_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]])</span>

    <span class="c1"># Third kernel -checkerboard pattern</span>
    <span class="n">kernel_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span>


    <span class="c1"># Stack all kernels in one tensor with (3, 1, 5, 5) dimensions</span>
    <span class="n">multiple_kernels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">kernel_1</span><span class="p">,</span> <span class="n">kernel_2</span><span class="p">,</span> <span class="n">kernel_3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">multiple_kernels</span><span class="p">)</span>

    <span class="c1"># Negative bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">]))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward Pass of Net3</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Convolution output</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>We apply the filters and relus to the images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net3</span> <span class="o">=</span> <span class="n">Net3</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">x_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output_x_relu</span> <span class="o">=</span> <span class="n">net3</span><span class="p">(</span><span class="n">x_img</span><span class="p">)</span>
<span class="n">output_x_relu</span> <span class="o">=</span> <span class="n">output_x_relu</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">o_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output_o_relu</span> <span class="o">=</span> <span class="n">net3</span><span class="p">(</span><span class="n">o_img</span><span class="p">)</span>
<span class="n">output_o_relu</span> <span class="o">=</span> <span class="n">output_o_relu</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let us view the image of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(O\)</span> and what the output of the filters applied to them look like.</p>
<p><em>Execute this cell to view the filtered images</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to view the filtered images*</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax11</span><span class="p">,</span> <span class="n">ax12</span><span class="p">,</span> <span class="n">ax13</span><span class="p">,</span> <span class="n">ax14</span><span class="p">,</span> <span class="n">ax15</span><span class="p">,</span> <span class="n">ax16</span><span class="p">,</span> <span class="n">ax17</span><span class="p">),</span>
      <span class="p">(</span><span class="n">ax21</span><span class="p">,</span> <span class="n">ax22</span><span class="p">,</span> <span class="n">ax23</span><span class="p">,</span> <span class="n">ax24</span><span class="p">,</span> <span class="n">ax25</span><span class="p">,</span> <span class="n">ax26</span><span class="p">,</span> <span class="n">ax27</span><span class="p">),</span>
      <span class="p">(</span><span class="n">ax31</span><span class="p">,</span> <span class="n">ax32</span><span class="p">,</span> <span class="n">ax33</span><span class="p">,</span> <span class="n">ax34</span><span class="p">,</span> <span class="n">ax35</span><span class="p">,</span> <span class="n">ax36</span><span class="p">,</span> <span class="n">ax37</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span><span class="p">,</span>
                                                                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1"># Show the filters</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net3</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net3</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3"</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net3</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>

<span class="n">ax15</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1"</span><span class="p">)</span>
<span class="n">ax15</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net3</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax16</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2"</span><span class="p">)</span>
<span class="n">ax16</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net3</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax17</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3"</span><span class="p">)</span>
<span class="n">ax17</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net3</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>

<span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span>
<span class="c1"># Show x and the filters applied to `x`</span>
<span class="n">ax21</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"image x"</span><span class="p">)</span>
<span class="n">ax21</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax22</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 1"</span><span class="p">)</span>
<span class="n">ax22</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax23</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 2"</span><span class="p">)</span>
<span class="n">ax23</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax24</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 3"</span><span class="p">)</span>
<span class="n">ax24</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>

<span class="n">ax25</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1 + ReLU"</span><span class="p">)</span>
<span class="n">ax25</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x_relu</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax26</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2 + ReLU"</span><span class="p">)</span>
<span class="n">ax26</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x_relu</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax27</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3 + ReLU"</span><span class="p">)</span>
<span class="n">ax27</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x_relu</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>

<span class="c1"># Show o and the filters applied to `o`</span>
<span class="n">ax31</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"image o"</span><span class="p">)</span>
<span class="n">ax31</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax32</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 1"</span><span class="p">)</span>
<span class="n">ax32</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax33</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 2"</span><span class="p">)</span>
<span class="n">ax33</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax34</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 3"</span><span class="p">)</span>
<span class="n">ax34</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>

<span class="n">ax35</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1 + ReLU"</span><span class="p">)</span>
<span class="n">ax35</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o_relu</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax36</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2 + ReLU"</span><span class="p">)</span>
<span class="n">ax36</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o_relu</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax37</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3 + ReLU"</span><span class="p">)</span>
<span class="n">ax37</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o_relu</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D2_Tutorial1_122_0.png" src="../../../_images/W2D2_Tutorial1_122_0.png">
</img></div>
</div>
<p>Discuss with your pod how the ReLU activations help strengthen the features necessary to detect an <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p><a class="reference external" href="https://stats.stackexchange.com/a/226927">Here</a>’s an discussion which talks about how ReLU is useful as an activation funciton.</p>
<p><a class="reference external" href="https://stats.stackexchange.com/questions/126238/what-are-the-advantages-of-relu-over-sigmoid-function-in-deep-neural-networks?sfb=2">Here</a>’s another excellent discussion about the advantages of using ReLU.</p>
</div>
<div class="section" id="section-3-3-pooling">
<h2>Section 3.3: Pooling<a class="headerlink" href="#section-3-3-pooling" title="Permalink to this headline">¶</a></h2>
<p>Convolutional layers create feature maps that summarize the presence of particular features (e.g. edges) in the input. However, these feature maps record the <em>precise</em> position of features in the input. That means that small changes to the position of an object in an image can result in a very different feature map. But a cup is a cup (and an <span class="math notranslate nohighlight">\(X\)</span> is an <span class="math notranslate nohighlight">\(X\)</span>) no matter where it appears in the image!  We need to achieve <em>translational invariance</em>.</p>
<p>A common approach to this problem is called downsampling. Downsampling creates a lower-resolution version of an image, retaining the large structural elements and removing some of the fine detail that may be less relevant to the task. In CNNs, Max-Pooling and Average-Pooling are used to downsample.  These operations shrink the size of the hidden layers, and produce features that are more translationally invariant, which can be better leveraged by subsequent layers.</p>
<p>Like convolutional layers, pooling layers have fixed-shape windows (pooling windows) that are systematically applied to the input.  As with filters, we can change the shape of the window and the size of the stride.  And, just like with filters, every time we apply a pooling operation we produce a single output.</p>
<p>Pooling performs a kind of information compression that provides summary statistics for a <em>neighborhood</em> of the input.</p>
<ul class="simple">
<li><p>In Maxpooling, we compute the maximum value of all pixels in the pooling window.</p></li>
<li><p>In Avgpooling, we compute the average value of all pixels in the pooling window.</p></li>
</ul>
<p>The example below shows the result of Maxpooling within the yellow pooling windows to create the red pooling output matrix.</p>
<figure>
<center><img src="https://developers.google.com/machine-learning/glossary/images/PoolingConvolution.svg?hl=fr" width="400px"/>
<figcaption>An Example of Pooling with a kernel size of 2</figcaption>
</center>
</figure>
<p>Pooling gives our network translational invariance by providing a summary of the values in each pooling window. Thus, a small change in the features of the underlying image won’t make a huge difference to the output.</p>
<p>Note that, unlike a convolutional layer, the pooling layer contains no learned parameters! Pooling just computes a pre-determined summary of the input and passes that along.  This is in contrast to the convolutional layer, where there are filters to be learned.</p>
<div class="section" id="interactive-demo-3-3-the-effect-of-the-stride">
<h3>Interactive Demo 3.3: The effect of the stride<a class="headerlink" href="#interactive-demo-3-3-the-effect-of-the-stride" title="Permalink to this headline">¶</a></h3>
<p><strong>Important:</strong> Change the bool variable <code class="docutils literal notranslate"><span class="pre">run_demo</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> by ticking the box, in order to experiment with the demo. Due to video rendering on jupyter-book, we had to remove it from the automatic execution.</p>
<p>The following animation depicts how changing the stride changes the output. The stride defines how much the pooling region is moved over the input matrix to produce the next output (red arrows in the animation).  Give it a try! Change the stride and see how it affects the output shape.  You can also try MaxPool or AvgPool.</p>
<p><em>Run this cell to enable the widget!</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run this cell to enable the widget!*</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="n">id_html</span> <span class="o">=</span> <span class="mf">3.3</span>
<span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/interactive_demo</span><span class="si">{</span><span class="n">id_html</span><span class="si">}</span><span class="s1">.html'</span>
<span class="n">run_demo</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># @param {type:"boolean"}</span>
<span class="k">if</span> <span class="n">run_demo</span><span class="p">:</span>
  <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-3-3-implement-maxpooling">
<h3>Coding Exercise 3.3: Implement MaxPooling<a class="headerlink" href="#coding-exercise-3-3-implement-maxpooling" title="Permalink to this headline">¶</a></h3>
<p>Let us now implement MaxPooling in PyTorch and observe the effects of Pooling on the dimension of the input image. Use a kernel of size 2 and stride of 2 for the MaxPooling layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net4</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Neural Network instance</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise parameters of Net4</span>

<span class="sd">    Args:</span>
<span class="sd">      padding: int or tuple, optional</span>
<span class="sd">        Zero-padding added to both sides of the input. Default: 0</span>
<span class="sd">      stride: int</span>
<span class="sd">        Stride</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net4</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>

    <span class="c1"># First kernel - leading diagonal</span>
    <span class="n">kernel_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span>

    <span class="c1"># Second kernel - other diagonal</span>
    <span class="n">kernel_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]])</span>

    <span class="c1"># Third kernel -checkerboard pattern</span>
    <span class="n">kernel_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
                              <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]]])</span>


    <span class="c1"># Stack all kernels in one tensor with (3, 1, 5, 5) dimensions</span>
    <span class="n">multiple_kernels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">kernel_1</span><span class="p">,</span> <span class="n">kernel_2</span><span class="p">,</span> <span class="n">kernel_3</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">multiple_kernels</span><span class="p">)</span>

    <span class="c1"># Negative bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">12</span><span class="p">]))</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define the maxpool layer"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=...</span><span class="p">,</span> <span class="n">stride</span><span class="o">=...</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward Pass of Net4</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Convolution + ReLU output</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define the maxpool layer"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># Pass through a max pool layer</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 3.3: Implement MaxPooling'</span><span class="p">)</span>

<span class="c1">## Check if your implementation is correct</span>
<span class="c1"># net4 = Net4().to(DEVICE)</span>
<span class="c1"># check_pooling_net(net4, device=DEVICE)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_f8a2dc20.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>✅ Your network produced the correct output.
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output_x_pool</span> <span class="o">=</span> <span class="n">net4</span><span class="p">(</span><span class="n">x_img</span><span class="p">)</span>
<span class="n">output_x_pool</span> <span class="o">=</span> <span class="n">output_x_pool</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">o_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">output_o_pool</span> <span class="o">=</span> <span class="n">net4</span><span class="p">(</span><span class="n">o_img</span><span class="p">)</span>
<span class="n">output_o_pool</span> <span class="o">=</span> <span class="n">output_o_pool</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
<p><em>Run the cell to plot the outputs!</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run the cell to plot the outputs!*</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">((</span><span class="n">ax11</span><span class="p">,</span> <span class="n">ax12</span><span class="p">,</span> <span class="n">ax13</span><span class="p">,</span> <span class="n">ax14</span><span class="p">),</span>
      <span class="p">(</span><span class="n">ax21</span><span class="p">,</span> <span class="n">ax22</span><span class="p">,</span> <span class="n">ax23</span><span class="p">,</span> <span class="n">ax24</span><span class="p">),</span>
      <span class="p">(</span><span class="n">ax31</span><span class="p">,</span> <span class="n">ax32</span><span class="p">,</span> <span class="n">ax33</span><span class="p">,</span> <span class="n">ax34</span><span class="p">))</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="c1"># Show the filters</span>
<span class="n">ax11</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"off"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 1"</span><span class="p">)</span>
<span class="n">ax12</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net4</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 2"</span><span class="p">)</span>
<span class="n">ax13</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net4</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"filter 3"</span><span class="p">)</span>
<span class="n">ax14</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">net4</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>

<span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span>
<span class="c1"># Show x and the filters applied to x</span>
<span class="n">ax21</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"image x"</span><span class="p">)</span>
<span class="n">ax21</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax22</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 1"</span><span class="p">)</span>
<span class="n">ax22</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x_pool</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax23</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 2"</span><span class="p">)</span>
<span class="n">ax23</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x_pool</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax24</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 3"</span><span class="p">)</span>
<span class="n">ax24</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_x_pool</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>

<span class="c1"># Show o and the filters applied to o</span>
<span class="n">ax31</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"image o"</span><span class="p">)</span>
<span class="n">ax31</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<span class="n">ax32</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 1"</span><span class="p">)</span>
<span class="n">ax32</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o_pool</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax33</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 2"</span><span class="p">)</span>
<span class="n">ax33</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o_pool</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">ax34</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"output filter 3"</span><span class="p">)</span>
<span class="n">ax34</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_o_pool</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
<p>You should observe the size of the output as being half of what you saw after the ReLU section, which is due to the Maxpool layer.</p>
<p>Despite the reduction in the size of the output, the important or high-level features in the output still remains intact.</p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-putting-it-all-together">
<h1>Section 4: Putting it all together<a class="headerlink" href="#section-4-putting-it-all-together" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~33mins</em></p>
<div class="section" id="video-5-putting-it-all-together">
<h2>Video 5: Putting it all together<a class="headerlink" href="#video-5-putting-it-all-together" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "4fc9b0de9b5244e6a0d2962d1343d14e"}
</script></div>
</div>
</div>
<div class="section" id="section-4-1-number-of-parameters-in-convolutional-vs-fully-connected-models">
<h2>Section 4.1: Number of Parameters in Convolutional vs. Fully-connected Models<a class="headerlink" href="#section-4-1-number-of-parameters-in-convolutional-vs-fully-connected-models" title="Permalink to this headline">¶</a></h2>
<p>Convolutional networks encourage weight-sharing by learning a single kernel that is repeated over the entire input image. In general, this kernel is just a few parameters, compared to the huge number of parameters in a dense network.</p>
<p>Let’s use the animation below to calculate few-layer network parameters for image data of shape <span class="math notranslate nohighlight">\(32\times32\)</span> using both convolutional layers and dense layers. The <code class="docutils literal notranslate"><span class="pre">Num_Dense</span></code> in this exercise is the number of dense layers we use in the network, with each dense layer having the same input and output dimensions. <code class="docutils literal notranslate"><span class="pre">Num_Convs</span></code> is the number of convolutional blocks in the network, with each block containing a single kernel. The kernel size is the length and width of this kernel.</p>
<p><strong>Note:</strong> you must run the cell before you can use the sliders.</p>
<br/>
<center>
<img src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/img_params.png"/>
<figcaption> Parameter comparison</figcaption>
</center>
<div class="section" id="interactive-demo-4-1-number-of-parameters">
<h3>Interactive Demo 4.1: Number of Parameters<a class="headerlink" href="#interactive-demo-4-1-number-of-parameters" title="Permalink to this headline">¶</a></h3>
<p><em>Run this cell to enable the widget</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run this cell to enable the widget*</span>
<span class="kn">import</span> <span class="nn">io</span><span class="o">,</span> <span class="nn">base64</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>


<span class="k">def</span> <span class="nf">do_plot</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">number_of_Linear</span><span class="p">,</span> <span class="n">number_of_Conv2d</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="p">,</span> <span class="n">pooling</span><span class="p">,</span> <span class="n">Final_Layer</span><span class="p">):</span>
  <span class="n">sample_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>
  <span class="n">linear_layer</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">linear_nets</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">code_dense</span> <span class="o">=</span> <span class="s2">""</span>

  <span class="n">code_dense</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"model_dense = nn.Sequential(</span><span class="se">\n</span><span class="s2">"</span>
  <span class="n">code_dense</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.Flatten(),</span><span class="se">\n</span><span class="s2">"</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_Linear</span><span class="p">):</span>
    <span class="n">linear_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span>
                                  <span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span>
                                  <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">linear_nets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">linear_layer</span><span class="p">))</span>
    <span class="n">code_dense</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.Linear(</span><span class="si">{</span><span class="n">image_size</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">image_size</span><span class="si">}</span><span class="s2">*1, </span><span class="si">{</span><span class="n">image_size</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">image_size</span><span class="si">}</span><span class="s2">*1, bias=False),</span><span class="se">\n</span><span class="s2">"</span>
  <span class="k">if</span> <span class="n">Final_Layer</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">linear_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">image_size</span> <span class="o">*</span> <span class="n">image_size</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
                                  <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">linear_nets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">linear_layer</span><span class="p">))</span>
    <span class="n">code_dense</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.Linear(</span><span class="si">{</span><span class="n">image_size</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">image_size</span><span class="si">}</span><span class="s2">*1, 10, bias=False)</span><span class="se">\n</span><span class="s2">"</span>
  <span class="n">code_dense</span> <span class="o">+=</span> <span class="s2">")</span><span class="se">\n</span><span class="s2">"</span>
  <span class="n">code_dense</span> <span class="o">+=</span> <span class="s2">"result_dense = model_dense(sample_image)</span><span class="se">\n</span><span class="s2">"</span>
  <span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">linear_layer</span><span class="p">)</span>

  <span class="n">conv_layer</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">conv_nets</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">code_conv</span> <span class="o">=</span> <span class="s2">""</span>

  <span class="n">code_conv</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"model_conv = nn.Sequential(</span><span class="se">\n</span><span class="s2">"</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_Conv2d</span><span class="p">):</span>
    <span class="n">conv_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">out_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                                <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                                <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

    <span class="n">conv_nets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layer</span><span class="p">))</span>
    <span class="n">code_conv</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.Conv2d(in_channels=1, out_channels=1, kernel_size=</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">, padding=</span><span class="si">{</span><span class="n">kernel_size</span><span class="o">//</span><span class="mi">2</span><span class="si">}</span><span class="s2">, bias=False),</span><span class="se">\n</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">pooling</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">conv_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="n">code_conv</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.MaxPool2d(2, 2),</span><span class="se">\n</span><span class="s2">"</span>
    <span class="n">conv_nets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layer</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">Final_Layer</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">conv_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">code_conv</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.Flatten(),</span><span class="se">\n</span><span class="s2">"</span>
    <span class="n">conv_nets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layer</span><span class="p">))</span>
    <span class="n">shape_conv</span> <span class="o">=</span> <span class="n">conv_nets</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">sample_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">conv_layer</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">shape_conv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">code_conv</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">"    nn.Linear(</span><span class="si">{</span><span class="n">shape_conv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, 10, bias=False),</span><span class="se">\n</span><span class="s2">"</span>
    <span class="n">conv_nets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layer</span><span class="p">))</span>
  <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">conv_layer</span><span class="p">)</span>
  <span class="n">code_conv</span> <span class="o">+=</span> <span class="s2">")</span><span class="se">\n</span><span class="s2">"</span>
  <span class="n">code_conv</span> <span class="o">+=</span> <span class="s2">"result_conv = model_conv(sample_image)</span><span class="se">\n</span><span class="s2">"</span>


  <span class="n">t_1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">shape_linear</span> <span class="o">=</span> <span class="n">linear_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">sample_image</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">t_2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">shape_conv</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="p">(</span><span class="n">sample_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">t_3</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">"Time taken by Dense Layer </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t_2</span> <span class="o">-</span> <span class="n">t_1</span><span class="p">))</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Time taken by Conv Layer  </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t_3</span> <span class="o">-</span> <span class="n">t_2</span><span class="p">))</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">"left"</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">"bottom"</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">"right"</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">"top"</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">linear_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
  <span class="n">nl</span> <span class="o">=</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span>
  <span class="n">p2</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span>
           <span class="sa">f</span><span class="s2">"Total Parameters in Dense Layer </span><span class="si">{</span><span class="n">p1</span><span class="si">:</span><span class="s2">10,d</span><span class="si">}{</span><span class="n">nl</span><span class="si">}</span><span class="s2">Total Parameters in Conv Layer   </span><span class="si">{</span><span class="n">p2</span><span class="si">:</span><span class="s2">10,d</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.23</span><span class="p">,</span> <span class="mf">0.62</span><span class="p">,</span> <span class="s2">"Dense Net"</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
           <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">text3</span><span class="p">):</span>
<span class="w">      </span><span class="sd">"""</span>
<span class="sd">      Function to render widget</span>
<span class="sd">      """</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                                 <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">clip_on</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">text1</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
               <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
               <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.08</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">text3</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
               <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

  <span class="n">x</span> <span class="o">=</span> <span class="mf">0.25</span>
  <span class="k">if</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s2">"Flatten"</span><span class="p">,</span>
           <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">sample_image</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mf">0.08</span> <span class="o">+</span> <span class="mf">0.01</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_Linear</span><span class="p">):</span>
    <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s2">"g"</span><span class="p">,</span> <span class="s2">"Dense"</span><span class="p">,</span>
           <span class="nb">tuple</span><span class="p">(</span><span class="n">linear_nets</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">sample_image</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
           <span class="nb">list</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mf">0.11</span>

  <span class="k">if</span> <span class="n">Final_Layer</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">number_of_Linear</span>
    <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s2">"g"</span><span class="p">,</span> <span class="s2">"Dense"</span><span class="p">,</span>
           <span class="nb">tuple</span><span class="p">(</span><span class="n">linear_nets</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">sample_image</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
           <span class="nb">list</span><span class="p">(</span><span class="n">linear_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.23</span><span class="p">,</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.35</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">"Conv Net"</span><span class="p">,</span>
           <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">,</span>
           <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="mf">0.25</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_Conv2d</span><span class="p">):</span>
    <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="s2">"Conv"</span><span class="p">,</span>
           <span class="nb">tuple</span><span class="p">(</span><span class="n">conv_nets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="p">](</span><span class="n">sample_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
           <span class="nb">list</span><span class="p">(</span><span class="n">conv_nets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mf">0.11</span>
    <span class="k">if</span> <span class="n">pooling</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">"Pooling"</span><span class="p">,</span>
             <span class="nb">tuple</span><span class="p">(</span><span class="n">conv_nets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">](</span><span class="n">sample_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="s2">""</span><span class="p">)</span>
      <span class="n">x</span> <span class="o">+=</span> <span class="mf">0.08</span> <span class="o">+</span> <span class="mf">0.01</span>

  <span class="k">if</span> <span class="n">Final_Layer</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">number_of_Conv2d</span>
    <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s2">"Flatten"</span><span class="p">,</span>
           <span class="nb">tuple</span><span class="p">(</span><span class="n">conv_nets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span><span class="p">](</span><span class="n">sample_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="s2">""</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mf">0.08</span> <span class="o">+</span> <span class="mf">0.01</span>

    <span class="n">addBox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="s2">"g"</span><span class="p">,</span> <span class="s2">"Dense"</span><span class="p">,</span>
            <span class="nb">tuple</span><span class="p">(</span><span class="n">conv_nets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">](</span><span class="n">sample_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">conv_nets</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="mf">0.11</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.3</span> <span class="o">+</span> <span class="mf">0.35</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
           <span class="s2">"Input"</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span>
                             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">clip_on</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.3</span> <span class="o">+</span> <span class="mf">0.35</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">sample_image</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span>
           <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s2">"center"</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">"center"</span><span class="p">)</span>

  <span class="c1"># Plot</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_tight_layout</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">my_stringIObytes</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">my_stringIObytes</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'png'</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
  <span class="n">my_stringIObytes</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">my_base64_jpgData</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">my_stringIObytes</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>

  <span class="k">del</span> <span class="n">linear_layer</span><span class="p">,</span> <span class="n">conv_layer</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
  <span class="n">mystring</span> <span class="o">=</span> <span class="s2">"""&lt;img src="data:image/png;base64,"""</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">my_base64_jpgData</span><span class="p">)[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">"""" alt="Graph"&gt;"""</span>

  <span class="k">return</span> <span class="n">code_dense</span><span class="p">,</span> <span class="n">code_conv</span><span class="p">,</span> <span class="n">mystring</span>


<span class="c1"># Parameters</span>
<span class="n">caption</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="s1">'The values of range1 and range2 are synchronized'</span><span class="p">)</span>
<span class="n">slider_batch_size</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                      <span class="n">description</span><span class="o">=</span><span class="s2">"BatchSize"</span><span class="p">)</span>
<span class="n">slider_image_size</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                                      <span class="n">description</span><span class="o">=</span><span class="s2">"ImageSize"</span><span class="p">)</span>
<span class="n">slider_number_of_Linear</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                            <span class="n">description</span><span class="o">=</span><span class="s2">"NumDense"</span><span class="p">)</span>
<span class="n">slider_number_of_Conv2d</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                            <span class="n">description</span><span class="o">=</span><span class="s2">"NumConv"</span><span class="p">)</span>
<span class="n">slider_kernel_size</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">21</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                       <span class="n">description</span><span class="o">=</span><span class="s2">"KernelSize"</span><span class="p">)</span>
<span class="n">input_pooling</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Checkbox</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                 <span class="n">description</span><span class="o">=</span><span class="s2">"Pooling"</span><span class="p">)</span>
<span class="n">input_Final_Layer</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Checkbox</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                     <span class="n">description</span><span class="o">=</span><span class="s2">"Final_Layer"</span><span class="p">)</span>

<span class="n">output_code1</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span> <span class="p">)</span>

<span class="n">output_plot</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span> <span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_func</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span>
              <span class="n">number_of_Linear</span><span class="p">,</span> <span class="n">number_of_Conv2d</span><span class="p">,</span>
              <span class="n">kernel_size</span><span class="p">,</span> <span class="n">pooling</span><span class="p">,</span> <span class="n">Final_Layer</span><span class="p">):</span>

    <span class="n">code1</span><span class="p">,</span> <span class="n">code2</span><span class="p">,</span> <span class="n">plot</span> <span class="o">=</span> <span class="n">do_plot</span><span class="p">(</span><span class="n">image_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                                 <span class="n">number_of_Linear</span><span class="p">,</span> <span class="n">number_of_Conv2d</span><span class="p">,</span>
                                 <span class="n">kernel_size</span><span class="p">,</span> <span class="n">pooling</span><span class="p">,</span> <span class="n">Final_Layer</span><span class="p">)</span>
    <span class="n">output_plot</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">plot</span>

    <span class="n">output_code1</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="s2">"""</span>
<span class="s2">    &lt;!DOCTYPE html&gt;</span>
<span class="s2">    &lt;html&gt;</span>
<span class="s2">      &lt;head&gt;</span>
<span class="s2">        &lt;style&gt;</span>
<span class="s2">          * {</span>
<span class="s2">            box-sizing: border-box;</span>
<span class="s2">          }</span>
<span class="s2">          .column {</span>
<span class="s2">            float: left;</span>
<span class="s2">            /*width: 33.33%;*/</span>
<span class="s2">            padding: 5px;</span>
<span class="s2">          }</span>
<span class="s2">          /* Clearfix (clear floats) */</span>
<span class="s2">          .row::after {</span>
<span class="s2">            content: "";</span>
<span class="s2">            clear: both;</span>
<span class="s2">            display: table;</span>
<span class="s2">          }</span>
<span class="s2">          pre {</span>
<span class="s2">            line-height: 1.2em;</span>
<span class="s2">          }</span>
<span class="s2">        &lt;/style&gt;</span>
<span class="s2">      &lt;/head&gt;</span>

<span class="s2">      &lt;body&gt;</span>
<span class="s2">        &lt;div class="row"&gt;</span>
<span class="s2">          &lt;div class="column" style="overflow-x: scroll;"&gt;</span>
<span class="s2">          &lt;h2&gt;Code for Dense Network&lt;/h2&gt;</span>
<span class="s2">          &lt;pre&gt;"""</span> <span class="o">+</span> <span class="n">code1</span> <span class="o">+</span> <span class="s2">"""&lt;/pre&gt;</span>
<span class="s2">        &lt;/div&gt;</span>
<span class="s2">          &lt;div class="column" style="overflow-x: scroll;"&gt;</span>
<span class="s2">          &lt;h2&gt;Code for Conv Network&lt;/h2&gt;</span>
<span class="s2">          &lt;pre&gt;"""</span> <span class="o">+</span> <span class="n">code2</span> <span class="o">+</span> <span class="s2">"""&lt;/pre&gt;</span>
<span class="s2">          &lt;/div&gt;</span>
<span class="s2">        &lt;/div&gt;</span>
<span class="s2">      &lt;/body&gt;</span>
<span class="s2">    &lt;/html&gt;</span>
<span class="s2">"""</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">interactive_output</span><span class="p">(</span><span class="n">plot_func</span><span class="p">,</span> <span class="p">{</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">slider_batch_size</span><span class="p">,</span>
    <span class="s2">"image_size"</span><span class="p">:</span> <span class="n">slider_image_size</span><span class="p">,</span>
    <span class="s2">"number_of_Linear"</span><span class="p">:</span> <span class="n">slider_number_of_Linear</span><span class="p">,</span>
    <span class="s2">"number_of_Conv2d"</span><span class="p">:</span> <span class="n">slider_number_of_Conv2d</span><span class="p">,</span>
    <span class="s2">"kernel_size"</span><span class="p">:</span> <span class="n">slider_kernel_size</span><span class="p">,</span>
    <span class="s2">"pooling"</span><span class="p">:</span> <span class="n">input_pooling</span><span class="p">,</span>
    <span class="s2">"Final_Layer"</span><span class="p">:</span> <span class="n">input_Final_Layer</span><span class="p">,</span>
<span class="p">})</span>

<span class="n">ui</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">slider_batch_size</span><span class="p">,</span> <span class="n">slider_image_size</span><span class="p">,</span>
                   <span class="n">slider_number_of_Linear</span><span class="p">,</span>
                   <span class="n">widgets</span><span class="o">.</span><span class="n">HBox</span><span class="p">([</span><span class="n">slider_number_of_Conv2d</span><span class="p">,</span>
                                 <span class="n">slider_kernel_size</span><span class="p">,</span>
                                 <span class="n">input_pooling</span><span class="p">]),</span>
                   <span class="n">input_Final_Layer</span><span class="p">])</span>
<span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">HBox</span><span class="p">([</span><span class="n">output_plot</span><span class="p">,</span> <span class="n">output_code1</span><span class="p">]),</span> <span class="n">ui</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d851191c0325481783f884242b95e6cd"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "6c4f5a2fc3e14c73ae031d0a75093ea1"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "75c42ade7c994407871aa9d5c64928de"}
</script></div>
</div>
<p>The difference in parameters is huge, and it continues to increase as the input image size increases. Larger images require that the linear layer use a matrix that can be directly multiplied with the input pixels.</p>
<br/>
<p>While pooling does not reduce the number of parameters for a subsequent convolutional layer, it does decreases the image size. Therefore, later dense layers will need fewer parameters.</p>
<br/>
<p>The CNN parameter size, however, is invariant of the image size, as irrespective of the input that it gets, it keeps sliding the same learnable filter over the images.</p>
<p>The reduced parameter set not only brings down memory usage by huge chunks, but it also allows the model to generalize better.</p>
<div class="section" id="video-6-implement-your-own-cnn">
<h4>Video 6: Implement your own CNN<a class="headerlink" href="#video-6-implement-your-own-cnn" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "89e99c8342d04e51a836a09a355c90d2"}
</script></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-4-implement-your-own-cnn">
<h2>Coding Exercise 4: Implement your own CNN<a class="headerlink" href="#coding-exercise-4-implement-your-own-cnn" title="Permalink to this headline">¶</a></h2>
<p>Let’s stack up all we have learnt. Create a CNN with the following structure. <br/></p>
<ul class="simple">
<li><p>Convolution <code class="docutils literal notranslate"><span class="pre">nn.Conv2d(in_channels=1,</span> <span class="pre">out_channels=32,</span> <span class="pre">kernel_size=3)</span></code></p></li>
<li><p>Convolution <code class="docutils literal notranslate"><span class="pre">nn.Conv2d(in_channels=32,</span> <span class="pre">out_channels=64,</span> <span class="pre">kernel_size=3)</span></code></p></li>
<li><p>Pool Layer <code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d(kernel_size=2)</span></code></p></li>
<li><p>Fully Connected Layer <code class="docutils literal notranslate"><span class="pre">nn.Linear(in_features=9216,</span> <span class="pre">out_features=128)</span></code></p></li>
<li><p>Fully Connected layer <code class="docutils literal notranslate"><span class="pre">nn.Linear(in_features=128,</span> <span class="pre">out_features=2)</span></code></p></li>
</ul>
<p>Note: As discussed in the video, we would like to flatten the output from the Convolutional Layers before passing on the Linear layers, thereby converting an input of shape <span class="math notranslate nohighlight">\([\text{BatchSize}, \text{Channels}, \text{Height}, \text{Width}]\)</span> to <span class="math notranslate nohighlight">\([\text{BatchSize}, \text{Channels} \times \text{Height} \times \text{Width}]\)</span>, which in this case would be from <span class="math notranslate nohighlight">\([32, 64, 12, 12]\)</span> (output of second convolution layer) to <span class="math notranslate nohighlight">\([32, 64 \times 12 \times 12] = [32, 9216]\)</span>. Recall that the input images have size <span class="math notranslate nohighlight">\([28, 28]\)</span>.</p>
<p>Hint: You could use <code class="docutils literal notranslate"><span class="pre">torch.flatten(x,</span> <span class="pre">1)</span></code> in order to flatten the input at this stage. The <span class="math notranslate nohighlight">\(1\)</span> means it flattens dimensions starting with dimensions 1 in order to exclude the batch dimension from the flattening.</p>
<p>We should also stop to think about how we get the output of the pooling layer to be <span class="math notranslate nohighlight">\(12 \times 12\)</span>. It is because first, the two <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> with a <code class="docutils literal notranslate"><span class="pre">kernel_size=3</span></code> operations cause the image to be reduced to <span class="math notranslate nohighlight">\(26 \times 26\)</span> and the second <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> reduces it to <span class="math notranslate nohighlight">\(24 \times 24\)</span>. Finally, the <code class="docutils literal notranslate"><span class="pre">MaxPool2d</span></code> operation reduces the output size by half to <span class="math notranslate nohighlight">\(12 \times 12\)</span>.</p>
<p>Also, don’t forget the ReLUs (use e.g., <code class="docutils literal notranslate"><span class="pre">F.ReLU</span></code>)! No need to add a ReLU after the final fully connected layer.</p>
<div class="section" id="train-test-functions-run-me">
<h3>Train/Test Functions (Run Me)<a class="headerlink" href="#train-test-functions-run-me" title="Permalink to this headline">¶</a></h3>
<p>Double-click to see the contents!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Train/Test Functions (Run Me)</span>

<span class="c1"># @markdown Double-click to see the contents!</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Training function</span>

<span class="sd">  Args:</span>
<span class="sd">    model: nn.module</span>
<span class="sd">      Neural network instance</span>
<span class="sd">    device: string</span>
<span class="sd">      GPU/CUDA if available, CPU otherwise</span>
<span class="sd">    epochs: int</span>
<span class="sd">      Number of epochs</span>
<span class="sd">    train_loader: torch.loader</span>
<span class="sd">      Training Set</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">'batch'</span><span class="p">)</span> <span class="k">as</span> <span class="n">tepoch</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">tepoch</span><span class="p">:</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">tepoch</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Test function</span>

<span class="sd">  Args:</span>
<span class="sd">    model: nn.module</span>
<span class="sd">      Neural network instance</span>
<span class="sd">    device: string</span>
<span class="sd">      GPU/CUDA if available, CPU otherwise</span>
<span class="sd">    data_loader: torch.loader</span>
<span class="sd">      Test Set</span>

<span class="sd">  Returns:</span>
<span class="sd">    acc: float</span>
<span class="sd">      Test accuracy</span>
<span class="sd">  """</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

  <span class="n">acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
  <span class="k">return</span> <span class="n">acc</span>
</pre></div>
</div>
</div>
</div>
<p>We download the data. Notice that here, we normalize the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">emnist_train</span><span class="p">,</span> <span class="n">emnist_test</span> <span class="o">=</span> <span class="n">get_Xvs0_dataset</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_data_loaders</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">,</span> <span class="n">emnist_test</span><span class="p">,</span>
                                             <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EMNIST_Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Neural network instance with following structure</span>
<span class="sd">  nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3) # Convolutional Layer 1</span>
<span class="sd">  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3) + max-pooling # Convolutional Block 2</span>
<span class="sd">  nn.Linear(in_features=9216, out_features=128) # Fully Connected Layer 1</span>
<span class="sd">  nn.Linear(in_features=128, out_features=2) # Fully Connected Layer 2</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialize parameters of EMNISTNet</span>

<span class="sd">    Args:</span>
<span class="sd">      None</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EMNIST_Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define the required layers"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward pass of EMNISTNet</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Output of final fully connected layer</span>
<span class="sd">    """</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="c1"># Hint: Do not forget to flatten the image as it goes from</span>
    <span class="c1"># Convolution Layers to Linear Layers!</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define forward pass for any input x"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 4: Implement your own CNN'</span><span class="p">)</span>

<span class="c1">## Uncomment the lines below to train your network</span>
<span class="c1"># emnist_net = EMNIST_Net().to(DEVICE)</span>
<span class="c1"># print("Total Parameters in Network {:10d}".format(sum(p.numel() for p in emnist_net.parameters())))</span>
<span class="c1"># train(emnist_net, DEVICE, train_loader, 1)</span>
<span class="c1">## Uncomment to test your model</span>
<span class="c1"># print(f'Test accuracy is: {test(emnist_net, DEVICE, test_loader)}')</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_259add6d.py"><em>Click for solution</em></a></p>
<p>You should have been able to get a test accuracy of around <span class="math notranslate nohighlight">\(99%\)</span>!</p>
<p><strong>Note:</strong> We are using a softmax function here which converts a real value to a value between 0 and 1, which can be interpreted as a probability.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Index of an image in the dataset that corresponds to an X and O</span>
<span class="n">x_img_idx</span> <span class="o">=</span> <span class="mi">11</span>
<span class="n">o_img_idx</span> <span class="o">=</span> <span class="mi">0</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Input:"</span><span class="p">)</span>
<span class="n">x_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">x_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
           <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">emnist_net</span><span class="p">(</span><span class="n">x_img</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Result:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Confidence of image being an 'O':"</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Confidence of image being an 'X':"</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>

</div>
<p>The network is quite confident that this image is an <span class="math notranslate nohighlight">\(X\)</span>!</p>
<p>Note that this is evident from the softmax output, which shows the probabilities of the image belonging to each of the classes. There is a higher probability of belonging to class 1; i.e., class <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Let us also test the network on an <span class="math notranslate nohighlight">\(O\)</span> image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"Input:"</span><span class="p">)</span>
<span class="n">o_img</span> <span class="o">=</span> <span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">emnist_train</span><span class="p">[</span><span class="n">o_img_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span>
           <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">emnist_net</span><span class="p">(</span><span class="n">o_img</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Result:"</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Confidence of image being an 'O':"</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Confidence of image being an 'X':"</span><span class="p">,</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>In this Tutorial we have familiarized ouselves with CNNs. We have leaned how the convolution operation works and be applied in various images. Also, we have learned to implement our own CNN. In the next Tutorial, we will go deeper in the training of CNNs!</p>
<p>Next we will talk about RNNs, which shares parameters over time.</p>
<div class="section" id="airtable-submission-link">
<h2>Airtable Submission Link<a class="headerlink" href="#airtable-submission-link" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Airtable Submission Link</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPyDisplay</span>
<span class="n">IPyDisplay</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">"""</span>
<span class="s2">  &lt;div&gt;</span>
<span class="s2">    &lt;a href= "</span><span class="si">{</span><span class="n">atform</span><span class="o">.</span><span class="n">url</span><span class="p">()</span><span class="si">}</span><span class="s2">" target="_blank"&gt;</span>
<span class="s2">    &lt;img src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1"</span>
<span class="s2">  alt="button link to Airtable" style="width:410px"&gt;&lt;/a&gt;</span>
<span class="s2">    &lt;/div&gt;"""</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
<a href="https://portal.neuromatchacademy.org/api/redirect/to/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzJEMl9UMSIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTY3NzM1NTkxNS44Nzg4MDd9LCB7ImV2ZW50IjogIlZpZGVvIDE6IEludHJvZHVjdGlvbiB0byBDTk5zIGFuZCBSTk5zIiwgInRzIjogMTY3NzM1NTkxOC45NjA0MzAxfSwgeyJldmVudCI6ICJWaWRlbyAyOiBSZXByZXNlbnRhdGlvbnMgJiBWaXN1YWwgcHJvY2Vzc2luZyBpbiB0aGUgYnJhaW4iLCAidHMiOiAxNjc3MzU1OTE5LjIwNTc3MjR9LCB7ImV2ZW50IjogIlZpZGVvIDM6IERldGFpbHMgYWJvdXQgQ29udm9sdXRpb24iLCAidHMiOiAxNjc3MzU1OTE5LjQ1NDM5MTV9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSAyLjE6IENvbnZvbHV0aW9uIG9mIGEgU2ltcGxlIEtlcm5lbCIsICJ0cyI6IDE2NzczNTU5MTkuNDg3MzI2NH0sIHsiZXZlbnQiOiAiQ29kaW5nIEV4ZXJjaXNlIDIuMjogQ29udm9sdXRpb24gT3V0cHV0IFNpemUiLCAidHMiOiAxNjc3MzU1OTE5LjQ5NjQ4MTJ9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSAyLjM6IENvZGluZyBhIENvbnZvbHV0aW9uIiwgInRzIjogMTY3NzM1NTkxOS41MDkzMDM2fSwgeyJldmVudCI6ICJWaWRlbyA0OiBQb29saW5nIiwgInRzIjogMTY3NzM1NTkyMS4xMzgyMTM5fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgMy4zOiBJbXBsZW1lbnQgTWF4UG9vbGluZyIsICJ0cyI6IDE2NzczNTU5NTQuMDI2MTE5NX0sIHsiZXZlbnQiOiAiVmlkZW8gNTogUHV0dGluZyBpdCBhbGwgdG9nZXRoZXIiLCAidHMiOiAxNjc3MzU1OTU1LjU1NzkyNn0sIHsiZXZlbnQiOiAiVmlkZW8gNjogSW1wbGVtZW50IHlvdXIgb3duIENOTiIsICJ0cyI6IDE2NzczNTU5NTUuOTUxNTY5fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgNDogSW1wbGVtZW50IHlvdXIgb3duIENOTiIsICJ0cyI6IDE2NzczNTU5NTYuMTA4MDI3N30sIHsiZXZlbnQiOiAidXJsIGdlbmVyYXRlZCIsICJ0cyI6IDE2NzczNTU5NTYuNjk1NjY1MX1dfQ%3D%3D" target="_blank">
<img alt="button link to Airtable" src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/AirtableSubmissionButton.png?raw=1" style="width:410px"/></a>
</div></div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-1-write-your-own-training-loop-revisited">
<h1>Bonus 1: Write your own training loop revisited<a class="headerlink" href="#bonus-1-write-your-own-training-loop-revisited" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~20mins</em></p>
<p>In the last section we coded up a CNN, but trained it with some predefined functions.  In this section, we will walk through an example of training loop for a convolution net. In this section, we will train a CNN using convolution layers and maxpool and then observe what the training and validation curves look like. In Section 6, we will add regularization and data augmentation to see what effects they have on the curves and why it is important to incorporate them while training our network.
<br/></p>
<div class="section" id="video-7-writing-your-own-training-loop">
<h2>Video 7: Writing your own training loop<a class="headerlink" href="#video-7-writing-your-own-training-loop" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2202c201936445fdb5272fe0d6b4d7fa"}
</script></div>
</div>
</div>
<div class="section" id="bonus-1-1-understand-the-dataset">
<h2>Bonus 1.1: Understand the Dataset<a class="headerlink" href="#bonus-1-1-understand-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>The dataset we are going to use for this task is called Fashion-MNIST. It consists of a training set of 60,000 examples and a test set of 10,000 examples. We further divide the test set into a validation set and a test set (8,000 and 2,000, respectively). Each example is a <span class="math notranslate nohighlight">\(28 \times 28\)</span> gray scale image, associated with a label from 10 classes. Following are the labels of the dataset:</p>
<br/>
<div class="amsmath math notranslate nohighlight" id="equation-eb8e7489-5ff3-45cd-84c1-a295ada19d16">
<span class="eqno">(67)<a class="headerlink" href="#equation-eb8e7489-5ff3-45cd-84c1-a295ada19d16" title="Permalink to this equation">¶</a></span>\[\begin{matrix}
\text{label} &amp;&amp; \text{category} \\
\hline
0 &amp;&amp; \text{T-shirt/top} \\
1 &amp;&amp; \text{Trouser} \\
2 &amp;&amp; \text{Pullover} \\
3 &amp;&amp; \text{Dress} \\
4 &amp;&amp; \text{Coat} \\
5 &amp;&amp; \text{Sandal} \\
6 &amp;&amp; \text{Shirt} \\
7 &amp;&amp; \text{Sneaker} \\
8 &amp;&amp; \text{Bag} \\
9 &amp;&amp; \text{Ankle boot} \\
\end{matrix}\]</div>
<p><strong>Note:</strong> We will reduce the dataset to just the two categories T-shirt/top and Shirt to reduce the training time from about 10min to 2min. We later provide pretrained results to give you an idea how the results would look on the whole dataset.</p>
<div class="section" id="download-fashion-mnist-dataset">
<h3>Download Fashion MNIST dataset<a class="headerlink" href="#download-fashion-mnist-dataset" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download Fashion MNIST dataset</span>

<span class="c1"># webpage: https://github.com/zalandoresearch/fashion-mnist</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s1">'FashionMNIST.tar.gz'</span>
<span class="n">folder</span> <span class="o">=</span> <span class="s1">'FashionMNIST'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/dfhu5/download"</span>
<span class="n">download_data</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">tar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading FashionMNIST dataset...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading FashionMNIST completed.

Extracting the files...
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="loading-fashion-mnist-data">
<h3>Loading Fashion-MNIST Data<a class="headerlink" href="#loading-fashion-mnist-data" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">reduce_classes(data)</span></code> to reduce Fashion-MNIST Data to two-categories</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Loading Fashion-MNIST Data</span>

<span class="c1"># @markdown `reduce_classes(data)` to reduce Fashion-MNIST Data to two-categories</span>

<span class="c1"># need to split into train, validation, test</span>
<span class="k">def</span> <span class="nf">reduce_classes</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Reducing classes in Fashion MNIST</span>
<span class="sd">  to T-Shirts and Shirts</span>

<span class="sd">  Args:</span>
<span class="sd">    data: torch.tensor</span>
<span class="sd">      Training Data</span>

<span class="sd">  Returns:</span>
<span class="sd">    data: torch.tensor</span>
<span class="sd">      Data with two classes</span>
<span class="sd">  """</span>
  <span class="c1"># Only want T-Shirts (0) and Shirts (6) labels</span>
  <span class="n">train_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">6</span><span class="p">)</span>
  <span class="n">data</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
  <span class="n">data</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>

  <span class="c1"># Convert Xs predictions to 1, Os predictions to 0</span>
  <span class="n">data</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="k">return</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">get_fashion_mnist_dataset</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to get Fashion MNIST data</span>

<span class="sd">  Args:</span>
<span class="sd">    binary: boolean</span>
<span class="sd">      If True, training data has only two classes</span>
<span class="sd">    download: boolean</span>
<span class="sd">      If True, download training data</span>
<span class="sd">    seed: int</span>
<span class="sd">      Set seed for reproducibility [default: 0]</span>

<span class="sd">  Returns:</span>
<span class="sd">    train_data: torch.tensor</span>
<span class="sd">      Training data</span>
<span class="sd">    test_data: torch.tensor</span>
<span class="sd">      Test data</span>
<span class="sd">    validation_data: torch.tensor</span>
<span class="sd">      Validation data</span>
<span class="sd">  """</span>
  <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                                  <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                  <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                                  <span class="p">])</span>

  <span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span>
                                     <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                                     <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>


  <span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span>
                                    <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                                    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">binary</span><span class="p">:</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">reduce_classes</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">reduce_classes</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

  <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>
                                                             <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)),</span>
                                                              <span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">))])</span>

  <span class="k">return</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">get_fashion_mnist_dataset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p>If you want to continue with the 10 class dataset, skip the next cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">get_fashion_mnist_dataset</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p>Here’s some code to visualize the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">,</span> <span class="n">ax4</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">ax4</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">18.5</span><span class="p">,</span> <span class="mf">10.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D2_Tutorial1_182_0.png" src="../../../_images/W2D2_Tutorial1_182_0.png">
</img></div>
</div>
<p>Take a minute with your pod and talk about which classes you think would be most confusable.  How hard will it be to differentiate t-shirt/tops from shirts?</p>
</div>
<div class="section" id="video-8-the-training-loop">
<h3>Video 8: The Training Loop<a class="headerlink" href="#video-8-the-training-loop" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f7fdd3ead33840cdbbd36be09271c419"}
</script></div>
</div>
</div>
</div>
<div class="section" id="bonus-1-2-backpropagation-reminder">
<h2>Bonus 1.2: Backpropagation Reminder<a class="headerlink" href="#bonus-1-2-backpropagation-reminder" title="Permalink to this headline">¶</a></h2>
<p><em>Feel free to skip if you’ve got a good handle on Backpropagation</em></p>
<p>We know that we multiply the input data/tensors with weight matrices to obtain some output. Initially, we don’t know what the actual weight matrices are so we initialize them with some random values. These random weight matrices when applied as a transformation on the input gives us some output. At first the outputs/predictions will match the true labels only by chance.</p>
<p>To improve performance, we need to change the weight matrices so that the predicted outputs are similar to the true outputs (labels). We first calculate how far away the predicted outputs are to the true outputs using a loss function. Based on the loss function, we change the values of our weight matrices using the gradients of the error with respect to the weight matrices.</p>
<p>Since we are using PyTorch throughout the course, we will use the built-in functions to update the weights. We call the <code class="docutils literal notranslate"><span class="pre">backward()</span></code> method on our ‘loss’ variable to calculate the gradients/derivatives with respect to all the weight matrices and biases. And then we call the <code class="docutils literal notranslate"><span class="pre">step()</span></code> method on the optimizer variable to apply the gradient updates to our weight matrices.</p>
<p>Here’s an animation of backpropagation works.</p>
<img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/Backpropagation.gif" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/Backpropagation.gif"/>
<br/>
<p>In <a class="reference external" href="https://machinelearningknowledge.ai/animated-explanation-of-feed-forward-neural-network-architecture/">this article</a> you can find more animations!</p>
<p>Let’s first see a sample training loop. First, we create the network and load a dataset. Then we look at the training loop.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">emnist_net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Create a sample network</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise parameters of sample network</span>

<span class="sd">    Args:</span>
<span class="sd">      None</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># First define the layers.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">26</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward pass of sample network</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Output after passing through sample network</span>
<span class="sd">    """</span>
    <span class="c1"># Conv layer 1.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Conv layer 2.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Fully connected layer 1.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">64</span><span class="p">)</span>  <span class="c1"># You have to first flatten the ourput from the</span>
                            <span class="c1"># previous convolution layer.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Fully connected layer 2.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="load-a-sample-dataset-emnist">
<h3>Load a sample dataset (EMNIST)<a class="headerlink" href="#load-a-sample-dataset-emnist" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Load a sample dataset (EMNIST)</span>
<span class="c1"># Download the data if there are not downloaded</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s1">'EMNIST.zip'</span>
<span class="n">folder</span> <span class="o">=</span> <span class="s1">'EMNIST'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/xwfaj/download"</span>
<span class="n">download_data</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">tar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">EMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">"."</span><span class="p">,</span>
                              <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                              <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">split</span><span class="o">=</span><span class="s1">'letters'</span><span class="p">)</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">EMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">"."</span><span class="p">,</span>
                             <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                             <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">split</span><span class="o">=</span><span class="s1">'letters'</span><span class="p">)</span>

<span class="c1"># Labels should start from 0</span>
<span class="n">mnist_train</span><span class="o">.</span><span class="n">targets</span> <span class="o">-=</span> <span class="mi">1</span>
<span class="n">mnist_test</span><span class="o">.</span><span class="n">targets</span> <span class="o">-=</span> <span class="mi">1</span>

<span class="c1"># Create data loaders</span>
<span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                           <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                           <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                           <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                          <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                          <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>EMNIST dataset has already been downloaded.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Training</span>
<span class="c1"># Instantiate model</span>
<span class="c1"># Puts the Model on the GPU (Select runtime-type as GPU</span>
<span class="c1">#                            from the 'Runtime-&gt;Change Runtime type' option).</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">emnist_net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># Loss and Optimizer</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># Make changes here, if necessary</span>

<span class="c1"># Iterate through train set minibatchs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>  <span class="c1"># Make changes here, if necessary</span>
  <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>

    <span class="c1"># Zero out the gradients</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Forward pass</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">images</span>
    <span class="c1"># Move the data to GPU for faster execution.</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">labs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Calculate loss.</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">labs</span><span class="p">)</span>

    <span class="c1"># Backpropagation and gradient update.</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># Calculate gradients.</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># Apply gradient udpate.</span>


<span class="c1">## Testing</span>
<span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="c1"># Iterate through test set minibatchs</span>
  <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
    <span class="c1"># Forward pass</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">images</span>
      <span class="c1"># Move the data to GPU for faster execution.</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">labs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0a5f0c0b91224b99af92710a2ac29015"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d86f85ad437d4eedb6bdba977600934e"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "89618a84058d4c09945826ec6ac92d21"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "8d6f7bf74e474d56b89a1624e438934e"}
</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_44325</span><span class="o">/</span><span class="mf">1706982206.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>     <span class="c1"># Move the data to GPU for faster execution.</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>     <span class="n">x</span><span class="p">,</span> <span class="n">labs</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">23</span>     <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">24</span> 
<span class="g g-Whitespace">     </span><span class="mi">25</span>     <span class="c1"># Calculate loss.</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">/tmp/ipykernel_44325/1200628106.py</span> in <span class="ni">forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">39</span> 
<span class="g g-Whitespace">     </span><span class="mi">40</span>     <span class="c1"># Conv layer 2.</span>
<span class="ne">---&gt; </span><span class="mi">41</span>     <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">42</span>     <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">43</span>     <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">461</span> 
<span class="g g-Whitespace">    </span><span class="mi">462</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">463</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_conv_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">464</span> 
<span class="g g-Whitespace">    </span><span class="mi">465</span> <span class="k">class</span> <span class="nc">Conv3d</span><span class="p">(</span><span class="n">_ConvNd</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.15/x64/lib/python3.7/site-packages/torch/nn/modules/conv.py</span> in <span class="ni">_conv_forward</span><span class="nt">(self, input, weight, bias)</span>
<span class="g g-Whitespace">    </span><span class="mi">458</span>                             <span class="n">_pair</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">459</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">460</span>                         <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">461</span> 
<span class="g g-Whitespace">    </span><span class="mi">462</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>You already coded the structure of a CNN. Now, you are going to implement the training loop for a CNN.</p>
<ul class="simple">
<li><p>Choose the correct criterion</p></li>
<li><p>Code up the training part (calculating gradients, loss, stepping forward)</p></li>
<li><p>Keep a track of the running loss i.e for each epoch we want to to know the average loss of the batch size. We have already done the same for accuracy for you.</p></li>
</ul>
</div>
</div>
<div class="section" id="bonus-1-3-fashion-mnist-dataset">
<h2>Bonus 1.3: Fashion-MNIST dataset<a class="headerlink" href="#bonus-1-3-fashion-mnist-dataset" title="Permalink to this headline">¶</a></h2>
<p>Now Let us train on the actual Fashion-MNIST dataset.</p>
<div class="section" id="getting-the-dataloaders-run-me">
<h3>Getting the DataLoaders (Run Me)<a class="headerlink" href="#getting-the-dataloaders-run-me" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown ##### Getting the DataLoaders (Run Me)</span>


<span class="k">def</span> <span class="nf">get_data_loaders</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">validation_dataset</span><span class="p">,</span>
                     <span class="n">test_dataset</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span>
                     <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function to fetch dataloaders</span>

<span class="sd">  Args:</span>
<span class="sd">    train_dataset: torch.tensor</span>
<span class="sd">      Training data</span>
<span class="sd">    test_dataset: torch.tensor</span>
<span class="sd">      Test data</span>
<span class="sd">    validation_dataset: torch.tensor</span>
<span class="sd">      Validation data</span>
<span class="sd">    batch_size: int</span>
<span class="sd">      Batch Size  [default: 64]</span>
<span class="sd">    seed: int</span>
<span class="sd">      Set seed for reproducibility</span>

<span class="sd">  Returns:</span>
<span class="sd">    train_loader: torch.loader</span>
<span class="sd">      Training Data</span>
<span class="sd">    test_loader: torch.loader</span>
<span class="sd">      Test Data</span>
<span class="sd">    validation_loader: torch.loader</span>
<span class="sd">      Validation Data</span>
<span class="sd">  """</span>

  <span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
  <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

  <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                            <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
  <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">,</span>
                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                 <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                 <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
  <span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span>
                           <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                           <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                           <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">test_loader</span>


<span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_data_loaders</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                                                                <span class="n">validation_data</span><span class="p">,</span>
                                                                <span class="n">test_data</span><span class="p">,</span> <span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FMNIST_Net1</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Convolutional Neural Network</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise parameters of CNN</span>

<span class="sd">    Args:</span>
<span class="sd">      num_classes: int</span>
<span class="sd">        Number of classes</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FMNIST_Net1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward pass of CNN</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Output after passing through CNN</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-bonus-1-code-the-training-loop">
<h2>Coding Exercise Bonus 1: Code the training loop<a class="headerlink" href="#coding-exercise-bonus-1-code-the-training-loop" title="Permalink to this headline">¶</a></h2>
<p>Now try coding the training loop.</p>
<p>You should first have a <code class="docutils literal notranslate"><span class="pre">criterion</span></code> defined (you can use <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code> here, which you learned about last week) so that you can calculate the loss. Next, you should to put everything together. Start the training process by first obtaining the model output, calculating the loss, and finally updating the weights.</p>
<p><em>Don’t forget to zero out the gradients.</em></p>
<p><strong>Note:</strong> The comments in the <code class="docutils literal notranslate"><span class="pre">train</span></code> function provides many hints that will help you fill in the missing code. This will give you a solid understanding of the different steps involved in the training loop.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Training loop</span>

<span class="sd">  Args:</span>
<span class="sd">    model: nn.module</span>
<span class="sd">      Neural network instance</span>
<span class="sd">    device: string</span>
<span class="sd">      GPU/CUDA if available, CPU otherwise</span>
<span class="sd">    epochs: int</span>
<span class="sd">      Number of epochs</span>
<span class="sd">    train_loader: torch.loader</span>
<span class="sd">      Training Set</span>
<span class="sd">    validation_loader: torch.loader</span>
<span class="sd">      Validation set</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">criterion</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
  <span class="n">train_loss</span><span class="p">,</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">train_acc</span><span class="p">,</span> <span class="n">validation_acc</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">unit</span><span class="o">=</span><span class="s1">'epoch'</span><span class="p">)</span> <span class="k">as</span> <span class="n">tepochs</span><span class="p">:</span>
    <span class="n">tepochs</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s1">'Training'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tepochs</span><span class="p">:</span>
      <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
      <span class="c1"># Keeps track of the running loss</span>
      <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
      <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="c1">####################################################################</span>
        <span class="c1"># Fill in missing code below (...),</span>
        <span class="c1"># then remove or comment the line below to test your function</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Update the steps of the train loop"</span><span class="p">)</span>
        <span class="c1">####################################################################</span>
        <span class="c1"># COMPLETE CODE FOR TRAINING LOOP by following these steps</span>
        <span class="c1"># 1. Get the model output (call the model with the data from this batch)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="o">...</span>

        <span class="c1"># 2. Zero the gradients out (i.e. reset the gradient that the optimizer</span>
        <span class="c1">#                       has collected so far with optimizer.zero_grad())</span>
        <span class="o">...</span>

        <span class="c1"># 3. Get the Loss (call the loss criterion with the model's output</span>
        <span class="c1">#                  and the target values)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>

        <span class="c1"># 4. Calculate the gradients (do the pass backwards from the loss</span>
        <span class="c1">#                             with loss.backward())</span>
        <span class="o">...</span>

        <span class="c1"># 5. Update the weights (using the training step of the optimizer,</span>
        <span class="c1">#                        optimizer.step())</span>
        <span class="o">...</span>

        <span class="c1">####################################################################</span>
        <span class="c1"># Fill in missing code below (...),</span>
        <span class="c1"># then remove or comment the line below to test your function</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Update the set_postfix function"</span><span class="p">)</span>
        <span class="c1">####################################################################</span>
        <span class="c1"># Set loss to whatever you end up naming your variable when</span>
        <span class="c1"># calling criterion</span>
        <span class="c1"># For example, loss = criterion(output, target)</span>
        <span class="c1"># then set loss = loss.item() in the set_postfix function</span>
        <span class="n">tepochs</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=...</span><span class="p">)</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="o">...</span>  <span class="c1"># Add the loss for this batch</span>

        <span class="c1"># Get accuracy</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

      <span class="c1">####################################################################</span>
      <span class="c1"># Fill in missing code below (...),</span>
      <span class="c1"># then remove or comment the line below to test your function</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Append the train_loss"</span><span class="p">)</span>
      <span class="c1">####################################################################</span>
      <span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># Append the loss for this epoch (running loss divided by the number of batches e.g. len(train_loader))</span>
      <span class="n">train_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>

      <span class="c1"># Evaluate on validation data</span>
      <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
      <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">validation_loader</span><span class="p">:</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">tepochs</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c1"># Get accuracy</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

      <span class="n">validation_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">validation_loader</span><span class="p">))</span>
      <span class="n">validation_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">validation_loss</span><span class="p">,</span> <span class="n">validation_acc</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your training loop</span>
<span class="c1"># net = FMNIST_Net1(num_classes=2).to(DEVICE)</span>
<span class="c1"># train_loss, train_acc, validation_loss, validation_acc = train(net, DEVICE, train_loader, validation_loader, 20)</span>
<span class="c1"># print(f'Test accuracy is: {test(net, DEVICE, test_loader)}')</span>
<span class="c1"># plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_1279086f.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_1279086f_3.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_1279086f_3.png" style="width: 2195.0px; height: 755.0px;"/></a>
</div>
<div class="section" id="think-bonus-1-overfitting">
<h2>Think! Bonus 1: Overfitting<a class="headerlink" href="#think-bonus-1-overfitting" title="Permalink to this headline">¶</a></h2>
<p>Do you think this network is overfitting?
If yes, what can you do to combat this?</p>
<p><strong>Hint</strong>: Overfitting occurs when the training accuracy greatly exceeds the validation accuracy</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_3ef24bd7.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-2-overfitting-symptoms-and-cures">
<h1>Bonus 2: Overfitting - symptoms and cures<a class="headerlink" href="#bonus-2-overfitting-symptoms-and-cures" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~30mins</em></p>
<p>So you spent some time last week learning about regularization techniques. Below is a copy of the CNN model we used previously.  Now we want you to add some dropout regularization, and check if that helps reduce overfitting. If you’re up for a challenge, you can try methods other than dropout as well.</p>
<div class="section" id="bonus-2-1-regularization">
<h2>Bonus 2.1: Regularization<a class="headerlink" href="#bonus-2-1-regularization" title="Permalink to this headline">¶</a></h2>
<div class="section" id="coding-exercise-bonus-2-1-adding-regularization">
<h3>Coding Exercise Bonus 2.1: Adding Regularization<a class="headerlink" href="#coding-exercise-bonus-2-1-adding-regularization" title="Permalink to this headline">¶</a></h3>
<p>Add various regularization methods, feel free to add any and play around!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FMNIST_Net2</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Neural Network instance</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Initialise parameters of FMNIST_Net2</span>

<span class="sd">    Args:</span>
<span class="sd">      num_classes: int</span>
<span class="sd">        Number of classes</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FMNIST_Net2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Add regularization layers"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Forward pass of FMNIST_Net2</span>

<span class="sd">    Args:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Input features</span>

<span class="sd">    Returns:</span>
<span class="sd">      x: torch.tensor</span>
<span class="sd">        Output after passing through FMNIST_Net2</span>
<span class="sd">    """</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Now add the layers in your forward pass in appropriate order</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Add regularization in the forward pass"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment below to check your code</span>
<span class="c1"># net2 = FMNIST_Net2(num_classes=2).to(DEVICE)</span>
<span class="c1"># train_loss, train_acc, validation_loss, validation_acc = train(net2, DEVICE, train_loader, validation_loader, 20)</span>
<span class="c1"># print(f'Test accuracy is: {test(net2, DEVICE, test_loader)}')</span>
<span class="c1"># plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_0adbc972.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_0adbc972_3.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_0adbc972_3.png" style="width: 2195.0px; height: 755.0px;"/></a>
</div>
<div class="section" id="think-bonus-2-1-regularization">
<h3>Think! Bonus 2.1: Regularization<a class="headerlink" href="#think-bonus-2-1-regularization" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>Is the training accuracy slightly reduced from before adding regularization? What accuracy were you able to reduce it to?</p></li>
<li><p>Why does the validation accuracy start higher than training accuracy?</p></li>
</ol>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_6e9ea2ef.py"><em>Click for solution</em></a></p>
</div>
<div class="section" id="interactive-demo-bonus-2-1-dropout-exploration">
<h3>Interactive Demo Bonus 2.1: Dropout exploration<a class="headerlink" href="#interactive-demo-bonus-2-1-dropout-exploration" title="Permalink to this headline">¶</a></h3>
<p>If you want to try out more dropout parameter combinations, but do not have the time to run them, we have here precalculated some combinations you can use the sliders to explore them.</p>
<p><em>Run this cell to enable the widget</em></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Run this cell to enable the widget*</span>

<span class="kn">import</span> <span class="nn">io</span><span class="o">,</span> <span class="nn">base64</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span><span class="p">,</span> <span class="n">interactive_output</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3495898238046372</span><span class="p">,</span> <span class="mf">0.2901147632522786</span><span class="p">,</span> <span class="mf">0.2504794800931469</span><span class="p">,</span> <span class="mf">0.23571575765914105</span><span class="p">,</span> <span class="mf">0.21297093365896255</span><span class="p">,</span> <span class="mf">0.19087818914905508</span><span class="p">,</span> <span class="mf">0.186408187797729</span><span class="p">,</span> <span class="mf">0.19487689035211472</span><span class="p">,</span> <span class="mf">0.16774938120803934</span><span class="p">,</span> <span class="mf">0.1548648244958926</span><span class="p">,</span> <span class="mf">0.1390149021382503</span><span class="p">,</span> <span class="mf">0.10919439224922593</span><span class="p">,</span> <span class="mf">0.10054351237820501</span><span class="p">,</span> <span class="mf">0.09900783193594914</span><span class="p">,</span> <span class="mf">0.08370604479507088</span><span class="p">,</span> <span class="mf">0.07831853718318521</span><span class="p">,</span> <span class="mf">0.06859792241866285</span><span class="p">,</span> <span class="mf">0.06152600247383197</span><span class="p">,</span> <span class="mf">0.046342475851873885</span><span class="p">,</span> <span class="mf">0.055123823092992796</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.83475</span><span class="p">,</span> <span class="mf">0.8659166666666667</span><span class="p">,</span> <span class="mf">0.8874166666666666</span><span class="p">,</span> <span class="mf">0.8913333333333333</span><span class="p">,</span> <span class="mf">0.8998333333333334</span><span class="p">,</span> <span class="mf">0.9140833333333334</span><span class="p">,</span> <span class="mf">0.9178333333333333</span><span class="p">,</span> <span class="mf">0.9138333333333334</span><span class="p">,</span> <span class="mf">0.9251666666666667</span><span class="p">,</span> <span class="mf">0.92975</span><span class="p">,</span> <span class="mf">0.939</span><span class="p">,</span> <span class="mf">0.9525833333333333</span><span class="p">,</span> <span class="mf">0.9548333333333333</span><span class="p">,</span> <span class="mf">0.9585833333333333</span><span class="p">,</span> <span class="mf">0.9655833333333333</span><span class="p">,</span> <span class="mf">0.9661666666666666</span><span class="p">,</span> <span class="mf">0.9704166666666667</span><span class="p">,</span> <span class="mf">0.9743333333333334</span><span class="p">,</span> <span class="mf">0.9808333333333333</span><span class="p">,</span> <span class="mf">0.9775</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.334623601436615</span><span class="p">,</span> <span class="mf">0.2977438402175903</span><span class="p">,</span> <span class="mf">0.2655304968357086</span><span class="p">,</span> <span class="mf">0.25506321132183074</span><span class="p">,</span> <span class="mf">0.2588835284113884</span><span class="p">,</span> <span class="mf">0.2336345863342285</span><span class="p">,</span> <span class="mf">0.3029863876104355</span><span class="p">,</span> <span class="mf">0.240766831189394</span><span class="p">,</span> <span class="mf">0.2719801160693169</span><span class="p">,</span> <span class="mf">0.25231350839138034</span><span class="p">,</span> <span class="mf">0.2500132185220718</span><span class="p">,</span> <span class="mf">0.26699506521224975</span><span class="p">,</span> <span class="mf">0.2934862145781517</span><span class="p">,</span> <span class="mf">0.361227530837059</span><span class="p">,</span> <span class="mf">0.33196919202804565</span><span class="p">,</span> <span class="mf">0.36985905408859254</span><span class="p">,</span> <span class="mf">0.4042587959766388</span><span class="p">,</span> <span class="mf">0.3716402840614319</span><span class="p">,</span> <span class="mf">0.3707024946808815</span><span class="p">,</span> <span class="mf">0.4652537405490875</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.866875</span><span class="p">,</span> <span class="mf">0.851875</span><span class="p">,</span> <span class="mf">0.8775</span><span class="p">,</span> <span class="mf">0.889375</span><span class="p">,</span> <span class="mf">0.881875</span><span class="p">,</span> <span class="mf">0.900625</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.885625</span><span class="p">,</span> <span class="mf">0.876875</span><span class="p">,</span> <span class="mf">0.899375</span><span class="p">,</span> <span class="mf">0.90625</span><span class="p">,</span> <span class="mf">0.89875</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.884375</span><span class="p">,</span> <span class="mf">0.874375</span><span class="p">,</span> <span class="mf">0.89375</span><span class="p">,</span> <span class="mf">0.903125</span><span class="p">,</span> <span class="mf">0.890625</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.35404509995528993</span><span class="p">,</span> <span class="mf">0.30616586227366266</span><span class="p">,</span> <span class="mf">0.2872369573946963</span><span class="p">,</span> <span class="mf">0.27564131199045383</span><span class="p">,</span> <span class="mf">0.25969504263806853</span><span class="p">,</span> <span class="mf">0.24728168408445855</span><span class="p">,</span> <span class="mf">0.23505379509260046</span><span class="p">,</span> <span class="mf">0.21552803914280647</span><span class="p">,</span> <span class="mf">0.209761732277718</span><span class="p">,</span> <span class="mf">0.19977611067526518</span><span class="p">,</span> <span class="mf">0.19632092922767427</span><span class="p">,</span> <span class="mf">0.18672360206379535</span><span class="p">,</span> <span class="mf">0.16564940239124476</span><span class="p">,</span> <span class="mf">0.1654047035671612</span><span class="p">,</span> <span class="mf">0.1684555298985636</span><span class="p">,</span> <span class="mf">0.1627526102349796</span><span class="p">,</span> <span class="mf">0.13878319327263755</span><span class="p">,</span> <span class="mf">0.12881529055773577</span><span class="p">,</span> <span class="mf">0.12628930977525862</span><span class="p">,</span> <span class="mf">0.11346105090837846</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8324166666666667</span><span class="p">,</span> <span class="mf">0.8604166666666667</span><span class="p">,</span> <span class="mf">0.8680833333333333</span><span class="p">,</span> <span class="mf">0.8728333333333333</span><span class="p">,</span> <span class="mf">0.8829166666666667</span><span class="p">,</span> <span class="mf">0.88625</span><span class="p">,</span> <span class="mf">0.89425</span><span class="p">,</span> <span class="mf">0.90125</span><span class="p">,</span> <span class="mf">0.9015833333333333</span><span class="p">,</span> <span class="mf">0.90925</span><span class="p">,</span> <span class="mf">0.9114166666666667</span><span class="p">,</span> <span class="mf">0.917</span><span class="p">,</span> <span class="mf">0.9268333333333333</span><span class="p">,</span> <span class="mf">0.92475</span><span class="p">,</span> <span class="mf">0.921</span><span class="p">,</span> <span class="mf">0.9255833333333333</span><span class="p">,</span> <span class="mf">0.9385</span><span class="p">,</span> <span class="mf">0.9428333333333333</span><span class="p">,</span> <span class="mf">0.9424166666666667</span><span class="p">,</span> <span class="mf">0.9484166666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3533937376737595</span><span class="p">,</span> <span class="mf">0.29569859683513644</span><span class="p">,</span> <span class="mf">0.27531551957130435</span><span class="p">,</span> <span class="mf">0.2576177391409874</span><span class="p">,</span> <span class="mf">0.26947550356388095</span><span class="p">,</span> <span class="mf">0.25361743807792664</span><span class="p">,</span> <span class="mf">0.2527468180656433</span><span class="p">,</span> <span class="mf">0.24179009914398195</span><span class="p">,</span> <span class="mf">0.28664454460144045</span><span class="p">,</span> <span class="mf">0.23347773611545564</span><span class="p">,</span> <span class="mf">0.24672816634178163</span><span class="p">,</span> <span class="mf">0.27822364538908007</span><span class="p">,</span> <span class="mf">0.2380720081925392</span><span class="p">,</span> <span class="mf">0.24426509588956832</span><span class="p">,</span> <span class="mf">0.2443918392062187</span><span class="p">,</span> <span class="mf">0.24207917481660843</span><span class="p">,</span> <span class="mf">0.2519641682505608</span><span class="p">,</span> <span class="mf">0.3075403380393982</span><span class="p">,</span> <span class="mf">0.2798181238770485</span><span class="p">,</span> <span class="mf">0.26709021866321564</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.826875</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.870625</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.88625</span><span class="p">,</span> <span class="mf">0.891875</span><span class="p">,</span> <span class="mf">0.891875</span><span class="p">,</span> <span class="mf">0.890625</span><span class="p">,</span> <span class="mf">0.903125</span><span class="p">,</span> <span class="mf">0.89375</span><span class="p">,</span> <span class="mf">0.885625</span><span class="p">,</span> <span class="mf">0.903125</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.899375</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.905</span><span class="p">,</span> <span class="mf">0.905625</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.901875</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.39775496332886373</span><span class="p">,</span> <span class="mf">0.33771887778284704</span><span class="p">,</span> <span class="mf">0.321900939132939</span><span class="p">,</span> <span class="mf">0.3079229625774191</span><span class="p">,</span> <span class="mf">0.304149763301966</span><span class="p">,</span> <span class="mf">0.28249239723416086</span><span class="p">,</span> <span class="mf">0.2861261191044716</span><span class="p">,</span> <span class="mf">0.27356165798103554</span><span class="p">,</span> <span class="mf">0.2654648520686525</span><span class="p">,</span> <span class="mf">0.2697350280557541</span><span class="p">,</span> <span class="mf">0.25354846321204877</span><span class="p">,</span> <span class="mf">0.24612889034633942</span><span class="p">,</span> <span class="mf">0.23482802549892284</span><span class="p">,</span> <span class="mf">0.2389904112416379</span><span class="p">,</span> <span class="mf">0.23742155821875055</span><span class="p">,</span> <span class="mf">0.232423192127905</span><span class="p">,</span> <span class="mf">0.22337309338469455</span><span class="p">,</span> <span class="mf">0.2141852991932884</span><span class="p">,</span> <span class="mf">0.20677659985549907</span><span class="p">,</span> <span class="mf">0.19355326712607068</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8155</span><span class="p">,</span> <span class="mf">0.83625</span><span class="p">,</span> <span class="mf">0.8481666666666666</span><span class="p">,</span> <span class="mf">0.8530833333333333</span><span class="p">,</span> <span class="mf">0.8571666666666666</span><span class="p">,</span> <span class="mf">0.86775</span><span class="p">,</span> <span class="mf">0.8623333333333333</span><span class="p">,</span> <span class="mf">0.8711666666666666</span><span class="p">,</span> <span class="mf">0.8748333333333334</span><span class="p">,</span> <span class="mf">0.8685833333333334</span><span class="p">,</span> <span class="mf">0.8785</span><span class="p">,</span> <span class="mf">0.8804166666666666</span><span class="p">,</span> <span class="mf">0.8835833333333334</span><span class="p">,</span> <span class="mf">0.8840833333333333</span><span class="p">,</span> <span class="mf">0.88875</span><span class="p">,</span> <span class="mf">0.8919166666666667</span><span class="p">,</span> <span class="mf">0.8946666666666667</span><span class="p">,</span> <span class="mf">0.8960833333333333</span><span class="p">,</span> <span class="mf">0.906</span><span class="p">,</span> <span class="mf">0.9063333333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3430288594961166</span><span class="p">,</span> <span class="mf">0.4062050700187683</span><span class="p">,</span> <span class="mf">0.29745822548866274</span><span class="p">,</span> <span class="mf">0.27728439271450045</span><span class="p">,</span> <span class="mf">0.28092808067798614</span><span class="p">,</span> <span class="mf">0.2577864158153534</span><span class="p">,</span> <span class="mf">0.2651400637626648</span><span class="p">,</span> <span class="mf">0.25632822573184966</span><span class="p">,</span> <span class="mf">0.3082498562335968</span><span class="p">,</span> <span class="mf">0.2812121778726578</span><span class="p">,</span> <span class="mf">0.26345942318439486</span><span class="p">,</span> <span class="mf">0.2577408078312874</span><span class="p">,</span> <span class="mf">0.25757989794015884</span><span class="p">,</span> <span class="mf">0.26434457510709763</span><span class="p">,</span> <span class="mf">0.24917411386966706</span><span class="p">,</span> <span class="mf">0.27261342853307724</span><span class="p">,</span> <span class="mf">0.2445397639274597</span><span class="p">,</span> <span class="mf">0.26001051396131514</span><span class="p">,</span> <span class="mf">0.24147838801145555</span><span class="p">,</span> <span class="mf">0.2471102523803711</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.82875</span><span class="p">,</span> <span class="mf">0.795625</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.865625</span><span class="p">,</span> <span class="mf">0.8825</span><span class="p">,</span> <span class="mf">0.8825</span><span class="p">,</span> <span class="mf">0.87625</span><span class="p">,</span> <span class="mf">0.848125</span><span class="p">,</span> <span class="mf">0.87875</span><span class="p">,</span> <span class="mf">0.8675</span><span class="p">,</span> <span class="mf">0.889375</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">,</span> <span class="mf">0.866875</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.87125</span><span class="p">,</span> <span class="mf">0.895625</span><span class="p">,</span> <span class="mf">0.90375</span><span class="p">,</span> <span class="mf">0.90125</span><span class="p">,</span> <span class="mf">0.88625</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4454924576777093</span><span class="p">,</span> <span class="mf">0.43416607585993217</span><span class="p">,</span> <span class="mf">0.42200265769311723</span><span class="p">,</span> <span class="mf">0.40520024616667566</span><span class="p">,</span> <span class="mf">0.41137005166804536</span><span class="p">,</span> <span class="mf">0.404100904280835</span><span class="p">,</span> <span class="mf">0.40118067664034823</span><span class="p">,</span> <span class="mf">0.40139733080534223</span><span class="p">,</span> <span class="mf">0.3797615355158106</span><span class="p">,</span> <span class="mf">0.3596332479030528</span><span class="p">,</span> <span class="mf">0.3600061919460905</span><span class="p">,</span> <span class="mf">0.3554147962242999</span><span class="p">,</span> <span class="mf">0.34480382890460337</span><span class="p">,</span> <span class="mf">0.3329520877054397</span><span class="p">,</span> <span class="mf">0.33164913056695716</span><span class="p">,</span> <span class="mf">0.31860941466181836</span><span class="p">,</span> <span class="mf">0.30702565340919696</span><span class="p">,</span> <span class="mf">0.30605297186907304</span><span class="p">,</span> <span class="mf">0.2953788426486736</span><span class="p">,</span> <span class="mf">0.2877389984403519</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7788333333333334</span><span class="p">,</span> <span class="mf">0.7825</span><span class="p">,</span> <span class="mf">0.7854166666666667</span><span class="p">,</span> <span class="mf">0.7916666666666666</span><span class="p">,</span> <span class="mf">0.7885</span><span class="p">,</span> <span class="mf">0.7833333333333333</span><span class="p">,</span> <span class="mf">0.7923333333333333</span><span class="p">,</span> <span class="mf">0.79525</span><span class="p">,</span> <span class="mf">0.805</span><span class="p">,</span> <span class="mf">0.81475</span><span class="p">,</span> <span class="mf">0.8161666666666667</span><span class="p">,</span> <span class="mf">0.8188333333333333</span><span class="p">,</span> <span class="mf">0.817</span><span class="p">,</span> <span class="mf">0.8266666666666667</span><span class="p">,</span> <span class="mf">0.82225</span><span class="p">,</span> <span class="mf">0.8360833333333333</span><span class="p">,</span> <span class="mf">0.8456666666666667</span><span class="p">,</span> <span class="mf">0.8430833333333333</span><span class="p">,</span> <span class="mf">0.8491666666666666</span><span class="p">,</span> <span class="mf">0.8486666666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3507828885316849</span><span class="p">,</span> <span class="mf">0.3337512403726578</span><span class="p">,</span> <span class="mf">0.34320746660232543</span><span class="p">,</span> <span class="mf">0.3476085543632507</span><span class="p">,</span> <span class="mf">0.3326113569736481</span><span class="p">,</span> <span class="mf">0.33033264458179473</span><span class="p">,</span> <span class="mf">0.32014619171619413</span><span class="p">,</span> <span class="mf">0.3182142299413681</span><span class="p">,</span> <span class="mf">0.30076164126396177</span><span class="p">,</span> <span class="mf">0.3263852882385254</span><span class="p">,</span> <span class="mf">0.27597591280937195</span><span class="p">,</span> <span class="mf">0.29062016785144806</span><span class="p">,</span> <span class="mf">0.2765174686908722</span><span class="p">,</span> <span class="mf">0.269492534995079</span><span class="p">,</span> <span class="mf">0.2679423809051514</span><span class="p">,</span> <span class="mf">0.2691828978061676</span><span class="p">,</span> <span class="mf">0.2726386785507202</span><span class="p">,</span> <span class="mf">0.2541181230545044</span><span class="p">,</span> <span class="mf">0.2580208206176758</span><span class="p">,</span> <span class="mf">0.26315389811992645</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.839375</span><span class="p">,</span> <span class="mf">0.843125</span><span class="p">,</span> <span class="mf">0.823125</span><span class="p">,</span> <span class="mf">0.821875</span><span class="p">,</span> <span class="mf">0.81875</span><span class="p">,</span> <span class="mf">0.819375</span><span class="p">,</span> <span class="mf">0.8225</span><span class="p">,</span> <span class="mf">0.826875</span><span class="p">,</span> <span class="mf">0.835625</span><span class="p">,</span> <span class="mf">0.865</span><span class="p">,</span> <span class="mf">0.868125</span><span class="p">,</span> <span class="mf">0.855625</span><span class="p">,</span> <span class="mf">0.868125</span><span class="p">,</span> <span class="mf">0.884375</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.875</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.8975</span><span class="p">,</span> <span class="mf">0.885</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.34561181647029326</span><span class="p">,</span> <span class="mf">0.2834314257699124</span><span class="p">,</span> <span class="mf">0.2583787844298368</span><span class="p">,</span> <span class="mf">0.23892096465730922</span><span class="p">,</span> <span class="mf">0.23207981773513428</span><span class="p">,</span> <span class="mf">0.20245029634617745</span><span class="p">,</span> <span class="mf">0.183908417583146</span><span class="p">,</span> <span class="mf">0.17489413774393975</span><span class="p">,</span> <span class="mf">0.17696723581707857</span><span class="p">,</span> <span class="mf">0.15615438255778652</span><span class="p">,</span> <span class="mf">0.14469048382833283</span><span class="p">,</span> <span class="mf">0.12424647461305907</span><span class="p">,</span> <span class="mf">0.11314761043189371</span><span class="p">,</span> <span class="mf">0.11249036608422373</span><span class="p">,</span> <span class="mf">0.10725672634199579</span><span class="p">,</span> <span class="mf">0.09081190969160896</span><span class="p">,</span> <span class="mf">0.0942245383271353</span><span class="p">,</span> <span class="mf">0.08525650047677312</span><span class="p">,</span> <span class="mf">0.06622548752583246</span><span class="p">,</span> <span class="mf">0.06039895973307021</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8356666666666667</span><span class="p">,</span> <span class="mf">0.8675833333333334</span><span class="p">,</span> <span class="mf">0.88175</span><span class="p">,</span> <span class="mf">0.8933333333333333</span><span class="p">,</span> <span class="mf">0.8975833333333333</span><span class="p">,</span> <span class="mf">0.91175</span><span class="p">,</span> <span class="mf">0.91825</span><span class="p">,</span> <span class="mf">0.9249166666666667</span><span class="p">,</span> <span class="mf">0.9238333333333333</span><span class="p">,</span> <span class="mf">0.9305</span><span class="p">,</span> <span class="mf">0.938</span><span class="p">,</span> <span class="mf">0.9465833333333333</span><span class="p">,</span> <span class="mf">0.9525833333333333</span><span class="p">,</span> <span class="mf">0.9539166666666666</span><span class="p">,</span> <span class="mf">0.9555</span><span class="p">,</span> <span class="mf">0.9615</span><span class="p">,</span> <span class="mf">0.9606666666666667</span><span class="p">,</span> <span class="mf">0.96275</span><span class="p">,</span> <span class="mf">0.9725</span><span class="p">,</span> <span class="mf">0.9764166666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.31630186855792997</span><span class="p">,</span> <span class="mf">0.2702121251821518</span><span class="p">,</span> <span class="mf">0.2915778249502182</span><span class="p">,</span> <span class="mf">0.26050266206264494</span><span class="p">,</span> <span class="mf">0.27837209939956664</span><span class="p">,</span> <span class="mf">0.24276352763175965</span><span class="p">,</span> <span class="mf">0.3567117482423782</span><span class="p">,</span> <span class="mf">0.2752074319124222</span><span class="p">,</span> <span class="mf">0.2423130339384079</span><span class="p">,</span> <span class="mf">0.2565067422389984</span><span class="p">,</span> <span class="mf">0.28710135877132414</span><span class="p">,</span> <span class="mf">0.266545415520668</span><span class="p">,</span> <span class="mf">0.31818037331104276</span><span class="p">,</span> <span class="mf">0.28757534325122835</span><span class="p">,</span> <span class="mf">0.2777567034959793</span><span class="p">,</span> <span class="mf">0.2998969575762749</span><span class="p">,</span> <span class="mf">0.3292293107509613</span><span class="p">,</span> <span class="mf">0.30775387287139894</span><span class="p">,</span> <span class="mf">0.32681577146053314</span><span class="p">,</span> <span class="mf">0.44882203072309496</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.85375</span><span class="p">,</span> <span class="mf">0.879375</span><span class="p">,</span> <span class="mf">0.875625</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.86125</span><span class="p">,</span> <span class="mf">0.884375</span><span class="p">,</span> <span class="mf">0.851875</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.89625</span><span class="p">,</span> <span class="mf">0.875625</span><span class="p">,</span> <span class="mf">0.8675</span><span class="p">,</span> <span class="mf">0.895</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.89125</span><span class="p">,</span> <span class="mf">0.889375</span><span class="p">,</span> <span class="mf">0.880625</span><span class="p">,</span> <span class="mf">0.87875</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.894375</span><span class="p">,</span> <span class="mf">0.891875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.35970850011452715</span><span class="p">,</span> <span class="mf">0.31336131549261986</span><span class="p">,</span> <span class="mf">0.2881505932421126</span><span class="p">,</span> <span class="mf">0.2732012960267194</span><span class="p">,</span> <span class="mf">0.26232245425753137</span><span class="p">,</span> <span class="mf">0.2490472443639598</span><span class="p">,</span> <span class="mf">0.24866499093935845</span><span class="p">,</span> <span class="mf">0.22930880945096624</span><span class="p">,</span> <span class="mf">0.21745950407645803</span><span class="p">,</span> <span class="mf">0.20700296882460725</span><span class="p">,</span> <span class="mf">0.197304340356842</span><span class="p">,</span> <span class="mf">0.20665066804182022</span><span class="p">,</span> <span class="mf">0.19864868348900308</span><span class="p">,</span> <span class="mf">0.184807124210799</span><span class="p">,</span> <span class="mf">0.1684703354703936</span><span class="p">,</span> <span class="mf">0.17377675851767369</span><span class="p">,</span> <span class="mf">0.16638460063791655</span><span class="p">,</span> <span class="mf">0.15944768343754906</span><span class="p">,</span> <span class="mf">0.14876513817208878</span><span class="p">,</span> <span class="mf">0.1388207479835825</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.83375</span><span class="p">,</span> <span class="mf">0.85175</span><span class="p">,</span> <span class="mf">0.86725</span><span class="p">,</span> <span class="mf">0.8719166666666667</span><span class="p">,</span> <span class="mf">0.8761666666666666</span><span class="p">,</span> <span class="mf">0.8865833333333333</span><span class="p">,</span> <span class="mf">0.88275</span><span class="p">,</span> <span class="mf">0.8956666666666667</span><span class="p">,</span> <span class="mf">0.8995833333333333</span><span class="p">,</span> <span class="mf">0.9034166666666666</span><span class="p">,</span> <span class="mf">0.90825</span><span class="p">,</span> <span class="mf">0.9043333333333333</span><span class="p">,</span> <span class="mf">0.9093333333333333</span><span class="p">,</span> <span class="mf">0.9145</span><span class="p">,</span> <span class="mf">0.9196666666666666</span><span class="p">,</span> <span class="mf">0.9196666666666666</span><span class="p">,</span> <span class="mf">0.9216666666666666</span><span class="p">,</span> <span class="mf">0.9273333333333333</span><span class="p">,</span> <span class="mf">0.9299166666666666</span><span class="p">,</span> <span class="mf">0.93675</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3166788029670715</span><span class="p">,</span> <span class="mf">0.28422485530376435</span><span class="p">,</span> <span class="mf">0.38055971562862395</span><span class="p">,</span> <span class="mf">0.2586472672224045</span><span class="p">,</span> <span class="mf">0.2588653892278671</span><span class="p">,</span> <span class="mf">0.27983254253864287</span><span class="p">,</span> <span class="mf">0.25693483114242555</span><span class="p">,</span> <span class="mf">0.26412731170654297</span><span class="p">,</span> <span class="mf">0.2733065390586853</span><span class="p">,</span> <span class="mf">0.24399636536836625</span><span class="p">,</span> <span class="mf">0.24481021404266357</span><span class="p">,</span> <span class="mf">0.2689305514097214</span><span class="p">,</span> <span class="mf">0.2527604129910469</span><span class="p">,</span> <span class="mf">0.24829535871744157</span><span class="p">,</span> <span class="mf">0.2654112687706947</span><span class="p">,</span> <span class="mf">0.23074268400669098</span><span class="p">,</span> <span class="mf">0.24625462979078294</span><span class="p">,</span> <span class="mf">0.26423920392990113</span><span class="p">,</span> <span class="mf">0.25540480852127073</span><span class="p">,</span> <span class="mf">0.25536185175180437</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.856875</span><span class="p">,</span> <span class="mf">0.86625</span><span class="p">,</span> <span class="mf">0.815</span><span class="p">,</span> <span class="mf">0.8825</span><span class="p">,</span> <span class="mf">0.88125</span><span class="p">,</span> <span class="mf">0.875625</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.8775</span><span class="p">,</span> <span class="mf">0.870625</span><span class="p">,</span> <span class="mf">0.895</span><span class="p">,</span> <span class="mf">0.8975</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.88625</span><span class="p">,</span> <span class="mf">0.89125</span><span class="p">,</span> <span class="mf">0.903125</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.893125</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">,</span> <span class="mf">0.899375</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3975753842040579</span><span class="p">,</span> <span class="mf">0.34884724409339274</span><span class="p">,</span> <span class="mf">0.3296900932142075</span><span class="p">,</span> <span class="mf">0.3150389680361494</span><span class="p">,</span> <span class="mf">0.31285368667003954</span><span class="p">,</span> <span class="mf">0.30415422033439293</span><span class="p">,</span> <span class="mf">0.29553352716438314</span><span class="p">,</span> <span class="mf">0.289314468094009</span><span class="p">,</span> <span class="mf">0.2806722329969102</span><span class="p">,</span> <span class="mf">0.2724469883486311</span><span class="p">,</span> <span class="mf">0.26634286379719035</span><span class="p">,</span> <span class="mf">0.2645016222241077</span><span class="p">,</span> <span class="mf">0.2619251853766594</span><span class="p">,</span> <span class="mf">0.2551752221473354</span><span class="p">,</span> <span class="mf">0.26411766035759704</span><span class="p">,</span> <span class="mf">0.24515971153023394</span><span class="p">,</span> <span class="mf">0.2390686312412962</span><span class="p">,</span> <span class="mf">0.23573122312255362</span><span class="p">,</span> <span class="mf">0.221005061562074</span><span class="p">,</span> <span class="mf">0.22358600648635246</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8106666666666666</span><span class="p">,</span> <span class="mf">0.8286666666666667</span><span class="p">,</span> <span class="mf">0.844</span><span class="p">,</span> <span class="mf">0.8513333333333334</span><span class="p">,</span> <span class="mf">0.84975</span><span class="p">,</span> <span class="mf">0.8570833333333333</span><span class="p">,</span> <span class="mf">0.8624166666666667</span><span class="p">,</span> <span class="mf">0.8626666666666667</span><span class="p">,</span> <span class="mf">0.866</span><span class="p">,</span> <span class="mf">0.8706666666666667</span><span class="p">,</span> <span class="mf">0.8738333333333334</span><span class="p">,</span> <span class="mf">0.8748333333333334</span><span class="p">,</span> <span class="mf">0.8778333333333334</span><span class="p">,</span> <span class="mf">0.8798333333333334</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.8865</span><span class="p">,</span> <span class="mf">0.8898333333333334</span><span class="p">,</span> <span class="mf">0.8885833333333333</span><span class="p">,</span> <span class="mf">0.8991666666666667</span><span class="p">,</span> <span class="mf">0.8968333333333334</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3597823417186737</span><span class="p">,</span> <span class="mf">0.31115993797779085</span><span class="p">,</span> <span class="mf">0.29929635107517244</span><span class="p">,</span> <span class="mf">0.2986589139699936</span><span class="p">,</span> <span class="mf">0.2938830828666687</span><span class="p">,</span> <span class="mf">0.28118040919303894</span><span class="p">,</span> <span class="mf">0.2711684626340866</span><span class="p">,</span> <span class="mf">0.2844697123765945</span><span class="p">,</span> <span class="mf">0.26613601863384245</span><span class="p">,</span> <span class="mf">0.2783134698867798</span><span class="p">,</span> <span class="mf">0.2540236383676529</span><span class="p">,</span> <span class="mf">0.25821100890636445</span><span class="p">,</span> <span class="mf">0.2618845862150192</span><span class="p">,</span> <span class="mf">0.2554920208454132</span><span class="p">,</span> <span class="mf">0.26543013513088226</span><span class="p">,</span> <span class="mf">0.24074569433927537</span><span class="p">,</span> <span class="mf">0.26475649774074556</span><span class="p">,</span> <span class="mf">0.25578504264354707</span><span class="p">,</span> <span class="mf">0.2648500043153763</span><span class="p">,</span> <span class="mf">0.25700133621692656</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.825</span><span class="p">,</span> <span class="mf">0.8375</span><span class="p">,</span> <span class="mf">0.85875</span><span class="p">,</span> <span class="mf">0.855625</span><span class="p">,</span> <span class="mf">0.861875</span><span class="p">,</span> <span class="mf">0.868125</span><span class="p">,</span> <span class="mf">0.875</span><span class="p">,</span> <span class="mf">0.85375</span><span class="p">,</span> <span class="mf">0.886875</span><span class="p">,</span> <span class="mf">0.86375</span><span class="p">,</span> <span class="mf">0.88375</span><span class="p">,</span> <span class="mf">0.885625</span><span class="p">,</span> <span class="mf">0.875625</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.895</span><span class="p">,</span> <span class="mf">0.874375</span><span class="p">,</span> <span class="mf">0.89125</span><span class="p">,</span> <span class="mf">0.88625</span><span class="p">,</span> <span class="mf">0.895625</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4584837538447786</span><span class="p">,</span> <span class="mf">0.4506375778545725</span><span class="p">,</span> <span class="mf">0.4378386567089152</span><span class="p">,</span> <span class="mf">0.4066803843734112</span><span class="p">,</span> <span class="mf">0.3897064097542712</span><span class="p">,</span> <span class="mf">0.3855383962868376</span><span class="p">,</span> <span class="mf">0.39160584618753574</span><span class="p">,</span> <span class="mf">0.3731403942120836</span><span class="p">,</span> <span class="mf">0.37915910170116324</span><span class="p">,</span> <span class="mf">0.36966170814443144</span><span class="p">,</span> <span class="mf">0.35735995298687445</span><span class="p">,</span> <span class="mf">0.35630573094525236</span><span class="p">,</span> <span class="mf">0.346426092167484</span><span class="p">,</span> <span class="mf">0.34040802899510303</span><span class="p">,</span> <span class="mf">0.32829743726773464</span><span class="p">,</span> <span class="mf">0.3284692421872565</span><span class="p">,</span> <span class="mf">0.3186114077713895</span><span class="p">,</span> <span class="mf">0.32295761503120685</span><span class="p">,</span> <span class="mf">0.3201326223764014</span><span class="p">,</span> <span class="mf">0.30581602454185486</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7803333333333333</span><span class="p">,</span> <span class="mf">0.7709166666666667</span><span class="p">,</span> <span class="mf">0.7723333333333333</span><span class="p">,</span> <span class="mf">0.7850833333333334</span><span class="p">,</span> <span class="mf">0.7885</span><span class="p">,</span> <span class="mf">0.7903333333333333</span><span class="p">,</span> <span class="mf">0.7986666666666666</span><span class="p">,</span> <span class="mf">0.805</span><span class="p">,</span> <span class="mf">0.8011666666666667</span><span class="p">,</span> <span class="mf">0.8068333333333333</span><span class="p">,</span> <span class="mf">0.8095833333333333</span><span class="p">,</span> <span class="mf">0.8226666666666667</span><span class="p">,</span> <span class="mf">0.8285</span><span class="p">,</span> <span class="mf">0.83125</span><span class="p">,</span> <span class="mf">0.8369166666666666</span><span class="p">,</span> <span class="mf">0.8395</span><span class="p">,</span> <span class="mf">0.8441666666666666</span><span class="p">,</span> <span class="mf">0.8393333333333334</span><span class="p">,</span> <span class="mf">0.8490833333333333</span><span class="p">,</span> <span class="mf">0.8546666666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.43526833415031435</span><span class="p">,</span> <span class="mf">0.3598956459760666</span><span class="p">,</span> <span class="mf">0.3492005372047424</span><span class="p">,</span> <span class="mf">0.33501910269260404</span><span class="p">,</span> <span class="mf">0.31689528703689573</span><span class="p">,</span> <span class="mf">0.3113307124376297</span><span class="p">,</span> <span class="mf">0.32388085544109346</span><span class="p">,</span> <span class="mf">0.3084335786104202</span><span class="p">,</span> <span class="mf">0.3013568025827408</span><span class="p">,</span> <span class="mf">0.28992725372314454</span><span class="p">,</span> <span class="mf">0.28726822674274444</span><span class="p">,</span> <span class="mf">0.26945948660373686</span><span class="p">,</span> <span class="mf">0.276592333316803</span><span class="p">,</span> <span class="mf">0.27462401330471037</span><span class="p">,</span> <span class="mf">0.27574350595474245</span><span class="p">,</span> <span class="mf">0.2710308712720871</span><span class="p">,</span> <span class="mf">0.2702724140882492</span><span class="p">,</span> <span class="mf">0.27323003828525544</span><span class="p">,</span> <span class="mf">0.25551479041576386</span><span class="p">,</span> <span class="mf">0.26488787233829497</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.808125</span><span class="p">,</span> <span class="mf">0.81625</span><span class="p">,</span> <span class="mf">0.805</span><span class="p">,</span> <span class="mf">0.8325</span><span class="p">,</span> <span class="mf">0.846875</span><span class="p">,</span> <span class="mf">0.835625</span><span class="p">,</span> <span class="mf">0.850625</span><span class="p">,</span> <span class="mf">0.838125</span><span class="p">,</span> <span class="mf">0.836875</span><span class="p">,</span> <span class="mf">0.861875</span><span class="p">,</span> <span class="mf">0.85375</span><span class="p">,</span> <span class="mf">0.866875</span><span class="p">,</span> <span class="mf">0.858125</span><span class="p">,</span> <span class="mf">0.8825</span><span class="p">,</span> <span class="mf">0.879375</span><span class="p">,</span> <span class="mf">0.874375</span><span class="p">,</span> <span class="mf">0.874375</span><span class="p">,</span> <span class="mf">0.886875</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.86875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3579516930783049</span><span class="p">,</span> <span class="mf">0.29596046564426826</span><span class="p">,</span> <span class="mf">0.2779693031247626</span><span class="p">,</span> <span class="mf">0.2563994538356015</span><span class="p">,</span> <span class="mf">0.24771526356802342</span><span class="p">,</span> <span class="mf">0.2324555875693864</span><span class="p">,</span> <span class="mf">0.2139121579362991</span><span class="p">,</span> <span class="mf">0.20474095547452886</span><span class="p">,</span> <span class="mf">0.19138856208387842</span><span class="p">,</span> <span class="mf">0.18883306279461434</span><span class="p">,</span> <span class="mf">0.1763652620757831</span><span class="p">,</span> <span class="mf">0.1698919345248253</span><span class="p">,</span> <span class="mf">0.16033914366221808</span><span class="p">,</span> <span class="mf">0.1557997044651432</span><span class="p">,</span> <span class="mf">0.1432509447467771</span><span class="p">,</span> <span class="mf">0.13817814606776896</span><span class="p">,</span> <span class="mf">0.12609625801919622</span><span class="p">,</span> <span class="mf">0.11830132696381275</span><span class="p">,</span> <span class="mf">0.11182412960903441</span><span class="p">,</span> <span class="mf">0.112559904720872</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8314166666666667</span><span class="p">,</span> <span class="mf">0.8611666666666666</span><span class="p">,</span> <span class="mf">0.8736666666666667</span><span class="p">,</span> <span class="mf">0.8800833333333333</span><span class="p">,</span> <span class="mf">0.885</span><span class="p">,</span> <span class="mf">0.8944166666666666</span><span class="p">,</span> <span class="mf">0.9036666666666666</span><span class="p">,</span> <span class="mf">0.9090833333333334</span><span class="p">,</span> <span class="mf">0.9193333333333333</span><span class="p">,</span> <span class="mf">0.9161666666666667</span><span class="p">,</span> <span class="mf">0.92225</span><span class="p">,</span> <span class="mf">0.9255</span><span class="p">,</span> <span class="mf">0.93075</span><span class="p">,</span> <span class="mf">0.93225</span><span class="p">,</span> <span class="mf">0.939</span><span class="p">,</span> <span class="mf">0.9414166666666667</span><span class="p">,</span> <span class="mf">0.94375</span><span class="p">,</span> <span class="mf">0.9485833333333333</span><span class="p">,</span> <span class="mf">0.9535833333333333</span><span class="p">,</span> <span class="mf">0.9524166666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.30677567660808563</span><span class="p">,</span> <span class="mf">0.32954772651195524</span><span class="p">,</span> <span class="mf">0.25747098088264464</span><span class="p">,</span> <span class="mf">0.2736126834154129</span><span class="p">,</span> <span class="mf">0.2561805549263954</span><span class="p">,</span> <span class="mf">0.23671718776226044</span><span class="p">,</span> <span class="mf">0.24553639352321624</span><span class="p">,</span> <span class="mf">0.2338863667845726</span><span class="p">,</span> <span class="mf">0.24586652517318724</span><span class="p">,</span> <span class="mf">0.23423030972480774</span><span class="p">,</span> <span class="mf">0.26579618513584136</span><span class="p">,</span> <span class="mf">0.2781539523601532</span><span class="p">,</span> <span class="mf">0.27084136098623274</span><span class="p">,</span> <span class="mf">0.23948652744293214</span><span class="p">,</span> <span class="mf">0.26023868829011915</span><span class="p">,</span> <span class="mf">0.2419952344894409</span><span class="p">,</span> <span class="mf">0.2511997854709625</span><span class="p">,</span> <span class="mf">0.23935708701610564</span><span class="p">,</span> <span class="mf">0.2701922015845776</span><span class="p">,</span> <span class="mf">0.27307246536016466</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.870625</span><span class="p">,</span> <span class="mf">0.855625</span><span class="p">,</span> <span class="mf">0.886875</span><span class="p">,</span> <span class="mf">0.875625</span><span class="p">,</span> <span class="mf">0.878125</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">,</span> <span class="mf">0.885</span><span class="p">,</span> <span class="mf">0.890625</span><span class="p">,</span> <span class="mf">0.876875</span><span class="p">,</span> <span class="mf">0.896875</span><span class="p">,</span> <span class="mf">0.881875</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.896875</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.89875</span><span class="p">,</span> <span class="mf">0.904375</span><span class="p">,</span> <span class="mf">0.906875</span><span class="p">,</span> <span class="mf">0.894375</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3712943946903056</span><span class="p">,</span> <span class="mf">0.3198322071594761</span><span class="p">,</span> <span class="mf">0.29978102302931725</span><span class="p">,</span> <span class="mf">0.295274139798068</span><span class="p">,</span> <span class="mf">0.2861913934032968</span><span class="p">,</span> <span class="mf">0.27165328782606635</span><span class="p">,</span> <span class="mf">0.25972246442069397</span><span class="p">,</span> <span class="mf">0.2543164194819141</span><span class="p">,</span> <span class="mf">0.24795781916126292</span><span class="p">,</span> <span class="mf">0.24630710007028378</span><span class="p">,</span> <span class="mf">0.23296909834793272</span><span class="p">,</span> <span class="mf">0.23382153587931015</span><span class="p">,</span> <span class="mf">0.2239028559799524</span><span class="p">,</span> <span class="mf">0.21443849290780564</span><span class="p">,</span> <span class="mf">0.2149274461367663</span><span class="p">,</span> <span class="mf">0.20642021417300752</span><span class="p">,</span> <span class="mf">0.19801520536396097</span><span class="p">,</span> <span class="mf">0.1978839404009124</span><span class="p">,</span> <span class="mf">0.19118623847657062</span><span class="p">,</span> <span class="mf">0.18144798041024107</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8235833333333333</span><span class="p">,</span> <span class="mf">0.8538333333333333</span><span class="p">,</span> <span class="mf">0.8604166666666667</span><span class="p">,</span> <span class="mf">0.86075</span><span class="p">,</span> <span class="mf">0.8664166666666666</span><span class="p">,</span> <span class="mf">0.8754166666666666</span><span class="p">,</span> <span class="mf">0.8799166666666667</span><span class="p">,</span> <span class="mf">0.8815833333333334</span><span class="p">,</span> <span class="mf">0.88725</span><span class="p">,</span> <span class="mf">0.8848333333333334</span><span class="p">,</span> <span class="mf">0.8936666666666667</span><span class="p">,</span> <span class="mf">0.8935</span><span class="p">,</span> <span class="mf">0.895</span><span class="p">,</span> <span class="mf">0.8995</span><span class="p">,</span> <span class="mf">0.89625</span><span class="p">,</span> <span class="mf">0.9068333333333334</span><span class="p">,</span> <span class="mf">0.9098333333333334</span><span class="p">,</span> <span class="mf">0.9120833333333334</span><span class="p">,</span> <span class="mf">0.91375</span><span class="p">,</span> <span class="mf">0.9175833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3184810388088226</span><span class="p">,</span> <span class="mf">0.2948088157176971</span><span class="p">,</span> <span class="mf">0.29438531696796416</span><span class="p">,</span> <span class="mf">0.27669853866100313</span><span class="p">,</span> <span class="mf">0.2634278678894043</span><span class="p">,</span> <span class="mf">0.25847582578659056</span><span class="p">,</span> <span class="mf">0.2500907778739929</span><span class="p">,</span> <span class="mf">0.2538330048322678</span><span class="p">,</span> <span class="mf">0.25127841770648957</span><span class="p">,</span> <span class="mf">0.2519759064912796</span><span class="p">,</span> <span class="mf">0.2455715072154999</span><span class="p">,</span> <span class="mf">0.2437664610147476</span><span class="p">,</span> <span class="mf">0.259639236330986</span><span class="p">,</span> <span class="mf">0.24515749186277389</span><span class="p">,</span> <span class="mf">0.2553828465938568</span><span class="p">,</span> <span class="mf">0.2324645048379898</span><span class="p">,</span> <span class="mf">0.24492083072662355</span><span class="p">,</span> <span class="mf">0.24482838332653045</span><span class="p">,</span> <span class="mf">0.23327024638652802</span><span class="p">,</span> <span class="mf">0.2520161652565002</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.855</span><span class="p">,</span> <span class="mf">0.865</span><span class="p">,</span> <span class="mf">0.8525</span><span class="p">,</span> <span class="mf">0.856875</span><span class="p">,</span> <span class="mf">0.876875</span><span class="p">,</span> <span class="mf">0.88125</span><span class="p">,</span> <span class="mf">0.8825</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">,</span> <span class="mf">0.88875</span><span class="p">,</span> <span class="mf">0.889375</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.895</span><span class="p">,</span> <span class="mf">0.889375</span><span class="p">,</span> <span class="mf">0.90625</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.895</span><span class="p">,</span> <span class="mf">0.899375</span><span class="p">,</span> <span class="mf">0.901875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.40442772225496615</span><span class="p">,</span> <span class="mf">0.36662670541951</span><span class="p">,</span> <span class="mf">0.355034276367502</span><span class="p">,</span> <span class="mf">0.3396551510755052</span><span class="p">,</span> <span class="mf">0.3378269396563794</span><span class="p">,</span> <span class="mf">0.32084332002287214</span><span class="p">,</span> <span class="mf">0.31314464951766297</span><span class="p">,</span> <span class="mf">0.2982726935693558</span><span class="p">,</span> <span class="mf">0.2885229691387491</span><span class="p">,</span> <span class="mf">0.2888992782285873</span><span class="p">,</span> <span class="mf">0.2893476904706752</span><span class="p">,</span> <span class="mf">0.281817957996688</span><span class="p">,</span> <span class="mf">0.2771622718490185</span><span class="p">,</span> <span class="mf">0.2693793097550565</span><span class="p">,</span> <span class="mf">0.2617615883416952</span><span class="p">,</span> <span class="mf">0.2657115764995205</span><span class="p">,</span> <span class="mf">0.25631817549150043</span><span class="p">,</span> <span class="mf">0.24793559907281654</span><span class="p">,</span> <span class="mf">0.2538738044652533</span><span class="p">,</span> <span class="mf">0.23912971732305718</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8093333333333333</span><span class="p">,</span> <span class="mf">0.82825</span><span class="p">,</span> <span class="mf">0.8341666666666666</span><span class="p">,</span> <span class="mf">0.84525</span><span class="p">,</span> <span class="mf">0.84525</span><span class="p">,</span> <span class="mf">0.8515</span><span class="p">,</span> <span class="mf">0.8583333333333333</span><span class="p">,</span> <span class="mf">0.8626666666666667</span><span class="p">,</span> <span class="mf">0.8688333333333333</span><span class="p">,</span> <span class="mf">0.8685</span><span class="p">,</span> <span class="mf">0.8689166666666667</span><span class="p">,</span> <span class="mf">0.8693333333333333</span><span class="p">,</span> <span class="mf">0.8711666666666666</span><span class="p">,</span> <span class="mf">0.8766666666666667</span><span class="p">,</span> <span class="mf">0.88275</span><span class="p">,</span> <span class="mf">0.88175</span><span class="p">,</span> <span class="mf">0.8839166666666667</span><span class="p">,</span> <span class="mf">0.8866666666666667</span><span class="p">,</span> <span class="mf">0.8839166666666667</span><span class="p">,</span> <span class="mf">0.8929166666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.38392188608646394</span><span class="p">,</span> <span class="mf">0.3653419762849808</span><span class="p">,</span> <span class="mf">0.3050421380996704</span><span class="p">,</span> <span class="mf">0.30614266455173494</span><span class="p">,</span> <span class="mf">0.2937217426300049</span><span class="p">,</span> <span class="mf">0.30008585572242735</span><span class="p">,</span> <span class="mf">0.2794034606218338</span><span class="p">,</span> <span class="mf">0.27541795969009397</span><span class="p">,</span> <span class="mf">0.31378355383872986</span><span class="p">,</span> <span class="mf">0.2670704126358032</span><span class="p">,</span> <span class="mf">0.26745485186576845</span><span class="p">,</span> <span class="mf">0.2471194839477539</span><span class="p">,</span> <span class="mf">0.26509816259145735</span><span class="p">,</span> <span class="mf">0.25458798944950106</span><span class="p">,</span> <span class="mf">0.2481587851047516</span><span class="p">,</span> <span class="mf">0.25591064751148224</span><span class="p">,</span> <span class="mf">0.2596563971042633</span><span class="p">,</span> <span class="mf">0.2569611769914627</span><span class="p">,</span> <span class="mf">0.2435744071006775</span><span class="p">,</span> <span class="mf">0.2507249677181244</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.820625</span><span class="p">,</span> <span class="mf">0.846875</span><span class="p">,</span> <span class="mf">0.856875</span><span class="p">,</span> <span class="mf">0.868125</span><span class="p">,</span> <span class="mf">0.860625</span><span class="p">,</span> <span class="mf">0.87125</span><span class="p">,</span> <span class="mf">0.86625</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.865625</span><span class="p">,</span> <span class="mf">0.87875</span><span class="p">,</span> <span class="mf">0.878125</span><span class="p">,</span> <span class="mf">0.889375</span><span class="p">,</span> <span class="mf">0.87875</span><span class="p">,</span> <span class="mf">0.886875</span><span class="p">,</span> <span class="mf">0.89125</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.87375</span><span class="p">,</span> <span class="mf">0.884375</span><span class="p">,</span> <span class="mf">0.88875</span><span class="p">,</span> <span class="mf">0.89375</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.46106574311852455</span><span class="p">,</span> <span class="mf">0.4519433615372536</span><span class="p">,</span> <span class="mf">0.4446939624687459</span><span class="p">,</span> <span class="mf">0.4284856241751224</span><span class="p">,</span> <span class="mf">0.4527993325857406</span><span class="p">,</span> <span class="mf">0.4220876024758562</span><span class="p">,</span> <span class="mf">0.40969764266876463</span><span class="p">,</span> <span class="mf">0.39233948219012704</span><span class="p">,</span> <span class="mf">0.42498463344700793</span><span class="p">,</span> <span class="mf">0.3869199570506177</span><span class="p">,</span> <span class="mf">0.38021832910623954</span><span class="p">,</span> <span class="mf">0.3855376149270129</span><span class="p">,</span> <span class="mf">0.3721433773319772</span><span class="p">,</span> <span class="mf">0.3662295250340979</span><span class="p">,</span> <span class="mf">0.3629763710530514</span><span class="p">,</span> <span class="mf">0.358500304691335</span><span class="p">,</span> <span class="mf">0.3490118366131123</span><span class="p">,</span> <span class="mf">0.34879197790584665</span><span class="p">,</span> <span class="mf">0.33399240054348683</span><span class="p">,</span> <span class="mf">0.3347948451149971</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7866666666666666</span><span class="p">,</span> <span class="mf">0.7865</span><span class="p">,</span> <span class="mf">0.784</span><span class="p">,</span> <span class="mf">0.79375</span><span class="p">,</span> <span class="mf">0.7755833333333333</span><span class="p">,</span> <span class="mf">0.79125</span><span class="p">,</span> <span class="mf">0.7973333333333333</span><span class="p">,</span> <span class="mf">0.8085833333333333</span><span class="p">,</span> <span class="mf">0.7913333333333333</span><span class="p">,</span> <span class="mf">0.8125833333333333</span><span class="p">,</span> <span class="mf">0.81675</span><span class="p">,</span> <span class="mf">0.812</span><span class="p">,</span> <span class="mf">0.8173333333333334</span><span class="p">,</span> <span class="mf">0.8235833333333333</span><span class="p">,</span> <span class="mf">0.831</span><span class="p">,</span> <span class="mf">0.8306666666666667</span><span class="p">,</span> <span class="mf">0.8353333333333334</span><span class="p">,</span> <span class="mf">0.8320833333333333</span><span class="p">,</span> <span class="mf">0.84375</span><span class="p">,</span> <span class="mf">0.8410833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.35159709095954894</span><span class="p">,</span> <span class="mf">0.3579048192501068</span><span class="p">,</span> <span class="mf">0.3501501774787903</span><span class="p">,</span> <span class="mf">0.33594816565513613</span><span class="p">,</span> <span class="mf">0.3741619431972504</span><span class="p">,</span> <span class="mf">0.34183687329292295</span><span class="p">,</span> <span class="mf">0.3353554099798203</span><span class="p">,</span> <span class="mf">0.32617265462875367</span><span class="p">,</span> <span class="mf">0.3640907108783722</span><span class="p">,</span> <span class="mf">0.33187183618545535</span><span class="p">,</span> <span class="mf">0.32401839792728426</span><span class="p">,</span> <span class="mf">0.30536725163459777</span><span class="p">,</span> <span class="mf">0.31303414940834046</span><span class="p">,</span> <span class="mf">0.2893040508031845</span><span class="p">,</span> <span class="mf">0.3063929396867752</span><span class="p">,</span> <span class="mf">0.2909839802980423</span><span class="p">,</span> <span class="mf">0.2858921372890472</span><span class="p">,</span> <span class="mf">0.2850045281648636</span><span class="p">,</span> <span class="mf">0.28049838364124297</span><span class="p">,</span> <span class="mf">0.2873564797639847</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.816875</span><span class="p">,</span> <span class="mf">0.793125</span><span class="p">,</span> <span class="mf">0.810625</span><span class="p">,</span> <span class="mf">0.821875</span><span class="p">,</span> <span class="mf">0.8175</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.816875</span><span class="p">,</span> <span class="mf">0.814375</span><span class="p">,</span> <span class="mf">0.828125</span><span class="p">,</span> <span class="mf">0.83875</span><span class="p">,</span> <span class="mf">0.818125</span><span class="p">,</span> <span class="mf">0.843125</span><span class="p">,</span> <span class="mf">0.834375</span><span class="p">,</span> <span class="mf">0.85875</span><span class="p">,</span> <span class="mf">0.874375</span><span class="p">,</span> <span class="mf">0.85375</span><span class="p">,</span> <span class="mf">0.870625</span><span class="p">,</span> <span class="mf">0.85375</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.848125</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.37716902824158366</span><span class="p">,</span> <span class="mf">0.3260373148195287</span><span class="p">,</span> <span class="mf">0.3128290904012132</span><span class="p">,</span> <span class="mf">0.2998493126732238</span><span class="p">,</span> <span class="mf">0.29384377892030045</span><span class="p">,</span> <span class="mf">0.2759418967873492</span><span class="p">,</span> <span class="mf">0.26431119905665834</span><span class="p">,</span> <span class="mf">0.2577077782455277</span><span class="p">,</span> <span class="mf">0.25772295725789474</span><span class="p">,</span> <span class="mf">0.24954422610871335</span><span class="p">,</span> <span class="mf">0.24065862928933285</span><span class="p">,</span> <span class="mf">0.23703582263848882</span><span class="p">,</span> <span class="mf">0.23237684028262787</span><span class="p">,</span> <span class="mf">0.2200249534575863</span><span class="p">,</span> <span class="mf">0.22110319957929722</span><span class="p">,</span> <span class="mf">0.21804759631607126</span><span class="p">,</span> <span class="mf">0.21419822757548473</span><span class="p">,</span> <span class="mf">0.19927451733816812</span><span class="p">,</span> <span class="mf">0.19864692467641323</span><span class="p">,</span> <span class="mf">0.18966749441274938</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8215833333333333</span><span class="p">,</span> <span class="mf">0.848</span><span class="p">,</span> <span class="mf">0.8526666666666667</span><span class="p">,</span> <span class="mf">0.8585</span><span class="p">,</span> <span class="mf">0.8639166666666667</span><span class="p">,</span> <span class="mf">0.8716666666666667</span><span class="p">,</span> <span class="mf">0.8783333333333333</span><span class="p">,</span> <span class="mf">0.8849166666666667</span><span class="p">,</span> <span class="mf">0.88325</span><span class="p">,</span> <span class="mf">0.88325</span><span class="p">,</span> <span class="mf">0.8918333333333334</span><span class="p">,</span> <span class="mf">0.8913333333333333</span><span class="p">,</span> <span class="mf">0.896</span><span class="p">,</span> <span class="mf">0.9010833333333333</span><span class="p">,</span> <span class="mf">0.8996666666666666</span><span class="p">,</span> <span class="mf">0.9016666666666666</span><span class="p">,</span> <span class="mf">0.902</span><span class="p">,</span> <span class="mf">0.9120833333333334</span><span class="p">,</span> <span class="mf">0.9105833333333333</span><span class="p">,</span> <span class="mf">0.9160833333333334</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3255926352739334</span><span class="p">,</span> <span class="mf">0.3397491586208343</span><span class="p">,</span> <span class="mf">0.3148202610015869</span><span class="p">,</span> <span class="mf">0.30447013437747955</span><span class="p">,</span> <span class="mf">0.27427292466163633</span><span class="p">,</span> <span class="mf">0.2607581865787506</span><span class="p">,</span> <span class="mf">0.2583494257926941</span><span class="p">,</span> <span class="mf">0.24150457441806794</span><span class="p">,</span> <span class="mf">0.24839721441268922</span><span class="p">,</span> <span class="mf">0.24157819360494615</span><span class="p">,</span> <span class="mf">0.24594406485557557</span><span class="p">,</span> <span class="mf">0.2547012311220169</span><span class="p">,</span> <span class="mf">0.24132476687431337</span><span class="p">,</span> <span class="mf">0.2433958488702774</span><span class="p">,</span> <span class="mf">0.2358475297689438</span><span class="p">,</span> <span class="mf">0.24675665378570558</span><span class="p">,</span> <span class="mf">0.23343635857105255</span><span class="p">,</span> <span class="mf">0.22841362684965133</span><span class="p">,</span> <span class="mf">0.2247604575753212</span><span class="p">,</span> <span class="mf">0.24281086921691894</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.85125</span><span class="p">,</span> <span class="mf">0.85125</span><span class="p">,</span> <span class="mf">0.853125</span><span class="p">,</span> <span class="mf">0.851875</span><span class="p">,</span> <span class="mf">0.876875</span><span class="p">,</span> <span class="mf">0.87875</span><span class="p">,</span> <span class="mf">0.883125</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.89</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.88375</span><span class="p">,</span> <span class="mf">0.86625</span><span class="p">,</span> <span class="mf">0.88375</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.88875</span><span class="p">,</span> <span class="mf">0.896875</span><span class="p">,</span> <span class="mf">0.894375</span><span class="p">,</span> <span class="mf">0.899375</span><span class="p">,</span> <span class="mf">0.88625</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3795942336796446</span><span class="p">,</span> <span class="mf">0.33614943612446174</span><span class="p">,</span> <span class="mf">0.3235826115024851</span><span class="p">,</span> <span class="mf">0.3267444484728448</span><span class="p">,</span> <span class="mf">0.30353531146303137</span><span class="p">,</span> <span class="mf">0.29750882636042353</span><span class="p">,</span> <span class="mf">0.2964640334248543</span><span class="p">,</span> <span class="mf">0.28714796314214136</span><span class="p">,</span> <span class="mf">0.2744278162717819</span><span class="p">,</span> <span class="mf">0.27310871372514584</span><span class="p">,</span> <span class="mf">0.2624819800257683</span><span class="p">,</span> <span class="mf">0.2579742945889209</span><span class="p">,</span> <span class="mf">0.25963644726954876</span><span class="p">,</span> <span class="mf">0.25635017161356644</span><span class="p">,</span> <span class="mf">0.2501001837960583</span><span class="p">,</span> <span class="mf">0.24249463702769988</span><span class="p">,</span> <span class="mf">0.23696896695393196</span><span class="p">,</span> <span class="mf">0.23254455582417072</span><span class="p">,</span> <span class="mf">0.22419108628751117</span><span class="p">,</span> <span class="mf">0.22851746232110134</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8204166666666667</span><span class="p">,</span> <span class="mf">0.839</span><span class="p">,</span> <span class="mf">0.847</span><span class="p">,</span> <span class="mf">0.8506666666666667</span><span class="p">,</span> <span class="mf">0.8571666666666666</span><span class="p">,</span> <span class="mf">0.8635</span><span class="p">,</span> <span class="mf">0.8639166666666667</span><span class="p">,</span> <span class="mf">0.8711666666666666</span><span class="p">,</span> <span class="mf">0.8711666666666666</span><span class="p">,</span> <span class="mf">0.87475</span><span class="p">,</span> <span class="mf">0.87875</span><span class="p">,</span> <span class="mf">0.87925</span><span class="p">,</span> <span class="mf">0.8805833333333334</span><span class="p">,</span> <span class="mf">0.8845</span><span class="p">,</span> <span class="mf">0.88675</span><span class="p">,</span> <span class="mf">0.8908333333333334</span><span class="p">,</span> <span class="mf">0.8926666666666667</span><span class="p">,</span> <span class="mf">0.89525</span><span class="p">,</span> <span class="mf">0.8985</span><span class="p">,</span> <span class="mf">0.8955833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3383863967657089</span><span class="p">,</span> <span class="mf">0.31120560944080355</span><span class="p">,</span> <span class="mf">0.32110977828502657</span><span class="p">,</span> <span class="mf">0.3080899566411972</span><span class="p">,</span> <span class="mf">0.2866462391614914</span><span class="p">,</span> <span class="mf">0.27701647162437437</span><span class="p">,</span> <span class="mf">0.29040718913078306</span><span class="p">,</span> <span class="mf">0.2702513742446899</span><span class="p">,</span> <span class="mf">0.2590403389930725</span><span class="p">,</span> <span class="mf">0.26199558019638064</span><span class="p">,</span> <span class="mf">0.26484714448451996</span><span class="p">,</span> <span class="mf">0.2940529054403305</span><span class="p">,</span> <span class="mf">0.2654808533191681</span><span class="p">,</span> <span class="mf">0.25154681205749513</span><span class="p">,</span> <span class="mf">0.26637687146663663</span><span class="p">,</span> <span class="mf">0.24435366928577423</span><span class="p">,</span> <span class="mf">0.24174826145172118</span><span class="p">,</span> <span class="mf">0.2444209086894989</span><span class="p">,</span> <span class="mf">0.247626873254776</span><span class="p">,</span> <span class="mf">0.24192263156175614</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.843125</span><span class="p">,</span> <span class="mf">0.8575</span><span class="p">,</span> <span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.86375</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.875625</span><span class="p">,</span> <span class="mf">0.865</span><span class="p">,</span> <span class="mf">0.88</span><span class="p">,</span> <span class="mf">0.879375</span><span class="p">,</span> <span class="mf">0.885</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.85625</span><span class="p">,</span> <span class="mf">0.87625</span><span class="p">,</span> <span class="mf">0.88375</span><span class="p">,</span> <span class="mf">0.879375</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.886875</span><span class="p">,</span> <span class="mf">0.8825</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.41032169133107715</span><span class="p">,</span> <span class="mf">0.37122817583223605</span><span class="p">,</span> <span class="mf">0.35897897873470125</span><span class="p">,</span> <span class="mf">0.3438001747064768</span><span class="p">,</span> <span class="mf">0.33858899811797954</span><span class="p">,</span> <span class="mf">0.3389760729797343</span><span class="p">,</span> <span class="mf">0.32536247420184156</span><span class="p">,</span> <span class="mf">0.3152934226425404</span><span class="p">,</span> <span class="mf">0.30936657058748795</span><span class="p">,</span> <span class="mf">0.3078679118226183</span><span class="p">,</span> <span class="mf">0.30974164977669716</span><span class="p">,</span> <span class="mf">0.30031369174731537</span><span class="p">,</span> <span class="mf">0.29489042173991814</span><span class="p">,</span> <span class="mf">0.28921707251921613</span><span class="p">,</span> <span class="mf">0.28369594476324445</span><span class="p">,</span> <span class="mf">0.2849519875772456</span><span class="p">,</span> <span class="mf">0.27076949349584734</span><span class="p">,</span> <span class="mf">0.26930386248104116</span><span class="p">,</span> <span class="mf">0.26349931491657774</span><span class="p">,</span> <span class="mf">0.26431971300948176</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8086666666666666</span><span class="p">,</span> <span class="mf">0.82875</span><span class="p">,</span> <span class="mf">0.8284166666666667</span><span class="p">,</span> <span class="mf">0.8381666666666666</span><span class="p">,</span> <span class="mf">0.837</span><span class="p">,</span> <span class="mf">0.8389166666666666</span><span class="p">,</span> <span class="mf">0.8490833333333333</span><span class="p">,</span> <span class="mf">0.8488333333333333</span><span class="p">,</span> <span class="mf">0.8533333333333334</span><span class="p">,</span> <span class="mf">0.8551666666666666</span><span class="p">,</span> <span class="mf">0.8509166666666667</span><span class="p">,</span> <span class="mf">0.8615</span><span class="p">,</span> <span class="mf">0.8628333333333333</span><span class="p">,</span> <span class="mf">0.86225</span><span class="p">,</span> <span class="mf">0.8715</span><span class="p">,</span> <span class="mf">0.86775</span><span class="p">,</span> <span class="mf">0.8748333333333334</span><span class="p">,</span> <span class="mf">0.8719166666666667</span><span class="p">,</span> <span class="mf">0.8814166666666666</span><span class="p">,</span> <span class="mf">0.8835</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3464747530221939</span><span class="p">,</span> <span class="mf">0.3193131250143051</span><span class="p">,</span> <span class="mf">0.3464068531990051</span><span class="p">,</span> <span class="mf">0.3129056388139725</span><span class="p">,</span> <span class="mf">0.3131117367744446</span><span class="p">,</span> <span class="mf">0.30689118325710296</span><span class="p">,</span> <span class="mf">0.2929005026817322</span><span class="p">,</span> <span class="mf">0.3131696957349777</span><span class="p">,</span> <span class="mf">0.302835636138916</span><span class="p">,</span> <span class="mf">0.27934255003929137</span><span class="p">,</span> <span class="mf">0.300513002872467</span><span class="p">,</span> <span class="mf">0.26962003886699676</span><span class="p">,</span> <span class="mf">0.2676294481754303</span><span class="p">,</span> <span class="mf">0.26430738389492037</span><span class="p">,</span> <span class="mf">0.2525753951072693</span><span class="p">,</span> <span class="mf">0.2508367341756821</span><span class="p">,</span> <span class="mf">0.25303518533706665</span><span class="p">,</span> <span class="mf">0.24774718701839446</span><span class="p">,</span> <span class="mf">0.24518848478794097</span><span class="p">,</span> <span class="mf">0.26084545016288757</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8225</span><span class="p">,</span> <span class="mf">0.85375</span><span class="p">,</span> <span class="mf">0.849375</span><span class="p">,</span> <span class="mf">0.853125</span><span class="p">,</span> <span class="mf">0.85875</span><span class="p">,</span> <span class="mf">0.848125</span><span class="p">,</span> <span class="mf">0.856875</span><span class="p">,</span> <span class="mf">0.8575</span><span class="p">,</span> <span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.869375</span><span class="p">,</span> <span class="mf">0.863125</span><span class="p">,</span> <span class="mf">0.886875</span><span class="p">,</span> <span class="mf">0.8725</span><span class="p">,</span> <span class="mf">0.878125</span><span class="p">,</span> <span class="mf">0.894375</span><span class="p">,</span> <span class="mf">0.888125</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.89125</span><span class="p">,</span> <span class="mf">0.88875</span><span class="p">,</span> <span class="mf">0.86875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4765880586619073</span><span class="p">,</span> <span class="mf">0.4503744399928032</span><span class="p">,</span> <span class="mf">0.4249279998401378</span><span class="p">,</span> <span class="mf">0.42333967214886176</span><span class="p">,</span> <span class="mf">0.4236916420941657</span><span class="p">,</span> <span class="mf">0.4269233151002133</span><span class="p">,</span> <span class="mf">0.4192506206479478</span><span class="p">,</span> <span class="mf">0.41413671872083174</span><span class="p">,</span> <span class="mf">0.41084911515738104</span><span class="p">,</span> <span class="mf">0.389948022413127</span><span class="p">,</span> <span class="mf">0.39566395788433706</span><span class="p">,</span> <span class="mf">0.3741930383951106</span><span class="p">,</span> <span class="mf">0.3794517093040842</span><span class="p">,</span> <span class="mf">0.3692300356131919</span><span class="p">,</span> <span class="mf">0.3640432547223061</span><span class="p">,</span> <span class="mf">0.3608953575504587</span><span class="p">,</span> <span class="mf">0.3419572095129084</span><span class="p">,</span> <span class="mf">0.34907091543712515</span><span class="p">,</span> <span class="mf">0.33601277535583113</span><span class="p">,</span> <span class="mf">0.3408893179544743</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.77625</span><span class="p">,</span> <span class="mf">0.7823333333333333</span><span class="p">,</span> <span class="mf">0.7916666666666666</span><span class="p">,</span> <span class="mf">0.80075</span><span class="p">,</span> <span class="mf">0.7973333333333333</span><span class="p">,</span> <span class="mf">0.7810833333333334</span><span class="p">,</span> <span class="mf">0.7928333333333333</span><span class="p">,</span> <span class="mf">0.7930833333333334</span><span class="p">,</span> <span class="mf">0.7951666666666667</span><span class="p">,</span> <span class="mf">0.8015833333333333</span><span class="p">,</span> <span class="mf">0.8000833333333334</span><span class="p">,</span> <span class="mf">0.8126666666666666</span><span class="p">,</span> <span class="mf">0.811</span><span class="p">,</span> <span class="mf">0.81775</span><span class="p">,</span> <span class="mf">0.8236666666666667</span><span class="p">,</span> <span class="mf">0.8215</span><span class="p">,</span> <span class="mf">0.8305833333333333</span><span class="p">,</span> <span class="mf">0.8251666666666667</span><span class="p">,</span> <span class="mf">0.8299166666666666</span><span class="p">,</span> <span class="mf">0.836</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3674533206224442</span><span class="p">,</span> <span class="mf">0.36733597874641416</span><span class="p">,</span> <span class="mf">0.35894496202468873</span><span class="p">,</span> <span class="mf">0.3514183223247528</span><span class="p">,</span> <span class="mf">0.35345671892166136</span><span class="p">,</span> <span class="mf">0.36494161546230314</span><span class="p">,</span> <span class="mf">0.35217500329017637</span><span class="p">,</span> <span class="mf">0.3447349113225937</span><span class="p">,</span> <span class="mf">0.34697150766849516</span><span class="p">,</span> <span class="mf">0.36931039452552794</span><span class="p">,</span> <span class="mf">0.3350031852722168</span><span class="p">,</span> <span class="mf">0.3416145300865173</span><span class="p">,</span> <span class="mf">0.32389605045318604</span><span class="p">,</span> <span class="mf">0.3109715062379837</span><span class="p">,</span> <span class="mf">0.3322615468502045</span><span class="p">,</span> <span class="mf">0.327584428191185</span><span class="p">,</span> <span class="mf">0.31910278856754304</span><span class="p">,</span> <span class="mf">0.311815539598465</span><span class="p">,</span> <span class="mf">0.2950947880744934</span><span class="p">,</span> <span class="mf">0.2948034608364105</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.808125</span><span class="p">,</span> <span class="mf">0.789375</span><span class="p">,</span> <span class="mf">0.826875</span><span class="p">,</span> <span class="mf">0.821875</span><span class="p">,</span> <span class="mf">0.81375</span><span class="p">,</span> <span class="mf">0.804375</span><span class="p">,</span> <span class="mf">0.80625</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.820625</span><span class="p">,</span> <span class="mf">0.848125</span><span class="p">,</span> <span class="mf">0.816875</span><span class="p">,</span> <span class="mf">0.8125</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.84625</span><span class="p">,</span> <span class="mf">0.824375</span><span class="p">,</span> <span class="mf">0.828125</span><span class="p">,</span> <span class="mf">0.825625</span><span class="p">,</span> <span class="mf">0.840625</span><span class="p">,</span> <span class="mf">0.8475</span><span class="p">,</span> <span class="mf">0.844375</span><span class="p">]]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.400307985173582</span><span class="p">,</span> <span class="mf">0.2597426520640662</span><span class="p">,</span> <span class="mf">0.20706942731312025</span><span class="p">,</span> <span class="mf">0.17091670006251475</span><span class="p">,</span> <span class="mf">0.13984850759524653</span><span class="p">,</span> <span class="mf">0.11444453444522518</span><span class="p">,</span> <span class="mf">0.0929887340481538</span><span class="p">,</span> <span class="mf">0.07584588486117436</span><span class="p">,</span> <span class="mf">0.06030314570384176</span><span class="p">,</span> <span class="mf">0.04997897459031356</span><span class="p">,</span> <span class="mf">0.037156337104278056</span><span class="p">,</span> <span class="mf">0.02793900864590992</span><span class="p">,</span> <span class="mf">0.02030197833807442</span><span class="p">,</span> <span class="mf">0.01789472087045391</span><span class="p">,</span> <span class="mf">0.0175876492686666</span><span class="p">,</span> <span class="mf">0.019220354652448274</span><span class="p">,</span> <span class="mf">0.013543135874294319</span><span class="p">,</span> <span class="mf">0.006956856955481477</span><span class="p">,</span> <span class="mf">0.0024507183060002227</span><span class="p">,</span> <span class="mf">0.00206579088377317</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8547833333333333</span><span class="p">,</span> <span class="mf">0.9049</span><span class="p">,</span> <span class="mf">0.9241666666666667</span><span class="p">,</span> <span class="mf">0.9360166666666667</span><span class="p">,</span> <span class="mf">0.94695</span><span class="p">,</span> <span class="mf">0.9585833333333333</span><span class="p">,</span> <span class="mf">0.9658666666666667</span><span class="p">,</span> <span class="mf">0.9723166666666667</span><span class="p">,</span> <span class="mf">0.9780333333333333</span><span class="p">,</span> <span class="mf">0.9820166666666666</span><span class="p">,</span> <span class="mf">0.9868</span><span class="p">,</span> <span class="mf">0.9906666666666667</span><span class="p">,</span> <span class="mf">0.9936833333333334</span><span class="p">,</span> <span class="mf">0.9941333333333333</span><span class="p">,</span> <span class="mf">0.99405</span><span class="p">,</span> <span class="mf">0.9932833333333333</span><span class="p">,</span> <span class="mf">0.9960666666666667</span><span class="p">,</span> <span class="mf">0.9979666666666667</span><span class="p">,</span> <span class="mf">0.9996666666666667</span><span class="p">,</span> <span class="mf">0.9995666666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.36797549843788147</span><span class="p">,</span> <span class="mf">0.2586278670430183</span><span class="p">,</span> <span class="mf">0.24208260095119477</span><span class="p">,</span> <span class="mf">0.24353929474949837</span><span class="p">,</span> <span class="mf">0.24164094921946525</span><span class="p">,</span> <span class="mf">0.2638056704550982</span><span class="p">,</span> <span class="mf">0.2579395814836025</span><span class="p">,</span> <span class="mf">0.27675500786304474</span><span class="p">,</span> <span class="mf">0.2851512663513422</span><span class="p">,</span> <span class="mf">0.30380481338500975</span><span class="p">,</span> <span class="mf">0.3235128371268511</span><span class="p">,</span> <span class="mf">0.3284085538983345</span><span class="p">,</span> <span class="mf">0.3443841063082218</span><span class="p">,</span> <span class="mf">0.41086878085136413</span><span class="p">,</span> <span class="mf">0.457796107493341</span><span class="p">,</span> <span class="mf">0.4356938077956438</span><span class="p">,</span> <span class="mf">0.4109785168170929</span><span class="p">,</span> <span class="mf">0.4433729724138975</span><span class="p">,</span> <span class="mf">0.4688420155197382</span><span class="p">,</span> <span class="mf">0.4773445381522179</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.908375</span><span class="p">,</span> <span class="mf">0.91475</span><span class="p">,</span> <span class="mf">0.915125</span><span class="p">,</span> <span class="mf">0.91525</span><span class="p">,</span> <span class="mf">0.91725</span><span class="p">,</span> <span class="mf">0.924875</span><span class="p">,</span> <span class="mf">0.91975</span><span class="p">,</span> <span class="mf">0.922375</span><span class="p">,</span> <span class="mf">0.92025</span><span class="p">,</span> <span class="mf">0.920375</span><span class="p">,</span> <span class="mf">0.924875</span><span class="p">,</span> <span class="mf">0.9235</span><span class="p">,</span> <span class="mf">0.918125</span><span class="p">,</span> <span class="mf">0.91525</span><span class="p">,</span> <span class="mf">0.918875</span><span class="p">,</span> <span class="mf">0.923625</span><span class="p">,</span> <span class="mf">0.9235</span><span class="p">,</span> <span class="mf">0.92625</span><span class="p">,</span> <span class="mf">0.925</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4710115425463424</span><span class="p">,</span> <span class="mf">0.3166707545550647</span><span class="p">,</span> <span class="mf">0.25890692547440275</span><span class="p">,</span> <span class="mf">0.22350736999753187</span><span class="p">,</span> <span class="mf">0.19296910860009794</span><span class="p">,</span> <span class="mf">0.17304379170113154</span><span class="p">,</span> <span class="mf">0.15315235079105285</span><span class="p">,</span> <span class="mf">0.13728606270383925</span><span class="p">,</span> <span class="mf">0.12178339355929034</span><span class="p">,</span> <span class="mf">0.10961619754736898</span><span class="p">,</span> <span class="mf">0.10074329449495337</span><span class="p">,</span> <span class="mf">0.08793247367408294</span><span class="p">,</span> <span class="mf">0.07651288138686625</span><span class="p">,</span> <span class="mf">0.06934997136779089</span><span class="p">,</span> <span class="mf">0.06243234033510685</span><span class="p">,</span> <span class="mf">0.056774082654433795</span><span class="p">,</span> <span class="mf">0.05116950291028218</span><span class="p">,</span> <span class="mf">0.04961718403588313</span><span class="p">,</span> <span class="mf">0.04289388027836952</span><span class="p">,</span> <span class="mf">0.040430180404756245</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8289666666666666</span><span class="p">,</span> <span class="mf">0.8851833333333333</span><span class="p">,</span> <span class="mf">0.9045166666666666</span><span class="p">,</span> <span class="mf">0.9167666666666666</span><span class="p">,</span> <span class="mf">0.9294166666666667</span><span class="p">,</span> <span class="mf">0.93545</span><span class="p">,</span> <span class="mf">0.94275</span><span class="p">,</span> <span class="mf">0.9486666666666667</span><span class="p">,</span> <span class="mf">0.95365</span><span class="p">,</span> <span class="mf">0.95855</span><span class="p">,</span> <span class="mf">0.9618833333333333</span><span class="p">,</span> <span class="mf">0.9667</span><span class="p">,</span> <span class="mf">0.9717666666666667</span><span class="p">,</span> <span class="mf">0.9745833333333334</span><span class="p">,</span> <span class="mf">0.9765833333333334</span><span class="p">,</span> <span class="mf">0.9793</span><span class="p">,</span> <span class="mf">0.9809833333333333</span><span class="p">,</span> <span class="mf">0.9820333333333333</span><span class="p">,</span> <span class="mf">0.9839166666666667</span><span class="p">,</span> <span class="mf">0.9849166666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3629846270084381</span><span class="p">,</span> <span class="mf">0.31240448981523516</span><span class="p">,</span> <span class="mf">0.24729759228229523</span><span class="p">,</span> <span class="mf">0.2697310926616192</span><span class="p">,</span> <span class="mf">0.24718070650100707</span><span class="p">,</span> <span class="mf">0.23403583562374114</span><span class="p">,</span> <span class="mf">0.2295891786813736</span><span class="p">,</span> <span class="mf">0.22117181441187858</span><span class="p">,</span> <span class="mf">0.2475375788807869</span><span class="p">,</span> <span class="mf">0.23771390727162361</span><span class="p">,</span> <span class="mf">0.2562992911040783</span><span class="p">,</span> <span class="mf">0.25533875498175623</span><span class="p">,</span> <span class="mf">0.27057862806320193</span><span class="p">,</span> <span class="mf">0.2820998176634312</span><span class="p">,</span> <span class="mf">0.29471745146811007</span><span class="p">,</span> <span class="mf">0.2795617451965809</span><span class="p">,</span> <span class="mf">0.3008101430237293</span><span class="p">,</span> <span class="mf">0.28815430629253386</span><span class="p">,</span> <span class="mf">0.31814645100384953</span><span class="p">,</span> <span class="mf">0.3106237706840038</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.874125</span><span class="p">,</span> <span class="mf">0.88875</span><span class="p">,</span> <span class="mf">0.908875</span><span class="p">,</span> <span class="mf">0.9045</span><span class="p">,</span> <span class="mf">0.9145</span><span class="p">,</span> <span class="mf">0.918125</span><span class="p">,</span> <span class="mf">0.919375</span><span class="p">,</span> <span class="mf">0.9245</span><span class="p">,</span> <span class="mf">0.91975</span><span class="p">,</span> <span class="mf">0.926</span><span class="p">,</span> <span class="mf">0.923625</span><span class="p">,</span> <span class="mf">0.925875</span><span class="p">,</span> <span class="mf">0.92475</span><span class="p">,</span> <span class="mf">0.926375</span><span class="p">,</span> <span class="mf">0.925125</span><span class="p">,</span> <span class="mf">0.92525</span><span class="p">,</span> <span class="mf">0.924625</span><span class="p">,</span> <span class="mf">0.930875</span><span class="p">,</span> <span class="mf">0.924875</span><span class="p">,</span> <span class="mf">0.926625</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.6091368444629316</span><span class="p">,</span> <span class="mf">0.40709905083309106</span><span class="p">,</span> <span class="mf">0.33330900164873106</span><span class="p">,</span> <span class="mf">0.29541655938063605</span><span class="p">,</span> <span class="mf">0.26824146830864043</span><span class="p">,</span> <span class="mf">0.24633059249535552</span><span class="p">,</span> <span class="mf">0.22803501166832219</span><span class="p">,</span> <span class="mf">0.21262132842689435</span><span class="p">,</span> <span class="mf">0.20038021789160745</span><span class="p">,</span> <span class="mf">0.18430457027680647</span><span class="p">,</span> <span class="mf">0.1744787511763288</span><span class="p">,</span> <span class="mf">0.165271017740149</span><span class="p">,</span> <span class="mf">0.15522625095554507</span><span class="p">,</span> <span class="mf">0.1432937567076608</span><span class="p">,</span> <span class="mf">0.13617747858651222</span><span class="p">,</span> <span class="mf">0.12876031456241158</span><span class="p">,</span> <span class="mf">0.12141566201230325</span><span class="p">,</span> <span class="mf">0.11405601029369686</span><span class="p">,</span> <span class="mf">0.11116664642408522</span><span class="p">,</span> <span class="mf">0.10308189516060992</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7803833333333333</span><span class="p">,</span> <span class="mf">0.8559166666666667</span><span class="p">,</span> <span class="mf">0.8823</span><span class="p">,</span> <span class="mf">0.89505</span><span class="p">,</span> <span class="mf">0.9027333333333334</span><span class="p">,</span> <span class="mf">0.9099166666666667</span><span class="p">,</span> <span class="mf">0.9162333333333333</span><span class="p">,</span> <span class="mf">0.9224833333333333</span><span class="p">,</span> <span class="mf">0.9243166666666667</span><span class="p">,</span> <span class="mf">0.9321</span><span class="p">,</span> <span class="mf">0.9345833333333333</span><span class="p">,</span> <span class="mf">0.9375333333333333</span><span class="p">,</span> <span class="mf">0.9418833333333333</span><span class="p">,</span> <span class="mf">0.9456666666666667</span><span class="p">,</span> <span class="mf">0.9482333333333334</span><span class="p">,</span> <span class="mf">0.9513666666666667</span><span class="p">,</span> <span class="mf">0.9527333333333333</span><span class="p">,</span> <span class="mf">0.9559</span><span class="p">,</span> <span class="mf">0.9576166666666667</span><span class="p">,</span> <span class="mf">0.9611</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.36491659212112426</span><span class="p">,</span> <span class="mf">0.29200539910793305</span><span class="p">,</span> <span class="mf">0.2840233483910561</span><span class="p">,</span> <span class="mf">0.2591339669823646</span><span class="p">,</span> <span class="mf">0.24114771646261215</span><span class="p">,</span> <span class="mf">0.2436459481716156</span><span class="p">,</span> <span class="mf">0.2374294084906578</span><span class="p">,</span> <span class="mf">0.24284198743104934</span><span class="p">,</span> <span class="mf">0.22679156363010405</span><span class="p">,</span> <span class="mf">0.2229055170416832</span><span class="p">,</span> <span class="mf">0.21932773572206496</span><span class="p">,</span> <span class="mf">0.23045065227150918</span><span class="p">,</span> <span class="mf">0.23631879675388337</span><span class="p">,</span> <span class="mf">0.22048399156332016</span><span class="p">,</span> <span class="mf">0.2563135535418987</span><span class="p">,</span> <span class="mf">0.2494968646839261</span><span class="p">,</span> <span class="mf">0.24099056956171988</span><span class="p">,</span> <span class="mf">0.23974315640330315</span><span class="p">,</span> <span class="mf">0.24684958010911942</span><span class="p">,</span> <span class="mf">0.25887142738699914</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8665</span><span class="p">,</span> <span class="mf">0.8925</span><span class="p">,</span> <span class="mf">0.897</span><span class="p">,</span> <span class="mf">0.907375</span><span class="p">,</span> <span class="mf">0.914125</span><span class="p">,</span> <span class="mf">0.9125</span><span class="p">,</span> <span class="mf">0.913875</span><span class="p">,</span> <span class="mf">0.911875</span><span class="p">,</span> <span class="mf">0.921125</span><span class="p">,</span> <span class="mf">0.922625</span><span class="p">,</span> <span class="mf">0.923375</span><span class="p">,</span> <span class="mf">0.924125</span><span class="p">,</span> <span class="mf">0.922625</span><span class="p">,</span> <span class="mf">0.926</span><span class="p">,</span> <span class="mf">0.915625</span><span class="p">,</span> <span class="mf">0.926125</span><span class="p">,</span> <span class="mf">0.932625</span><span class="p">,</span> <span class="mf">0.927875</span><span class="p">,</span> <span class="mf">0.93</span><span class="p">,</span> <span class="mf">0.92525</span><span class="p">]],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.187068938827718</span><span class="p">,</span> <span class="mf">0.9080034740316842</span><span class="p">,</span> <span class="mf">0.6863665148329887</span><span class="p">,</span> <span class="mf">0.5706229420867301</span><span class="p">,</span> <span class="mf">0.5069490017921432</span><span class="p">,</span> <span class="mf">0.46316734996876485</span><span class="p">,</span> <span class="mf">0.42913920047885573</span><span class="p">,</span> <span class="mf">0.4107565824855874</span><span class="p">,</span> <span class="mf">0.3908677859061054</span><span class="p">,</span> <span class="mf">0.37283689377785745</span><span class="p">,</span> <span class="mf">0.3606657798388111</span><span class="p">,</span> <span class="mf">0.353545261082301</span><span class="p">,</span> <span class="mf">0.34009441143986</span><span class="p">,</span> <span class="mf">0.3239413740506559</span><span class="p">,</span> <span class="mf">0.3193119444620253</span><span class="p">,</span> <span class="mf">0.31045137204404577</span><span class="p">,</span> <span class="mf">0.3003838519091164</span><span class="p">,</span> <span class="mf">0.29092520530194615</span><span class="p">,</span> <span class="mf">0.28635713599447504</span><span class="p">,</span> <span class="mf">0.2760026559138349</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5551333333333334</span><span class="p">,</span> <span class="mf">0.6467</span><span class="p">,</span> <span class="mf">0.7338666666666667</span><span class="p">,</span> <span class="mf">0.7841333333333333</span><span class="p">,</span> <span class="mf">0.8128</span><span class="p">,</span> <span class="mf">0.82845</span><span class="p">,</span> <span class="mf">0.8430833333333333</span><span class="p">,</span> <span class="mf">0.8501666666666666</span><span class="p">,</span> <span class="mf">0.8580833333333333</span><span class="p">,</span> <span class="mf">0.8646166666666667</span><span class="p">,</span> <span class="mf">0.8667666666666667</span><span class="p">,</span> <span class="mf">0.8709833333333333</span><span class="p">,</span> <span class="mf">0.8766166666666667</span><span class="p">,</span> <span class="mf">0.8816666666666667</span><span class="p">,</span> <span class="mf">0.8812</span><span class="p">,</span> <span class="mf">0.88465</span><span class="p">,</span> <span class="mf">0.8898833333333334</span><span class="p">,</span> <span class="mf">0.8934666666666666</span><span class="p">,</span> <span class="mf">0.8940833333333333</span><span class="p">,</span> <span class="mf">0.8977666666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.6463955206871033</span><span class="p">,</span> <span class="mf">0.5193838343620301</span><span class="p">,</span> <span class="mf">0.4155286856889725</span><span class="p">,</span> <span class="mf">0.3316091845035553</span><span class="p">,</span> <span class="mf">0.3148408111333847</span><span class="p">,</span> <span class="mf">0.29354524302482604</span><span class="p">,</span> <span class="mf">0.2875490103960037</span><span class="p">,</span> <span class="mf">0.26903486740589144</span><span class="p">,</span> <span class="mf">0.27737221759557723</span><span class="p">,</span> <span class="mf">0.262776792883873</span><span class="p">,</span> <span class="mf">0.25498255288600924</span><span class="p">,</span> <span class="mf">0.2390553195178509</span><span class="p">,</span> <span class="mf">0.24918611392378806</span><span class="p">,</span> <span class="mf">0.23830307483673097</span><span class="p">,</span> <span class="mf">0.23538302001357078</span><span class="p">,</span> <span class="mf">0.24996423116326333</span><span class="p">,</span> <span class="mf">0.2464654156267643</span><span class="p">,</span> <span class="mf">0.24081429636478424</span><span class="p">,</span> <span class="mf">0.23204647853970528</span><span class="p">,</span> <span class="mf">0.23771219885349273</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.763875</span><span class="p">,</span> <span class="mf">0.81925</span><span class="p">,</span> <span class="mf">0.8685</span><span class="p">,</span> <span class="mf">0.8885</span><span class="p">,</span> <span class="mf">0.8895</span><span class="p">,</span> <span class="mf">0.895625</span><span class="p">,</span> <span class="mf">0.902</span><span class="p">,</span> <span class="mf">0.904125</span><span class="p">,</span> <span class="mf">0.906125</span><span class="p">,</span> <span class="mf">0.908</span><span class="p">,</span> <span class="mf">0.909375</span><span class="p">,</span> <span class="mf">0.9145</span><span class="p">,</span> <span class="mf">0.916125</span><span class="p">,</span> <span class="mf">0.9175</span><span class="p">,</span> <span class="mf">0.91875</span><span class="p">,</span> <span class="mf">0.91425</span><span class="p">,</span> <span class="mf">0.915375</span><span class="p">,</span> <span class="mf">0.918875</span><span class="p">,</span> <span class="mf">0.91975</span><span class="p">,</span> <span class="mf">0.91825</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4140813298491654</span><span class="p">,</span> <span class="mf">0.27481235485118843</span><span class="p">,</span> <span class="mf">0.22397600941614174</span><span class="p">,</span> <span class="mf">0.1890777693286951</span><span class="p">,</span> <span class="mf">0.16538111197112848</span><span class="p">,</span> <span class="mf">0.1448796250478132</span><span class="p">,</span> <span class="mf">0.12440053254032313</span><span class="p">,</span> <span class="mf">0.10817898457734855</span><span class="p">,</span> <span class="mf">0.09634132136696025</span><span class="p">,</span> <span class="mf">0.08548538653410352</span><span class="p">,</span> <span class="mf">0.07339220296349257</span><span class="p">,</span> <span class="mf">0.06470446296305314</span><span class="p">,</span> <span class="mf">0.060030178171393875</span><span class="p">,</span> <span class="mf">0.053294485403614034</span><span class="p">,</span> <span class="mf">0.04429284706704323</span><span class="p">,</span> <span class="mf">0.04014099264770115</span><span class="p">,</span> <span class="mf">0.03974721442450951</span><span class="p">,</span> <span class="mf">0.03304463665041803</span><span class="p">,</span> <span class="mf">0.02955428938137994</span><span class="p">,</span> <span class="mf">0.026940144761875052</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8496666666666667</span><span class="p">,</span> <span class="mf">0.8982666666666667</span><span class="p">,</span> <span class="mf">0.9162166666666667</span><span class="p">,</span> <span class="mf">0.9292166666666667</span><span class="p">,</span> <span class="mf">0.93805</span><span class="p">,</span> <span class="mf">0.9457666666666666</span><span class="p">,</span> <span class="mf">0.9534333333333334</span><span class="p">,</span> <span class="mf">0.9596</span><span class="p">,</span> <span class="mf">0.9645833333333333</span><span class="p">,</span> <span class="mf">0.9679</span><span class="p">,</span> <span class="mf">0.9726166666666667</span><span class="p">,</span> <span class="mf">0.9761666666666666</span><span class="p">,</span> <span class="mf">0.9775</span><span class="p">,</span> <span class="mf">0.9800166666666666</span><span class="p">,</span> <span class="mf">0.9842</span><span class="p">,</span> <span class="mf">0.9855333333333334</span><span class="p">,</span> <span class="mf">0.9857</span><span class="p">,</span> <span class="mf">0.98805</span><span class="p">,</span> <span class="mf">0.9895666666666667</span><span class="p">,</span> <span class="mf">0.9905833333333334</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3327465409040451</span><span class="p">,</span> <span class="mf">0.27738857254385946</span><span class="p">,</span> <span class="mf">0.23834018683433533</span><span class="p">,</span> <span class="mf">0.24359044748544692</span><span class="p">,</span> <span class="mf">0.23630736249685289</span><span class="p">,</span> <span class="mf">0.26239568686485293</span><span class="p">,</span> <span class="mf">0.23089197066426276</span><span class="p">,</span> <span class="mf">0.23183160039782524</span><span class="p">,</span> <span class="mf">0.2287161501646042</span><span class="p">,</span> <span class="mf">0.23795067170262338</span><span class="p">,</span> <span class="mf">0.2680365410447121</span><span class="p">,</span> <span class="mf">0.28079107534885406</span><span class="p">,</span> <span class="mf">0.2745736412107945</span><span class="p">,</span> <span class="mf">0.27641161236166956</span><span class="p">,</span> <span class="mf">0.2967236565724015</span><span class="p">,</span> <span class="mf">0.29836027943715454</span><span class="p">,</span> <span class="mf">0.28526886811852453</span><span class="p">,</span> <span class="mf">0.3188628684282303</span><span class="p">,</span> <span class="mf">0.3159900237545371</span><span class="p">,</span> <span class="mf">0.33990017675608397</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.876875</span><span class="p">,</span> <span class="mf">0.899875</span><span class="p">,</span> <span class="mf">0.918125</span><span class="p">,</span> <span class="mf">0.9105</span><span class="p">,</span> <span class="mf">0.918125</span><span class="p">,</span> <span class="mf">0.91</span><span class="p">,</span> <span class="mf">0.92075</span><span class="p">,</span> <span class="mf">0.922625</span><span class="p">,</span> <span class="mf">0.924</span><span class="p">,</span> <span class="mf">0.921</span><span class="p">,</span> <span class="mf">0.920875</span><span class="p">,</span> <span class="mf">0.921</span><span class="p">,</span> <span class="mf">0.9285</span><span class="p">,</span> <span class="mf">0.927625</span><span class="p">,</span> <span class="mf">0.9265</span><span class="p">,</span> <span class="mf">0.927375</span><span class="p">,</span> <span class="mf">0.925875</span><span class="p">,</span> <span class="mf">0.927</span><span class="p">,</span> <span class="mf">0.92575</span><span class="p">,</span> <span class="mf">0.925875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.48859380523978013</span><span class="p">,</span> <span class="mf">0.3269256727337075</span><span class="p">,</span> <span class="mf">0.275135099903734</span><span class="p">,</span> <span class="mf">0.24039912359244914</span><span class="p">,</span> <span class="mf">0.21368402032566858</span><span class="p">,</span> <span class="mf">0.19328243048317523</span><span class="p">,</span> <span class="mf">0.17890911489359732</span><span class="p">,</span> <span class="mf">0.16624130663682402</span><span class="p">,</span> <span class="mf">0.15215728174088827</span><span class="p">,</span> <span class="mf">0.1416037013468299</span><span class="p">,</span> <span class="mf">0.13273427299440288</span><span class="p">,</span> <span class="mf">0.12227611260405227</span><span class="p">,</span> <span class="mf">0.11463099068699917</span><span class="p">,</span> <span class="mf">0.10616964906720179</span><span class="p">,</span> <span class="mf">0.09988978996809357</span><span class="p">,</span> <span class="mf">0.09424899211093815</span><span class="p">,</span> <span class="mf">0.08670466838887077</span><span class="p">,</span> <span class="mf">0.0835973875783781</span><span class="p">,</span> <span class="mf">0.0778748192367698</span><span class="p">,</span> <span class="mf">0.07327510508696741</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.82055</span><span class="p">,</span> <span class="mf">0.8806666666666667</span><span class="p">,</span> <span class="mf">0.9004333333333333</span><span class="p">,</span> <span class="mf">0.9117333333333333</span><span class="p">,</span> <span class="mf">0.9206333333333333</span><span class="p">,</span> <span class="mf">0.92785</span><span class="p">,</span> <span class="mf">0.9333</span><span class="p">,</span> <span class="mf">0.9384166666666667</span><span class="p">,</span> <span class="mf">0.9430333333333333</span><span class="p">,</span> <span class="mf">0.9471833333333334</span><span class="p">,</span> <span class="mf">0.95055</span><span class="p">,</span> <span class="mf">0.9540166666666666</span><span class="p">,</span> <span class="mf">0.9568833333333333</span><span class="p">,</span> <span class="mf">0.9601666666666666</span><span class="p">,</span> <span class="mf">0.9620333333333333</span><span class="p">,</span> <span class="mf">0.9652</span><span class="p">,</span> <span class="mf">0.9676833333333333</span><span class="p">,</span> <span class="mf">0.9682666666666667</span><span class="p">,</span> <span class="mf">0.9706</span><span class="p">,</span> <span class="mf">0.9724333333333334</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.34025013536214826</span><span class="p">,</span> <span class="mf">0.29788709819316866</span><span class="p">,</span> <span class="mf">0.2680273652672768</span><span class="p">,</span> <span class="mf">0.2463292105793953</span><span class="p">,</span> <span class="mf">0.23471139985322953</span><span class="p">,</span> <span class="mf">0.22580294385552407</span><span class="p">,</span> <span class="mf">0.21676637730002404</span><span class="p">,</span> <span class="mf">0.20925517010688782</span><span class="p">,</span> <span class="mf">0.23552959233522416</span><span class="p">,</span> <span class="mf">0.21975916308164598</span><span class="p">,</span> <span class="mf">0.23494828915596008</span><span class="p">,</span> <span class="mf">0.21611644634604454</span><span class="p">,</span> <span class="mf">0.22251244640350343</span><span class="p">,</span> <span class="mf">0.22066593673825263</span><span class="p">,</span> <span class="mf">0.2214409472346306</span><span class="p">,</span> <span class="mf">0.22849382662773132</span><span class="p">,</span> <span class="mf">0.24493269926309585</span><span class="p">,</span> <span class="mf">0.2397777333110571</span><span class="p">,</span> <span class="mf">0.23578458192944526</span><span class="p">,</span> <span class="mf">0.2563280282020569</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.870875</span><span class="p">,</span> <span class="mf">0.8875</span><span class="p">,</span> <span class="mf">0.900375</span><span class="p">,</span> <span class="mf">0.906625</span><span class="p">,</span> <span class="mf">0.9145</span><span class="p">,</span> <span class="mf">0.921125</span><span class="p">,</span> <span class="mf">0.92125</span><span class="p">,</span> <span class="mf">0.92425</span><span class="p">,</span> <span class="mf">0.916</span><span class="p">,</span> <span class="mf">0.923125</span><span class="p">,</span> <span class="mf">0.920375</span><span class="p">,</span> <span class="mf">0.92675</span><span class="p">,</span> <span class="mf">0.92575</span><span class="p">,</span> <span class="mf">0.924875</span><span class="p">,</span> <span class="mf">0.925</span><span class="p">,</span> <span class="mf">0.924875</span><span class="p">,</span> <span class="mf">0.922875</span><span class="p">,</span> <span class="mf">0.931125</span><span class="p">,</span> <span class="mf">0.932375</span><span class="p">,</span> <span class="mf">0.929</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.6104797730917362</span><span class="p">,</span> <span class="mf">0.42115319246994154</span><span class="p">,</span> <span class="mf">0.3527538229359874</span><span class="p">,</span> <span class="mf">0.3136731511446586</span><span class="p">,</span> <span class="mf">0.2857721160565104</span><span class="p">,</span> <span class="mf">0.26646374052426197</span><span class="p">,</span> <span class="mf">0.24732486170523965</span><span class="p">,</span> <span class="mf">0.23057452346613286</span><span class="p">,</span> <span class="mf">0.21953405395769743</span><span class="p">,</span> <span class="mf">0.20952929538100767</span><span class="p">,</span> <span class="mf">0.19584925043811677</span><span class="p">,</span> <span class="mf">0.18926965880162044</span><span class="p">,</span> <span class="mf">0.18003955145856973</span><span class="p">,</span> <span class="mf">0.17379174885878176</span><span class="p">,</span> <span class="mf">0.16635702809354644</span><span class="p">,</span> <span class="mf">0.15807223409366633</span><span class="p">,</span> <span class="mf">0.1509416516620054</span><span class="p">,</span> <span class="mf">0.1477138751140758</span><span class="p">,</span> <span class="mf">0.14028569269798266</span><span class="p">,</span> <span class="mf">0.13906246528172417</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7786833333333333</span><span class="p">,</span> <span class="mf">0.8482166666666666</span><span class="p">,</span> <span class="mf">0.8730833333333333</span><span class="p">,</span> <span class="mf">0.888</span><span class="p">,</span> <span class="mf">0.8978</span><span class="p">,</span> <span class="mf">0.9033666666666667</span><span class="p">,</span> <span class="mf">0.9089166666666667</span><span class="p">,</span> <span class="mf">0.9147666666666666</span><span class="p">,</span> <span class="mf">0.91955</span><span class="p">,</span> <span class="mf">0.9221833333333334</span><span class="p">,</span> <span class="mf">0.92715</span><span class="p">,</span> <span class="mf">0.9309666666666667</span><span class="p">,</span> <span class="mf">0.9334</span><span class="p">,</span> <span class="mf">0.93495</span><span class="p">,</span> <span class="mf">0.9376833333333333</span><span class="p">,</span> <span class="mf">0.9402666666666667</span><span class="p">,</span> <span class="mf">0.94405</span><span class="p">,</span> <span class="mf">0.9439166666666666</span><span class="p">,</span> <span class="mf">0.9466833333333333</span><span class="p">,</span> <span class="mf">0.9464833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3859497320652008</span><span class="p">,</span> <span class="mf">0.3124091213941574</span><span class="p">,</span> <span class="mf">0.28177140313386917</span><span class="p">,</span> <span class="mf">0.2564259949326515</span><span class="p">,</span> <span class="mf">0.24969424712657928</span><span class="p">,</span> <span class="mf">0.23137387067079543</span><span class="p">,</span> <span class="mf">0.22758139592409135</span><span class="p">,</span> <span class="mf">0.22978509336709976</span><span class="p">,</span> <span class="mf">0.2293499847650528</span><span class="p">,</span> <span class="mf">0.22430640310049058</span><span class="p">,</span> <span class="mf">0.21563700905442237</span><span class="p">,</span> <span class="mf">0.21529569518566133</span><span class="p">,</span> <span class="mf">0.22171301135420798</span><span class="p">,</span> <span class="mf">0.2105387990772724</span><span class="p">,</span> <span class="mf">0.21190602815151213</span><span class="p">,</span> <span class="mf">0.21494245541095733</span><span class="p">,</span> <span class="mf">0.21312989933788776</span><span class="p">,</span> <span class="mf">0.20670134457945824</span><span class="p">,</span> <span class="mf">0.2146600303351879</span><span class="p">,</span> <span class="mf">0.21474341893941165</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.86</span><span class="p">,</span> <span class="mf">0.888</span><span class="p">,</span> <span class="mf">0.89625</span><span class="p">,</span> <span class="mf">0.907</span><span class="p">,</span> <span class="mf">0.908</span><span class="p">,</span> <span class="mf">0.915</span><span class="p">,</span> <span class="mf">0.917875</span><span class="p">,</span> <span class="mf">0.92</span><span class="p">,</span> <span class="mf">0.921125</span><span class="p">,</span> <span class="mf">0.917625</span><span class="p">,</span> <span class="mf">0.924</span><span class="p">,</span> <span class="mf">0.921875</span><span class="p">,</span> <span class="mf">0.925875</span><span class="p">,</span> <span class="mf">0.92575</span><span class="p">,</span> <span class="mf">0.928125</span><span class="p">,</span> <span class="mf">0.92775</span><span class="p">,</span> <span class="mf">0.928625</span><span class="p">,</span> <span class="mf">0.93075</span><span class="p">,</span> <span class="mf">0.92975</span><span class="p">,</span> <span class="mf">0.930375</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.1724896589194789</span><span class="p">,</span> <span class="mf">0.8803599189911315</span><span class="p">,</span> <span class="mf">0.692622532690766</span><span class="p">,</span> <span class="mf">0.5974764075837156</span><span class="p">,</span> <span class="mf">0.5319996399920124</span><span class="p">,</span> <span class="mf">0.49373906012028773</span><span class="p">,</span> <span class="mf">0.4741932853007876</span><span class="p">,</span> <span class="mf">0.45601858158927483</span><span class="p">,</span> <span class="mf">0.43706520244892216</span><span class="p">,</span> <span class="mf">0.4238534729236733</span><span class="p">,</span> <span class="mf">0.41077356216813454</span><span class="p">,</span> <span class="mf">0.38932509837882606</span><span class="p">,</span> <span class="mf">0.3771154705856019</span><span class="p">,</span> <span class="mf">0.3687882057305719</span><span class="p">,</span> <span class="mf">0.34927689276937485</span><span class="p">,</span> <span class="mf">0.3379922736602933</span><span class="p">,</span> <span class="mf">0.33547254843212393</span><span class="p">,</span> <span class="mf">0.3263144160448107</span><span class="p">,</span> <span class="mf">0.31800466419251233</span><span class="p">,</span> <span class="mf">0.3133781185822446</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5631833333333334</span><span class="p">,</span> <span class="mf">0.6579333333333334</span><span class="p">,</span> <span class="mf">0.7342166666666666</span><span class="p">,</span> <span class="mf">0.7765833333333333</span><span class="p">,</span> <span class="mf">0.8036333333333333</span><span class="p">,</span> <span class="mf">0.8197166666666666</span><span class="p">,</span> <span class="mf">0.82755</span><span class="p">,</span> <span class="mf">0.8320166666666666</span><span class="p">,</span> <span class="mf">0.8397833333333333</span><span class="p">,</span> <span class="mf">0.8432666666666667</span><span class="p">,</span> <span class="mf">0.8519333333333333</span><span class="p">,</span> <span class="mf">0.85835</span><span class="p">,</span> <span class="mf">0.86285</span><span class="p">,</span> <span class="mf">0.8641</span><span class="p">,</span> <span class="mf">0.87105</span><span class="p">,</span> <span class="mf">0.8756666666666667</span><span class="p">,</span> <span class="mf">0.8775166666666666</span><span class="p">,</span> <span class="mf">0.87965</span><span class="p">,</span> <span class="mf">0.88255</span><span class="p">,</span> <span class="mf">0.8832333333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5745115535259246</span><span class="p">,</span> <span class="mf">0.4740168128013611</span><span class="p">,</span> <span class="mf">0.4092038922309876</span><span class="p">,</span> <span class="mf">0.345498643040657</span><span class="p">,</span> <span class="mf">0.32894178831577303</span><span class="p">,</span> <span class="mf">0.2999964846372604</span><span class="p">,</span> <span class="mf">0.28456189918518066</span><span class="p">,</span> <span class="mf">0.28186965006589887</span><span class="p">,</span> <span class="mf">0.26958267349004744</span><span class="p">,</span> <span class="mf">0.26703972268104553</span><span class="p">,</span> <span class="mf">0.2667745503783226</span><span class="p">,</span> <span class="mf">0.2553461962342262</span><span class="p">,</span> <span class="mf">0.25764305877685545</span><span class="p">,</span> <span class="mf">0.2528705199956894</span><span class="p">,</span> <span class="mf">0.24987997275590895</span><span class="p">,</span> <span class="mf">0.24210182267427444</span><span class="p">,</span> <span class="mf">0.2366510547697544</span><span class="p">,</span> <span class="mf">0.24053962442278862</span><span class="p">,</span> <span class="mf">0.22825994032621383</span><span class="p">,</span> <span class="mf">0.2270425768494606</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.776875</span><span class="p">,</span> <span class="mf">0.822625</span><span class="p">,</span> <span class="mf">0.848875</span><span class="p">,</span> <span class="mf">0.87825</span><span class="p">,</span> <span class="mf">0.88925</span><span class="p">,</span> <span class="mf">0.899875</span><span class="p">,</span> <span class="mf">0.9015</span><span class="p">,</span> <span class="mf">0.904375</span><span class="p">,</span> <span class="mf">0.9035</span><span class="p">,</span> <span class="mf">0.906</span><span class="p">,</span> <span class="mf">0.906875</span><span class="p">,</span> <span class="mf">0.91125</span><span class="p">,</span> <span class="mf">0.907</span><span class="p">,</span> <span class="mf">0.908625</span><span class="p">,</span> <span class="mf">0.91175</span><span class="p">,</span> <span class="mf">0.917125</span><span class="p">,</span> <span class="mf">0.91675</span><span class="p">,</span> <span class="mf">0.916125</span><span class="p">,</span> <span class="mf">0.919875</span><span class="p">,</span> <span class="mf">0.917625</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.43062501005145276</span><span class="p">,</span> <span class="mf">0.29807482149078646</span><span class="p">,</span> <span class="mf">0.2541527441585623</span><span class="p">,</span> <span class="mf">0.21918726423338278</span><span class="p">,</span> <span class="mf">0.1950343672964555</span><span class="p">,</span> <span class="mf">0.17517360023010387</span><span class="p">,</span> <span class="mf">0.16213757058244144</span><span class="p">,</span> <span class="mf">0.14869415854364</span><span class="p">,</span> <span class="mf">0.13477844860392815</span><span class="p">,</span> <span class="mf">0.12352272007129848</span><span class="p">,</span> <span class="mf">0.11392300839184412</span><span class="p">,</span> <span class="mf">0.10589898744228679</span><span class="p">,</span> <span class="mf">0.09751250602896692</span><span class="p">,</span> <span class="mf">0.089864786467088</span><span class="p">,</span> <span class="mf">0.08516462990539526</span><span class="p">,</span> <span class="mf">0.07973235945548934</span><span class="p">,</span> <span class="mf">0.07441158362824137</span><span class="p">,</span> <span class="mf">0.07053931183896578</span><span class="p">,</span> <span class="mf">0.06258528833356954</span><span class="p">,</span> <span class="mf">0.06177985634201014</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8429</span><span class="p">,</span> <span class="mf">0.88905</span><span class="p">,</span> <span class="mf">0.9052166666666667</span><span class="p">,</span> <span class="mf">0.9182166666666667</span><span class="p">,</span> <span class="mf">0.92755</span><span class="p">,</span> <span class="mf">0.9337666666666666</span><span class="p">,</span> <span class="mf">0.93835</span><span class="p">,</span> <span class="mf">0.944</span><span class="p">,</span> <span class="mf">0.9489333333333333</span><span class="p">,</span> <span class="mf">0.95365</span><span class="p">,</span> <span class="mf">0.9565333333333333</span><span class="p">,</span> <span class="mf">0.9599166666666666</span><span class="p">,</span> <span class="mf">0.9637833333333333</span><span class="p">,</span> <span class="mf">0.9659666666666666</span><span class="p">,</span> <span class="mf">0.9685666666666667</span><span class="p">,</span> <span class="mf">0.9705</span><span class="p">,</span> <span class="mf">0.9713666666666667</span><span class="p">,</span> <span class="mf">0.9738</span><span class="p">,</span> <span class="mf">0.9770166666666666</span><span class="p">,</span> <span class="mf">0.9769833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.32814766228199005</span><span class="p">,</span> <span class="mf">0.29447353577613833</span><span class="p">,</span> <span class="mf">0.25052148789167406</span><span class="p">,</span> <span class="mf">0.22761481428146363</span><span class="p">,</span> <span class="mf">0.23280890756845474</span><span class="p">,</span> <span class="mf">0.23155913531780242</span><span class="p">,</span> <span class="mf">0.21984874603152274</span><span class="p">,</span> <span class="mf">0.2166314404308796</span><span class="p">,</span> <span class="mf">0.2202563073039055</span><span class="p">,</span> <span class="mf">0.22508277136087418</span><span class="p">,</span> <span class="mf">0.2237191815972328</span><span class="p">,</span> <span class="mf">0.2246915928721428</span><span class="p">,</span> <span class="mf">0.22815296687185765</span><span class="p">,</span> <span class="mf">0.2254556802213192</span><span class="p">,</span> <span class="mf">0.2337513281852007</span><span class="p">,</span> <span class="mf">0.2381753808259964</span><span class="p">,</span> <span class="mf">0.24798179551959038</span><span class="p">,</span> <span class="mf">0.24766947883367538</span><span class="p">,</span> <span class="mf">0.24877363580465317</span><span class="p">,</span> <span class="mf">0.2518915164768696</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.879625</span><span class="p">,</span> <span class="mf">0.89025</span><span class="p">,</span> <span class="mf">0.907875</span><span class="p">,</span> <span class="mf">0.916625</span><span class="p">,</span> <span class="mf">0.91625</span><span class="p">,</span> <span class="mf">0.91825</span><span class="p">,</span> <span class="mf">0.920875</span><span class="p">,</span> <span class="mf">0.923625</span><span class="p">,</span> <span class="mf">0.922625</span><span class="p">,</span> <span class="mf">0.923</span><span class="p">,</span> <span class="mf">0.92575</span><span class="p">,</span> <span class="mf">0.927125</span><span class="p">,</span> <span class="mf">0.928625</span><span class="p">,</span> <span class="mf">0.92625</span><span class="p">,</span> <span class="mf">0.925375</span><span class="p">,</span> <span class="mf">0.925625</span><span class="p">,</span> <span class="mf">0.926375</span><span class="p">,</span> <span class="mf">0.92475</span><span class="p">,</span> <span class="mf">0.9255</span><span class="p">,</span> <span class="mf">0.92675</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.5022556754285847</span><span class="p">,</span> <span class="mf">0.3545388207554436</span><span class="p">,</span> <span class="mf">0.2965180559564374</span><span class="p">,</span> <span class="mf">0.2689443711818917</span><span class="p">,</span> <span class="mf">0.24340009927622544</span><span class="p">,</span> <span class="mf">0.22504497168144819</span><span class="p">,</span> <span class="mf">0.21177587015574167</span><span class="p">,</span> <span class="mf">0.19926073912507308</span><span class="p">,</span> <span class="mf">0.18498492261557692</span><span class="p">,</span> <span class="mf">0.1792394390810273</span><span class="p">,</span> <span class="mf">0.16716771742809555</span><span class="p">,</span> <span class="mf">0.16088557891500022</span><span class="p">,</span> <span class="mf">0.15540826101420022</span><span class="p">,</span> <span class="mf">0.1471743908549931</span><span class="p">,</span> <span class="mf">0.14383414784458273</span><span class="p">,</span> <span class="mf">0.1351151093741311</span><span class="p">,</span> <span class="mf">0.1312572255915305</span><span class="p">,</span> <span class="mf">0.12904865093140014</span><span class="p">,</span> <span class="mf">0.12332957751079918</span><span class="p">,</span> <span class="mf">0.11934908895072208</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8186333333333333</span><span class="p">,</span> <span class="mf">0.8711666666666666</span><span class="p">,</span> <span class="mf">0.8905666666666666</span><span class="p">,</span> <span class="mf">0.9020666666666667</span><span class="p">,</span> <span class="mf">0.9106333333333333</span><span class="p">,</span> <span class="mf">0.9169333333333334</span><span class="p">,</span> <span class="mf">0.9227</span><span class="p">,</span> <span class="mf">0.9258166666666666</span><span class="p">,</span> <span class="mf">0.9317</span><span class="p">,</span> <span class="mf">0.9329666666666667</span><span class="p">,</span> <span class="mf">0.9384833333333333</span><span class="p">,</span> <span class="mf">0.9394333333333333</span><span class="p">,</span> <span class="mf">0.94185</span><span class="p">,</span> <span class="mf">0.9447666666666666</span><span class="p">,</span> <span class="mf">0.9449833333333333</span><span class="p">,</span> <span class="mf">0.9489</span><span class="p">,</span> <span class="mf">0.9506</span><span class="p">,</span> <span class="mf">0.9520333333333333</span><span class="p">,</span> <span class="mf">0.95295</span><span class="p">,</span> <span class="mf">0.9556833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.37072600054740906</span><span class="p">,</span> <span class="mf">0.2894986196160316</span><span class="p">,</span> <span class="mf">0.2896255247592926</span><span class="p">,</span> <span class="mf">0.2553737629055977</span><span class="p">,</span> <span class="mf">0.2347450014948845</span><span class="p">,</span> <span class="mf">0.23144772934913635</span><span class="p">,</span> <span class="mf">0.22532679361104965</span><span class="p">,</span> <span class="mf">0.2152210614681244</span><span class="p">,</span> <span class="mf">0.21610748746991157</span><span class="p">,</span> <span class="mf">0.22872606116533278</span><span class="p">,</span> <span class="mf">0.22058768355846406</span><span class="p">,</span> <span class="mf">0.20230921444296837</span><span class="p">,</span> <span class="mf">0.2118315652012825</span><span class="p">,</span> <span class="mf">0.20028054055571556</span><span class="p">,</span> <span class="mf">0.20844366964697839</span><span class="p">,</span> <span class="mf">0.20884322375059128</span><span class="p">,</span> <span class="mf">0.21231223946809769</span><span class="p">,</span> <span class="mf">0.19875787001848222</span><span class="p">,</span> <span class="mf">0.2072589308321476</span><span class="p">,</span> <span class="mf">0.22480831852555275</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.862</span><span class="p">,</span> <span class="mf">0.894</span><span class="p">,</span> <span class="mf">0.892375</span><span class="p">,</span> <span class="mf">0.906375</span><span class="p">,</span> <span class="mf">0.912625</span><span class="p">,</span> <span class="mf">0.91375</span><span class="p">,</span> <span class="mf">0.916875</span><span class="p">,</span> <span class="mf">0.918875</span><span class="p">,</span> <span class="mf">0.92125</span><span class="p">,</span> <span class="mf">0.9185</span><span class="p">,</span> <span class="mf">0.920375</span><span class="p">,</span> <span class="mf">0.92825</span><span class="p">,</span> <span class="mf">0.9255</span><span class="p">,</span> <span class="mf">0.92925</span><span class="p">,</span> <span class="mf">0.926875</span><span class="p">,</span> <span class="mf">0.9285</span><span class="p">,</span> <span class="mf">0.926375</span><span class="p">,</span> <span class="mf">0.93075</span><span class="p">,</span> <span class="mf">0.931125</span><span class="p">,</span> <span class="mf">0.922875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.6208003907124879</span><span class="p">,</span> <span class="mf">0.4341448332582201</span><span class="p">,</span> <span class="mf">0.3655890760454796</span><span class="p">,</span> <span class="mf">0.3245583019102179</span><span class="p">,</span> <span class="mf">0.3000562671722888</span><span class="p">,</span> <span class="mf">0.2840681741280215</span><span class="p">,</span> <span class="mf">0.2686156402947679</span><span class="p">,</span> <span class="mf">0.25843519997844566</span><span class="p">,</span> <span class="mf">0.24892204790227196</span><span class="p">,</span> <span class="mf">0.23988707410469493</span><span class="p">,</span> <span class="mf">0.22968693327770304</span><span class="p">,</span> <span class="mf">0.22323107979953416</span><span class="p">,</span> <span class="mf">0.21376596502403714</span><span class="p">,</span> <span class="mf">0.21353628940340172</span><span class="p">,</span> <span class="mf">0.208721635311143</span><span class="p">,</span> <span class="mf">0.20283085862393063</span><span class="p">,</span> <span class="mf">0.19862186088204892</span><span class="p">,</span> <span class="mf">0.1939613972542319</span><span class="p">,</span> <span class="mf">0.18833921627917968</span><span class="p">,</span> <span class="mf">0.18451892669552933</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7769666666666667</span><span class="p">,</span> <span class="mf">0.8453333333333334</span><span class="p">,</span> <span class="mf">0.86965</span><span class="p">,</span> <span class="mf">0.88425</span><span class="p">,</span> <span class="mf">0.8911</span><span class="p">,</span> <span class="mf">0.8957666666666667</span><span class="p">,</span> <span class="mf">0.90125</span><span class="p">,</span> <span class="mf">0.9056666666666666</span><span class="p">,</span> <span class="mf">0.9083833333333333</span><span class="p">,</span> <span class="mf">0.9122666666666667</span><span class="p">,</span> <span class="mf">0.91455</span><span class="p">,</span> <span class="mf">0.9176833333333333</span><span class="p">,</span> <span class="mf">0.92035</span><span class="p">,</span> <span class="mf">0.9217</span><span class="p">,</span> <span class="mf">0.9232333333333334</span><span class="p">,</span> <span class="mf">0.9238333333333333</span><span class="p">,</span> <span class="mf">0.9270333333333334</span><span class="p">,</span> <span class="mf">0.9283</span><span class="p">,</span> <span class="mf">0.93035</span><span class="p">,</span> <span class="mf">0.9312333333333334</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.390482270359993</span><span class="p">,</span> <span class="mf">0.3140819278359413</span><span class="p">,</span> <span class="mf">0.286346542596817</span><span class="p">,</span> <span class="mf">0.26530489122867584</span><span class="p">,</span> <span class="mf">0.25648517191410064</span><span class="p">,</span> <span class="mf">0.25534764647483826</span><span class="p">,</span> <span class="mf">0.24066219604015351</span><span class="p">,</span> <span class="mf">0.22813884472846985</span><span class="p">,</span> <span class="mf">0.22091108289361</span><span class="p">,</span> <span class="mf">0.22591463786363603</span><span class="p">,</span> <span class="mf">0.22548504903912545</span><span class="p">,</span> <span class="mf">0.21807716876268388</span><span class="p">,</span> <span class="mf">0.23463654381036758</span><span class="p">,</span> <span class="mf">0.21917386519908905</span><span class="p">,</span> <span class="mf">0.2077158398628235</span><span class="p">,</span> <span class="mf">0.2112607652246952</span><span class="p">,</span> <span class="mf">0.205703763961792</span><span class="p">,</span> <span class="mf">0.21748955991864205</span><span class="p">,</span> <span class="mf">0.20092388433218003</span><span class="p">,</span> <span class="mf">0.20742826372385026</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.859125</span><span class="p">,</span> <span class="mf">0.884375</span><span class="p">,</span> <span class="mf">0.89225</span><span class="p">,</span> <span class="mf">0.9035</span><span class="p">,</span> <span class="mf">0.9045</span><span class="p">,</span> <span class="mf">0.904875</span><span class="p">,</span> <span class="mf">0.907875</span><span class="p">,</span> <span class="mf">0.915375</span><span class="p">,</span> <span class="mf">0.914875</span><span class="p">,</span> <span class="mf">0.915375</span><span class="p">,</span> <span class="mf">0.916375</span><span class="p">,</span> <span class="mf">0.92075</span><span class="p">,</span> <span class="mf">0.91575</span><span class="p">,</span> <span class="mf">0.91825</span><span class="p">,</span> <span class="mf">0.92375</span><span class="p">,</span> <span class="mf">0.924</span><span class="p">,</span> <span class="mf">0.924875</span><span class="p">,</span> <span class="mf">0.917125</span><span class="p">,</span> <span class="mf">0.926875</span><span class="p">,</span> <span class="mf">0.920875</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.1608194957918196</span><span class="p">,</span> <span class="mf">0.8736483463918222</span><span class="p">,</span> <span class="mf">0.7270457689632485</span><span class="p">,</span> <span class="mf">0.6118623841482439</span><span class="p">,</span> <span class="mf">0.5539627463769302</span><span class="p">,</span> <span class="mf">0.5169604117872872</span><span class="p">,</span> <span class="mf">0.4843029365547176</span><span class="p">,</span> <span class="mf">0.4664089765979537</span><span class="p">,</span> <span class="mf">0.449539397952399</span><span class="p">,</span> <span class="mf">0.4308713404481599</span><span class="p">,</span> <span class="mf">0.4170197155842903</span><span class="p">,</span> <span class="mf">0.4104185118508746</span><span class="p">,</span> <span class="mf">0.3983522486299086</span><span class="p">,</span> <span class="mf">0.3890672579232945</span><span class="p">,</span> <span class="mf">0.38423672571047535</span><span class="p">,</span> <span class="mf">0.38125834129512437</span><span class="p">,</span> <span class="mf">0.36963055836461756</span><span class="p">,</span> <span class="mf">0.36898326972273116</span><span class="p">,</span> <span class="mf">0.3608236700328174</span><span class="p">,</span> <span class="mf">0.35822524538617145</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.56785</span><span class="p">,</span> <span class="mf">0.6591833333333333</span><span class="p">,</span> <span class="mf">0.71765</span><span class="p">,</span> <span class="mf">0.7660333333333333</span><span class="p">,</span> <span class="mf">0.7931666666666667</span><span class="p">,</span> <span class="mf">0.8079666666666667</span><span class="p">,</span> <span class="mf">0.8198833333333333</span><span class="p">,</span> <span class="mf">0.8275166666666667</span><span class="p">,</span> <span class="mf">0.8349833333333333</span><span class="p">,</span> <span class="mf">0.8422</span><span class="p">,</span> <span class="mf">0.8473666666666667</span><span class="p">,</span> <span class="mf">0.8486833333333333</span><span class="p">,</span> <span class="mf">0.85425</span><span class="p">,</span> <span class="mf">0.85675</span><span class="p">,</span> <span class="mf">0.8578666666666667</span><span class="p">,</span> <span class="mf">0.8603333333333333</span><span class="p">,</span> <span class="mf">0.8643333333333333</span><span class="p">,</span> <span class="mf">0.8637833333333333</span><span class="p">,</span> <span class="mf">0.8684333333333333</span><span class="p">,</span> <span class="mf">0.8680166666666667</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5984484012126923</span><span class="p">,</span> <span class="mf">0.5152713191509247</span><span class="p">,</span> <span class="mf">0.42289899206161496</span><span class="p">,</span> <span class="mf">0.3746640253067017</span><span class="p">,</span> <span class="mf">0.3369040569067001</span><span class="p">,</span> <span class="mf">0.32359291434288023</span><span class="p">,</span> <span class="mf">0.2978636801838875</span><span class="p">,</span> <span class="mf">0.2998174095153809</span><span class="p">,</span> <span class="mf">0.2883352539539337</span><span class="p">,</span> <span class="mf">0.2839300352931023</span><span class="p">,</span> <span class="mf">0.2775397801399231</span><span class="p">,</span> <span class="mf">0.2616970262527466</span><span class="p">,</span> <span class="mf">0.259125192284584</span><span class="p">,</span> <span class="mf">0.25470315623283385</span><span class="p">,</span> <span class="mf">0.2535187450051308</span><span class="p">,</span> <span class="mf">0.2600560383200645</span><span class="p">,</span> <span class="mf">0.25031394577026367</span><span class="p">,</span> <span class="mf">0.2547155976295471</span><span class="p">,</span> <span class="mf">0.23950587111711502</span><span class="p">,</span> <span class="mf">0.24401323813199996</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.750875</span><span class="p">,</span> <span class="mf">0.78025</span><span class="p">,</span> <span class="mf">0.86225</span><span class="p">,</span> <span class="mf">0.869875</span><span class="p">,</span> <span class="mf">0.884875</span><span class="p">,</span> <span class="mf">0.891625</span><span class="p">,</span> <span class="mf">0.898875</span><span class="p">,</span> <span class="mf">0.89275</span><span class="p">,</span> <span class="mf">0.901875</span><span class="p">,</span> <span class="mf">0.9005</span><span class="p">,</span> <span class="mf">0.899875</span><span class="p">,</span> <span class="mf">0.908375</span><span class="p">,</span> <span class="mf">0.91125</span><span class="p">,</span> <span class="mf">0.910375</span><span class="p">,</span> <span class="mf">0.910375</span><span class="p">,</span> <span class="mf">0.907</span><span class="p">,</span> <span class="mf">0.9135</span><span class="p">,</span> <span class="mf">0.910375</span><span class="p">,</span> <span class="mf">0.914125</span><span class="p">,</span> <span class="mf">0.911625</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.5018121279410716</span><span class="p">,</span> <span class="mf">0.3649225841834347</span><span class="p">,</span> <span class="mf">0.31199926770985253</span><span class="p">,</span> <span class="mf">0.2825479824850554</span><span class="p">,</span> <span class="mf">0.25993211727057186</span><span class="p">,</span> <span class="mf">0.2431308363737074</span><span class="p">,</span> <span class="mf">0.22870161555913973</span><span class="p">,</span> <span class="mf">0.22126636312587428</span><span class="p">,</span> <span class="mf">0.2113911879540824</span><span class="p">,</span> <span class="mf">0.20279224649834227</span><span class="p">,</span> <span class="mf">0.19300907663603836</span><span class="p">,</span> <span class="mf">0.18686007729360163</span><span class="p">,</span> <span class="mf">0.1815741605866057</span><span class="p">,</span> <span class="mf">0.1759802805684777</span><span class="p">,</span> <span class="mf">0.17041425832084564</span><span class="p">,</span> <span class="mf">0.16513840764014323</span><span class="p">,</span> <span class="mf">0.15892388751861383</span><span class="p">,</span> <span class="mf">0.1548161118118557</span><span class="p">,</span> <span class="mf">0.1498002242614656</span><span class="p">,</span> <span class="mf">0.14744469122107284</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8158</span><span class="p">,</span> <span class="mf">0.8648</span><span class="p">,</span> <span class="mf">0.8846833333333334</span><span class="p">,</span> <span class="mf">0.8954666666666666</span><span class="p">,</span> <span class="mf">0.9035333333333333</span><span class="p">,</span> <span class="mf">0.9097666666666666</span><span class="p">,</span> <span class="mf">0.9142666666666667</span><span class="p">,</span> <span class="mf">0.91615</span><span class="p">,</span> <span class="mf">0.9219166666666667</span><span class="p">,</span> <span class="mf">0.9239333333333334</span><span class="p">,</span> <span class="mf">0.9268166666666666</span><span class="p">,</span> <span class="mf">0.9287666666666666</span><span class="p">,</span> <span class="mf">0.9304833333333333</span><span class="p">,</span> <span class="mf">0.9327333333333333</span><span class="p">,</span> <span class="mf">0.9365</span><span class="p">,</span> <span class="mf">0.9368666666666666</span><span class="p">,</span> <span class="mf">0.9395333333333333</span><span class="p">,</span> <span class="mf">0.9418833333333333</span><span class="p">,</span> <span class="mf">0.9445</span><span class="p">,</span> <span class="mf">0.9450166666666666</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.35916801404953</span><span class="p">,</span> <span class="mf">0.30038927191495896</span><span class="p">,</span> <span class="mf">0.2824265750646591</span><span class="p">,</span> <span class="mf">0.28094157111644746</span><span class="p">,</span> <span class="mf">0.2402345055937767</span><span class="p">,</span> <span class="mf">0.24779821130633353</span><span class="p">,</span> <span class="mf">0.2263277245759964</span><span class="p">,</span> <span class="mf">0.22270147562026976</span><span class="p">,</span> <span class="mf">0.22010754531621932</span><span class="p">,</span> <span class="mf">0.20850908517837524</span><span class="p">,</span> <span class="mf">0.21723379525542258</span><span class="p">,</span> <span class="mf">0.20454896742105483</span><span class="p">,</span> <span class="mf">0.2065480750799179</span><span class="p">,</span> <span class="mf">0.20593296563625335</span><span class="p">,</span> <span class="mf">0.21030707907676696</span><span class="p">,</span> <span class="mf">0.2015896993279457</span><span class="p">,</span> <span class="mf">0.19770563289523124</span><span class="p">,</span> <span class="mf">0.19552358242869378</span><span class="p">,</span> <span class="mf">0.197759574085474</span><span class="p">,</span> <span class="mf">0.19900305101275445</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.867125</span><span class="p">,</span> <span class="mf">0.890875</span><span class="p">,</span> <span class="mf">0.896875</span><span class="p">,</span> <span class="mf">0.896</span><span class="p">,</span> <span class="mf">0.912125</span><span class="p">,</span> <span class="mf">0.90875</span><span class="p">,</span> <span class="mf">0.9185</span><span class="p">,</span> <span class="mf">0.916875</span><span class="p">,</span> <span class="mf">0.920375</span><span class="p">,</span> <span class="mf">0.925125</span><span class="p">,</span> <span class="mf">0.919375</span><span class="p">,</span> <span class="mf">0.92675</span><span class="p">,</span> <span class="mf">0.927125</span><span class="p">,</span> <span class="mf">0.924625</span><span class="p">,</span> <span class="mf">0.924125</span><span class="p">,</span> <span class="mf">0.9275</span><span class="p">,</span> <span class="mf">0.928</span><span class="p">,</span> <span class="mf">0.928875</span><span class="p">,</span> <span class="mf">0.93325</span><span class="p">,</span> <span class="mf">0.930125</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.564780301424359</span><span class="p">,</span> <span class="mf">0.41836969141385705</span><span class="p">,</span> <span class="mf">0.3581543931924204</span><span class="p">,</span> <span class="mf">0.3251280398018706</span><span class="p">,</span> <span class="mf">0.30215959723538427</span><span class="p">,</span> <span class="mf">0.28700008430778345</span><span class="p">,</span> <span class="mf">0.27507679125488693</span><span class="p">,</span> <span class="mf">0.26540731782439164</span><span class="p">,</span> <span class="mf">0.25373875692105496</span><span class="p">,</span> <span class="mf">0.24964979071734048</span><span class="p">,</span> <span class="mf">0.24098571216357922</span><span class="p">,</span> <span class="mf">0.23604591902512223</span><span class="p">,</span> <span class="mf">0.2270722362135392</span><span class="p">,</span> <span class="mf">0.2229606584985373</span><span class="p">,</span> <span class="mf">0.22031292727570545</span><span class="p">,</span> <span class="mf">0.21439386613126885</span><span class="p">,</span> <span class="mf">0.21020108821200156</span><span class="p">,</span> <span class="mf">0.2042837777872012</span><span class="p">,</span> <span class="mf">0.20376247368149283</span><span class="p">,</span> <span class="mf">0.20021205727082453</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7927</span><span class="p">,</span> <span class="mf">0.8474166666666667</span><span class="p">,</span> <span class="mf">0.8672166666666666</span><span class="p">,</span> <span class="mf">0.8811833333333333</span><span class="p">,</span> <span class="mf">0.8883</span><span class="p">,</span> <span class="mf">0.8952833333333333</span><span class="p">,</span> <span class="mf">0.89795</span><span class="p">,</span> <span class="mf">0.9011333333333333</span><span class="p">,</span> <span class="mf">0.9055833333333333</span><span class="p">,</span> <span class="mf">0.9071166666666667</span><span class="p">,</span> <span class="mf">0.9100333333333334</span><span class="p">,</span> <span class="mf">0.911</span><span class="p">,</span> <span class="mf">0.91515</span><span class="p">,</span> <span class="mf">0.9162166666666667</span><span class="p">,</span> <span class="mf">0.91775</span><span class="p">,</span> <span class="mf">0.9197833333333333</span><span class="p">,</span> <span class="mf">0.9218666666666666</span><span class="p">,</span> <span class="mf">0.9239</span><span class="p">,</span> <span class="mf">0.9236833333333333</span><span class="p">,</span> <span class="mf">0.92455</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.39558523416519165</span><span class="p">,</span> <span class="mf">0.3187315353155136</span><span class="p">,</span> <span class="mf">0.30105597496032716</span><span class="p">,</span> <span class="mf">0.2717038299441338</span><span class="p">,</span> <span class="mf">0.25286867189407347</span><span class="p">,</span> <span class="mf">0.24664685553312302</span><span class="p">,</span> <span class="mf">0.24286985045671464</span><span class="p">,</span> <span class="mf">0.23643679201602935</span><span class="p">,</span> <span class="mf">0.23006864881515504</span><span class="p">,</span> <span class="mf">0.2277349520921707</span><span class="p">,</span> <span class="mf">0.22591854375600814</span><span class="p">,</span> <span class="mf">0.2165311907827854</span><span class="p">,</span> <span class="mf">0.21385486593842506</span><span class="p">,</span> <span class="mf">0.21402871897816658</span><span class="p">,</span> <span class="mf">0.2096972267627716</span><span class="p">,</span> <span class="mf">0.21242560443282127</span><span class="p">,</span> <span class="mf">0.2098898750245571</span><span class="p">,</span> <span class="mf">0.2062524998188019</span><span class="p">,</span> <span class="mf">0.19932547932863234</span><span class="p">,</span> <span class="mf">0.20170186588168143</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.850625</span><span class="p">,</span> <span class="mf">0.88125</span><span class="p">,</span> <span class="mf">0.8845</span><span class="p">,</span> <span class="mf">0.897125</span><span class="p">,</span> <span class="mf">0.9065</span><span class="p">,</span> <span class="mf">0.9085</span><span class="p">,</span> <span class="mf">0.907625</span><span class="p">,</span> <span class="mf">0.91275</span><span class="p">,</span> <span class="mf">0.917125</span><span class="p">,</span> <span class="mf">0.9135</span><span class="p">,</span> <span class="mf">0.91825</span><span class="p">,</span> <span class="mf">0.922625</span><span class="p">,</span> <span class="mf">0.91925</span><span class="p">,</span> <span class="mf">0.921125</span><span class="p">,</span> <span class="mf">0.923625</span><span class="p">,</span> <span class="mf">0.92225</span><span class="p">,</span> <span class="mf">0.923375</span><span class="p">,</span> <span class="mf">0.922875</span><span class="p">,</span> <span class="mf">0.925625</span><span class="p">,</span> <span class="mf">0.92775</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.6916971901205303</span><span class="p">,</span> <span class="mf">0.4947840944567977</span><span class="p">,</span> <span class="mf">0.41710148827988963</span><span class="p">,</span> <span class="mf">0.38678343986460906</span><span class="p">,</span> <span class="mf">0.36429949198513906</span><span class="p">,</span> <span class="mf">0.34339441834831796</span><span class="p">,</span> <span class="mf">0.33055868282564665</span><span class="p">,</span> <span class="mf">0.3199633415272114</span><span class="p">,</span> <span class="mf">0.31550557391920575</span><span class="p">,</span> <span class="mf">0.3022628513289921</span><span class="p">,</span> <span class="mf">0.2959158662110885</span><span class="p">,</span> <span class="mf">0.2941135993993867</span><span class="p">,</span> <span class="mf">0.28555906579089063</span><span class="p">,</span> <span class="mf">0.27903660322462065</span><span class="p">,</span> <span class="mf">0.2769482293601102</span><span class="p">,</span> <span class="mf">0.27154609372716215</span><span class="p">,</span> <span class="mf">0.26548120195963487</span><span class="p">,</span> <span class="mf">0.26188135733291795</span><span class="p">,</span> <span class="mf">0.2588035051009929</span><span class="p">,</span> <span class="mf">0.2574938320115939</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7497333333333334</span><span class="p">,</span> <span class="mf">0.8236833333333333</span><span class="p">,</span> <span class="mf">0.8482333333333333</span><span class="p">,</span> <span class="mf">0.8618666666666667</span><span class="p">,</span> <span class="mf">0.8703666666666666</span><span class="p">,</span> <span class="mf">0.8772166666666666</span><span class="p">,</span> <span class="mf">0.8803333333333333</span><span class="p">,</span> <span class="mf">0.8829166666666667</span><span class="p">,</span> <span class="mf">0.88525</span><span class="p">,</span> <span class="mf">0.88945</span><span class="p">,</span> <span class="mf">0.89275</span><span class="p">,</span> <span class="mf">0.8937166666666667</span><span class="p">,</span> <span class="mf">0.8969</span><span class="p">,</span> <span class="mf">0.8977666666666667</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.90175</span><span class="p">,</span> <span class="mf">0.9041666666666667</span><span class="p">,</span> <span class="mf">0.9035</span><span class="p">,</span> <span class="mf">0.9049</span><span class="p">,</span> <span class="mf">0.9046166666666666</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.41916924858093263</span><span class="p">,</span> <span class="mf">0.3380992366075516</span><span class="p">,</span> <span class="mf">0.31549062132835387</span><span class="p">,</span> <span class="mf">0.2921286026239395</span><span class="p">,</span> <span class="mf">0.2786481494307518</span><span class="p">,</span> <span class="mf">0.28516836106777194</span><span class="p">,</span> <span class="mf">0.25556409001350405</span><span class="p">,</span> <span class="mf">0.2538892236948013</span><span class="p">,</span> <span class="mf">0.24726227968931197</span><span class="p">,</span> <span class="mf">0.24262803781032563</span><span class="p">,</span> <span class="mf">0.24080126863718032</span><span class="p">,</span> <span class="mf">0.24242325466871262</span><span class="p">,</span> <span class="mf">0.23416680485010147</span><span class="p">,</span> <span class="mf">0.22847312396764755</span><span class="p">,</span> <span class="mf">0.22423979061841964</span><span class="p">,</span> <span class="mf">0.2311997367441654</span><span class="p">,</span> <span class="mf">0.22794704174995423</span><span class="p">,</span> <span class="mf">0.21943940049409866</span><span class="p">,</span> <span class="mf">0.21820387506484987</span><span class="p">,</span> <span class="mf">0.21150743806362152</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.8435</span><span class="p">,</span> <span class="mf">0.87725</span><span class="p">,</span> <span class="mf">0.88425</span><span class="p">,</span> <span class="mf">0.890375</span><span class="p">,</span> <span class="mf">0.898125</span><span class="p">,</span> <span class="mf">0.89275</span><span class="p">,</span> <span class="mf">0.905625</span><span class="p">,</span> <span class="mf">0.906125</span><span class="p">,</span> <span class="mf">0.911</span><span class="p">,</span> <span class="mf">0.910625</span><span class="p">,</span> <span class="mf">0.911</span><span class="p">,</span> <span class="mf">0.909875</span><span class="p">,</span> <span class="mf">0.914875</span><span class="p">,</span> <span class="mf">0.915375</span><span class="p">,</span> <span class="mf">0.917875</span><span class="p">,</span> <span class="mf">0.915</span><span class="p">,</span> <span class="mf">0.91475</span><span class="p">,</span> <span class="mf">0.919625</span><span class="p">,</span> <span class="mf">0.923875</span><span class="p">,</span> <span class="mf">0.92425</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.162218615571573</span><span class="p">,</span> <span class="mf">0.8284856370453642</span><span class="p">,</span> <span class="mf">0.7309887468624217</span><span class="p">,</span> <span class="mf">0.6590983641744931</span><span class="p">,</span> <span class="mf">0.6089096262510906</span><span class="p">,</span> <span class="mf">0.5663433943285363</span><span class="p">,</span> <span class="mf">0.5383681068733048</span><span class="p">,</span> <span class="mf">0.5242803116787725</span><span class="p">,</span> <span class="mf">0.49926126579930785</span><span class="p">,</span> <span class="mf">0.48940120944018556</span><span class="p">,</span> <span class="mf">0.4789252862779062</span><span class="p">,</span> <span class="mf">0.46633604049746163</span><span class="p">,</span> <span class="mf">0.4596060775458686</span><span class="p">,</span> <span class="mf">0.4464966354847971</span><span class="p">,</span> <span class="mf">0.4418302221593064</span><span class="p">,</span> <span class="mf">0.43759817490254893</span><span class="p">,</span> <span class="mf">0.42892070028827645</span><span class="p">,</span> <span class="mf">0.4226101264516428</span><span class="p">,</span> <span class="mf">0.418694807601763</span><span class="p">,</span> <span class="mf">0.4110745745840103</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.58005</span><span class="p">,</span> <span class="mf">0.6824666666666667</span><span class="p">,</span> <span class="mf">0.7223333333333334</span><span class="p">,</span> <span class="mf">0.7464333333333333</span><span class="p">,</span> <span class="mf">0.7711333333333333</span><span class="p">,</span> <span class="mf">0.7891833333333333</span><span class="p">,</span> <span class="mf">0.8012333333333334</span><span class="p">,</span> <span class="mf">0.80635</span><span class="p">,</span> <span class="mf">0.8172666666666667</span><span class="p">,</span> <span class="mf">0.82225</span><span class="p">,</span> <span class="mf">0.8271833333333334</span><span class="p">,</span> <span class="mf">0.831</span><span class="p">,</span> <span class="mf">0.8335833333333333</span><span class="p">,</span> <span class="mf">0.8371833333333333</span><span class="p">,</span> <span class="mf">0.8412166666666666</span><span class="p">,</span> <span class="mf">0.84265</span><span class="p">,</span> <span class="mf">0.8458833333333333</span><span class="p">,</span> <span class="mf">0.8471166666666666</span><span class="p">,</span> <span class="mf">0.8497666666666667</span><span class="p">,</span> <span class="mf">0.8522833333333333</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5945872340202332</span><span class="p">,</span> <span class="mf">0.518519122838974</span><span class="p">,</span> <span class="mf">0.4681703653335571</span><span class="p">,</span> <span class="mf">0.42978407418727876</span><span class="p">,</span> <span class="mf">0.40349935555458066</span><span class="p">,</span> <span class="mf">0.37377681517601014</span><span class="p">,</span> <span class="mf">0.35234942865371705</span><span class="p">,</span> <span class="mf">0.3359788683652878</span><span class="p">,</span> <span class="mf">0.3217720929384232</span><span class="p">,</span> <span class="mf">0.3279728285074234</span><span class="p">,</span> <span class="mf">0.3114012089371681</span><span class="p">,</span> <span class="mf">0.3060767319202423</span><span class="p">,</span> <span class="mf">0.2949701727628708</span><span class="p">,</span> <span class="mf">0.2981588536500931</span><span class="p">,</span> <span class="mf">0.2855641575455666</span><span class="p">,</span> <span class="mf">0.28112928783893587</span><span class="p">,</span> <span class="mf">0.28212732630968096</span><span class="p">,</span> <span class="mf">0.27846804082393645</span><span class="p">,</span> <span class="mf">0.27372796374559405</span><span class="p">,</span> <span class="mf">0.27415593349933626</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.78525</span><span class="p">,</span> <span class="mf">0.8215</span><span class="p">,</span> <span class="mf">0.820125</span><span class="p">,</span> <span class="mf">0.844375</span><span class="p">,</span> <span class="mf">0.86375</span><span class="p">,</span> <span class="mf">0.875125</span><span class="p">,</span> <span class="mf">0.876625</span><span class="p">,</span> <span class="mf">0.882</span><span class="p">,</span> <span class="mf">0.887875</span><span class="p">,</span> <span class="mf">0.884625</span><span class="p">,</span> <span class="mf">0.890375</span><span class="p">,</span> <span class="mf">0.892125</span><span class="p">,</span> <span class="mf">0.897125</span><span class="p">,</span> <span class="mf">0.894125</span><span class="p">,</span> <span class="mf">0.902625</span><span class="p">,</span> <span class="mf">0.89975</span><span class="p">,</span> <span class="mf">0.89975</span><span class="p">,</span> <span class="mf">0.90125</span><span class="p">,</span> <span class="mf">0.902</span><span class="p">,</span> <span class="mf">0.90075</span><span class="p">]]]</span>


<span class="n">Dropout1</span> <span class="o">=</span> <span class="mf">0.25</span> <span class="c1"># param {type:"slider", min:0, max:0.75, step:0.25}</span>
<span class="n">Dropout2</span> <span class="o">=</span> <span class="mf">0.75</span> <span class="c1"># param {type:"slider", min:0, max:0.75, step:0.25}</span>

<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">Dropout1</span><span class="p">,</span> <span class="n">Dropout2</span><span class="p">):</span>
  <span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">validation_loss</span><span class="p">,</span> <span class="n">validation_acc</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">Dropout1</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">Dropout2</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)]</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">)</span>
  <span class="n">plot_loss_accuracy</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">validation_loss</span><span class="p">,</span> <span class="n">validation_acc</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">my_stringIObytes</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">my_stringIObytes</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'png'</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
  <span class="n">my_stringIObytes</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">my_base64_jpgData</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">my_stringIObytes</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
  <span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="s2">"""&lt;img src="data:image/png;base64,"""</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">my_base64_jpgData</span><span class="p">)[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">"""" alt="Graph"&gt;"""</span>

<span class="n">d1</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"Dropout 1"</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">,</span> <span class="s1">'width'</span><span class="p">:</span> <span class="s1">'800px'</span><span class="p">},</span> <span class="p">)</span>
<span class="n">d2</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"Dropout 2"</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">,</span> <span class="s1">'width'</span><span class="p">:</span> <span class="s1">'800px'</span><span class="p">},</span> <span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="s2">"aasdsd"</span><span class="p">)</span>

<span class="n">w</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">plot</span><span class="p">,</span> <span class="p">{</span><span class="s2">"Dropout1"</span><span class="p">:</span><span class="n">d1</span><span class="p">,</span> <span class="s2">"Dropout2"</span><span class="p">:</span> <span class="n">d2</span><span class="p">})</span>
<span class="n">display</span><span class="p">(</span><span class="n">widgets</span><span class="o">.</span><span class="n">VBox</span><span class="p">([</span><span class="n">d1</span><span class="p">,</span> <span class="n">d2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">w</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-bonus-2-2-how-much-does-augmentation-help">
<h3>Coding Exercise Bonus 2.2: How much does augmentation help?<a class="headerlink" href="#coding-exercise-bonus-2-2-how-much-does-augmentation-help" title="Permalink to this headline">¶</a></h3>
<p>Last week you also learned how data augmentation can  regularize a network. Let’s add data augmentation to our model via transforms and see if that helps our model to better generalize! In the following cell, add the transforms you want in the list <code class="docutils literal notranslate"><span class="pre">augmentation_transforms</span></code>. We will then run the same network you created in the above exercise (with regularization) and then plot the loss and accuracies.</p>
<p><a class="reference external" href="https://pytorch.org/vision/stable/transforms.html">Here</a> is the link to the list of transforms available in PyTorch.</p>
<div class="section" id="download-fashion-mnist-if-it-has-not-been-downloaded">
<h4>Download Fashion-MNIST, if it has not been downloaded.<a class="headerlink" href="#download-fashion-mnist-if-it-has-not-been-downloaded" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download Fashion-MNIST, if it has not been downloaded.</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s1">'FashionMNIST.tar.gz'</span>
<span class="n">folder</span> <span class="o">=</span> <span class="s1">'FashionMNIST'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/dfhu5/download"</span>
<span class="n">download_data</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">tar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transforms_custom</span><span class="p">(</span><span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Helper function defining transformations</span>

<span class="sd">  Args:</span>
<span class="sd">    binary: boolean</span>
<span class="sd">      If True, number of classes = 2</span>
<span class="sd">    download: boolean</span>
<span class="sd">      If True, download dataset</span>
<span class="sd">    seed: int</span>
<span class="sd">      Set seed for reproducibility</span>

<span class="sd">  Returns:</span>
<span class="sd">    train_loader: torch.loader</span>
<span class="sd">      Training Set</span>
<span class="sd">    test_loader: torch.loader</span>
<span class="sd">      Test Set</span>
<span class="sd">    validation_loader: torch.loader</span>
<span class="sd">      Validation Set</span>
<span class="sd">  """</span>
  <span class="c1"># Basic preprocessing</span>
  <span class="n">preprocessing_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                              <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))]</span>
  <span class="c1"># Add the augmentation transforms to the preprocessing</span>
  <span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">get_augmentation_transforms</span><span class="p">()</span> <span class="o">+</span>
                                       <span class="n">preprocessing_transforms</span><span class="p">)</span>
  <span class="c1"># Load the Fashion MNIST dataset with the transforms</span>
  <span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span>
                                     <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                                     <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">transform</span><span class="o">=</span><span class="n">train_transform</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">binary</span><span class="p">:</span>
    <span class="c1"># Reduce to our two classes to speed up training</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">reduce_classes</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

  <span class="c1"># Get the data loader instances for the dataset</span>
  <span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">get_data_loaders</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                                                                  <span class="n">validation_data</span><span class="p">,</span>
                                                                  <span class="n">test_data</span><span class="p">,</span>
                                                                  <span class="n">seed</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">,</span> <span class="n">test_loader</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_augmentation_transforms</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Returns Augmentation Transforms</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    augmentation_transforms: list</span>
<span class="sd">      List of augmentation transforms</span>
<span class="sd">  """</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in missing code below (...),</span>
  <span class="c1"># then remove or comment the line below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Add Transforms"</span><span class="p">)</span>
  <span class="c1">####################################################################</span>
  <span class="n">augmentation_transforms</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">augmentation_transforms</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">net3</span> <span class="o">=</span> <span class="n">FMNIST_Net2</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>  <span class="c1"># Get the network</span>

<span class="c1">## Uncomment below to test your function</span>
<span class="c1"># train_loader, validation_loader, test_loader = transforms_custom(binary=True, seed=SEED)</span>
<span class="c1"># train_loss, train_acc, validation_loss, validation_acc = train(net3, DEVICE, train_loader, validation_loader, 20)</span>
<span class="c1"># print(f'Test accuracy is: {test(net3, DEVICE, test_loader)}')</span>
<span class="c1"># plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_240aa557.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_240aa557_3.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D2_ConvnetsAndDlThinking/static/W2D2_Tutorial1_Solution_240aa557_3.png" style="width: 2195.0px; height: 755.0px;"/></a>
</div>
</div>
<div class="section" id="think-bonus-2-2-data-augmentation">
<h3>Think! Bonus 2.2: Data Augmentation<a class="headerlink" href="#think-bonus-2-2-data-augmentation" title="Permalink to this headline">¶</a></h3>
<p>Did the training accuracy reduce further compared to with dropout alone? Is the model still overfitting?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D2_ConvnetsAndDlThinking/solutions/W2D2_Tutorial1_Solution_ae125a93.py"><em>Click for solution</em></a></p>
<p>Great! In this section you trained what may have been your very first CNN. You added regularization and data augmentation in order to get a model that generalizes well. All the pieces are beginning to fit together!</p>
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W2D2_ConvnetsAndDlThinking/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="../chapter_title.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Convnets And Dl Thinking</p>
</div>
</a>
<a class="right-next" href="W2D2_Tutorial2.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 2: Deep Learning Thinking 1: Cost Functions</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under under a <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</br></p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>