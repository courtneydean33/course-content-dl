
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 2: Time series for Language — Neuromatch Academy: Deep Learning</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-dl-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D5_Tutorial3.html" rel="next" title="(Bonus) Tutorial 3: Multilingual Embeddings"/>
<link href="W2D5_Tutorial1.html" rel="prev" title="Tutorial 1: Introduction to processing time series"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/DeepLearning.html">
   Prerequisites and preparatory materials for NMA Deep Learning
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Basics Module
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_BonusLecture.html">
     Bonus Lecture: Yoshua Bengio
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Fine Tuning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Optimization/chapter_title.html">
   Optimization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Optimization/student/W1D5_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_Regularization/chapter_title.html">
   Regularization (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_Regularization/student/W2D1_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/FineTuning.html">
   Deep Learning: The Basics and Fine Tuning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/chapter_title.html">
   Convnets And Dl Thinking (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_Tutorial2.html">
     Tutorial 2: Deep Learning Thinking 1: Cost Functions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ConvnetsAndDlThinking/student/W2D2_BonusLecture.html">
     Bonus Lecture: Kyunghyun Cho
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernConvnets/student/W2D3_Tutorial2.html">
     (Bonus) Tutorial 2: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_GenerativeModels/chapter_title.html">
   Generative Models (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial2.html">
     Tutorial 2: Introduction to GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_Tutorial4.html">
     (Bonus) Tutorial 4: Deploying Neural Networks on the Web
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_GenerativeModels/student/W2D4_BonusLecture.html">
     Bonus Lecture: Geoffrey Hinton
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Natural Language Processing
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Time Series And Natural Language Processing (W2D5)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W2D5_Tutorial1.html">
     Tutorial 1: Introduction to processing time series
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 2: Time series for Language
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W2D5_Tutorial3.html">
     (Bonus) Tutorial 3: Multilingual Embeddings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_AttentionAndTransformers/student/W3D1_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_DlThinking2/chapter_title.html">
   Dl Thinking2 (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_DlThinking2/student/W3D2_Tutorial1.html">
     Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/NaturalLanguageProcessing.html">
   Deep Learning: Convnets and NLP
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_UnsupervisedAndSelfSupervisedLearning/student/W3D3_BonusLecture.html">
     Bonus Lecture: Melanie Mitchell
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_Tutorial5.html">
     (Bonus) Tutorial 5: Function approximation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_BasicReinforcementLearning/student/W3D4_BonusLecture.html">
     Bonus Lecture: Chealsea Finn
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial1.html">
     Tutorial 1: Game Set-Up and Random Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial2.html">
     Tutorial 2: Value-Based Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial3.html">
     Tutorial 3: Policy-based Player
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_Tutorial4.html">
     Bonus Tutorial: Planning with Monte Carlo
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_ReinforcementLearningForGames/student/W3D5_BonusLecture.html">
     Bonus Lecture: Amita Kapoor
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/ReinforcementLearning.html">
   Deep Learning: Reinforcement Learning Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Time series for Language
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
     Setup
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
       Install dependencies
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
       Figure Settings
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-dataset-from-nltk">
       Load Dataset from
       <code class="docutils literal notranslate">
<span class="pre">
         nltk
        </span>
</code>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
       Set random seed
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
       Set device (GPU or CPU). Execute
       <code class="docutils literal notranslate">
<span class="pre">
         set_device()
        </span>
</code>
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-recurrent-neural-networks-rnns">
   Section 1: Recurrent Neural Networks (RNNs)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-introduction">
     Section 1.1: Introduction
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-rnns">
       Video 1: RNNs
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-rnn-basic-architectures">
       Video 2: RNN: Basic Architectures
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#dataset">
       Dataset
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-dataset-function">
         Load dataset function
        </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#explore-dataset">
         Explore Dataset
        </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
         Helper Functions
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-2-1d-cnn">
     Section 1.2: 1D CNN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-time-series">
       Video 3: Time Series
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-implement-a-1d-cnn">
       Coding Exercise 1: Implement a 1D CNN
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-3-vanilla-rnn">
     Section 1.3: Vanilla RNN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-implement-a-vanilla-rnn">
       Coding Exercise 2: Implement a Vanilla RNN
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-rnn-applications-and-language-models">
   Section 2: RNN applications and Language Models
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#important">
<strong>
      Important!
     </strong>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-rnn-architectures-for-nlp">
     Video 4: RNN Architectures for NLP
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-text-generation-and-language-modelling">
     Section 2.1: Text Generation and Language Modelling
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-sequence-modeling">
       Video 5: Sequence Modeling
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-implement-text-generation">
       Coding Exercise 3: Implement Text generation
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-sequence-tagging">
     Section 2.2: Sequence Tagging
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-tagging">
       Video 6: Tagging
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-implement-sequence-labelling">
       Coding Exercise 4: Implement Sequence Labelling
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#evaluation">
       Evaluation
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#training">
       Training
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-3-sequence-to-sequence">
     Section 2.3: Sequence to Sequence
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-seq2seq">
       Video 7: Seq2Seq
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-download-and-preprocessing">
       Data download and Preprocessing
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#padding">
       Padding
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#encoder-and-decoder-architecture">
       Encoder and Decoder Architecture
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-5-implement-encoder-and-decoder">
         Coding Exercise 5: Implement Encoder and Decoder
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Evaluation
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-summary">
     Video 8: Summary
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-exploring-input-length-for-rnns">
   Bonus 1: Exploring input length for RNNs
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-improving-text-generation">
   Bonus 2: Improving Text Generation
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-1-improving-text-generation">
     Bonus Coding Exercise 1: Improving Text Generation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#execute-cell-to-train-the-model">
       Execute cell to train the model
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 2: Time series for Language</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Time series for Language
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
     Setup
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
       Install dependencies
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
       Figure Settings
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-dataset-from-nltk">
       Load Dataset from
       <code class="docutils literal notranslate">
<span class="pre">
         nltk
        </span>
</code>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
       Set random seed
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
       Set device (GPU or CPU). Execute
       <code class="docutils literal notranslate">
<span class="pre">
         set_device()
        </span>
</code>
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-recurrent-neural-networks-rnns">
   Section 1: Recurrent Neural Networks (RNNs)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-introduction">
     Section 1.1: Introduction
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-rnns">
       Video 1: RNNs
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-rnn-basic-architectures">
       Video 2: RNN: Basic Architectures
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#dataset">
       Dataset
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#load-dataset-function">
         Load dataset function
        </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#explore-dataset">
         Explore Dataset
        </a>
</li>
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
         Helper Functions
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-2-1d-cnn">
     Section 1.2: 1D CNN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-time-series">
       Video 3: Time Series
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-implement-a-1d-cnn">
       Coding Exercise 1: Implement a 1D CNN
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-3-vanilla-rnn">
     Section 1.3: Vanilla RNN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-implement-a-vanilla-rnn">
       Coding Exercise 2: Implement a Vanilla RNN
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-rnn-applications-and-language-models">
   Section 2: RNN applications and Language Models
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#important">
<strong>
      Important!
     </strong>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-rnn-architectures-for-nlp">
     Video 4: RNN Architectures for NLP
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-text-generation-and-language-modelling">
     Section 2.1: Text Generation and Language Modelling
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-sequence-modeling">
       Video 5: Sequence Modeling
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-implement-text-generation">
       Coding Exercise 3: Implement Text generation
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-sequence-tagging">
     Section 2.2: Sequence Tagging
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-tagging">
       Video 6: Tagging
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-implement-sequence-labelling">
       Coding Exercise 4: Implement Sequence Labelling
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#evaluation">
       Evaluation
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#training">
       Training
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-3-sequence-to-sequence">
     Section 2.3: Sequence to Sequence
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-seq2seq">
       Video 7: Seq2Seq
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-download-and-preprocessing">
       Data download and Preprocessing
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#padding">
       Padding
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#encoder-and-decoder-architecture">
       Encoder and Decoder Architecture
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-5-implement-encoder-and-decoder">
         Coding Exercise 5: Implement Encoder and Decoder
        </a>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Evaluation
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-summary">
     Video 8: Summary
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-1-exploring-input-length-for-rnns">
   Bonus 1: Exploring input length for RNNs
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-2-improving-text-generation">
   Bonus 2: Improving Text Generation
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-1-improving-text-generation">
     Bonus Coding Exercise 1: Improving Text Generation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#execute-cell-to-train-the-model">
       Execute cell to train the model
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student/W2D5_Tutorial2.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-2-time-series-for-language">
<h1>Tutorial 2: Time series for Language<a class="headerlink" href="#tutorial-2-time-series-for-language" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 2, Day 5: Time Series And Natural Language Processing</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Lyle Ungar, Kelson Shilling-Scrivo, Alish Dipani</p>
<p><strong>Content reviewers:</strong> Kelson Shilling-Scrivo</p>
<p><strong>Content editors:</strong> Kelson Shilling-Scrivo</p>
<p><strong>Production editors:</strong> Gagana B, Spiros Chavlis</p>
<br/>
<p><em>Based on Content from: Anushree Hede, Pooja Consul, Ann-Katrin Reuel</em></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>Before we begin with exploring how RNNs excel at modelling sequences, we will explore some of the other ways we can model sequences, encode text, and make meaningful measurements using such encodings and embeddings.</p>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/n23hy/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
<p>These are the slides for the videos in this tutorial. If you want to locally download the slides, click <a class="reference external" href="https://osf.io/n23hy/download">here</a>.</p>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h2>
<div class="section" id="install-dependencies">
<h3>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h3>
<p>There may be <em>errors</em> and/or <em>warnings</em> reported during the installation. However, they are to be ignored.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>

<span class="c1"># @markdown There may be *errors* and/or *warnings* reported during the installation. However, they are to be ignored.</span>
<span class="o">!</span>pip install <span class="nv">torch</span><span class="o">==</span><span class="m">1</span>.8.0+cu111 <span class="nv">torchvision</span><span class="o">==</span><span class="m">0</span>.9.0+cu111 <span class="nv">torchaudio</span><span class="o">==</span><span class="m">0</span>.8.0 <span class="nv">torchtext</span><span class="o">==</span><span class="m">0</span>.9.0 -f https://download.pytorch.org/whl/torch_stable.html --quiet
<span class="o">!</span>pip install unidecode --quiet
<span class="o">!</span>pip install nltk --quiet
<span class="o">!</span>pip install <span class="nv">d2l</span><span class="o">==</span><span class="m">0</span>.16.5 --quiet
<span class="o">!</span>pip install python-Levenshtein --quiet

<span class="o">!</span>pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet

<span class="kn">from</span> <span class="nn">evaltools.airtable</span> <span class="kn">import</span> <span class="n">AirtableForm</span>
<span class="n">atform</span> <span class="o">=</span> <span class="n">AirtableForm</span><span class="p">(</span><span class="s1">'appn7VdPRseSoMXEG'</span><span class="p">,</span><span class="s1">'W2D5_T2'</span><span class="p">,</span><span class="s1">'https://portal.neuromatchacademy.org/api/redirect/to/b4d16463-cbc0-4a8c-b0b6-1cbaa428ee7c'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>

<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">unidecode</span>
<span class="kn">import</span> <span class="nn">collections</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="kn">from</span> <span class="nn">torchtext.legacy</span> <span class="kn">import</span> <span class="n">data</span><span class="p">,</span> <span class="n">datasets</span>

<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h3>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="load-dataset-from-nltk">
<h3>Load Dataset from <code class="docutils literal notranslate"><span class="pre">nltk</span></code><a class="headerlink" href="#load-dataset-from-nltk" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title  Load Dataset from `nltk`</span>
<span class="c1"># No critical warnings, so we suppress it</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">)</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'punkt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h3>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h3>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># For DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Function that controls randomness.</span>
<span class="sd">  NumPy and random modules must be imported.</span>

<span class="sd">  Args:</span>
<span class="sd">    seed : Integer</span>
<span class="sd">      A non-negative integer that defines the random state. Default is `None`.</span>
<span class="sd">    seed_torch : Boolean</span>
<span class="sd">      If `True` sets the random seed for pytorch tensors, so pytorch module</span>
<span class="sd">      must be imported. Default is `True`.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>

<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  DataLoader will reseed workers following randomness in</span>
<span class="sd">  multi-process data loading algorithm.</span>

<span class="sd">  Args:</span>
<span class="sd">    worker_id: integer</span>
<span class="sd">      ID of subprocess to seed. 0 means that</span>
<span class="sd">      the data will be loaded in the main process</span>
<span class="sd">      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h3>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>

<span class="c1"># Inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Set the device. CUDA if available, CPU otherwise</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing</span>
<span class="sd">  """</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
<span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-recurrent-neural-networks-rnns">
<h1>Section 1: Recurrent Neural Networks (RNNs)<a class="headerlink" href="#section-1-recurrent-neural-networks-rnns" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~25mins</em></p>
<div class="section" id="section-1-1-introduction">
<h2>Section 1.1: Introduction<a class="headerlink" href="#section-1-1-introduction" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-1-rnns">
<h3>Video 1: RNNs<a class="headerlink" href="#video-1-rnns" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "5124f46fa8bd4d2aba386feac7b9193a"}
</script></div>
</div>
<p>Recurrent neural networks (RNNs), are a family of neural networks for processing sequential data. Just as a convolutional network is specialized for processing a grid of values <span class="math notranslate nohighlight">\(X\)</span>, such as an image, a recurrent neural network is specialized for processing a sequence of values. RNNs prove useful in many scenarios where other deep learning models are not effective.</p>
<ul class="simple">
<li><p>Not all problems can be converted into one with fixed length inputs and outputs.</p></li>
<li><p>The deep learning models we have seen so far pick samples randomly. This might not be the best strategy for a task of understanding meaning from a piece of text. Words in a text occur in a sequence and therefore cannot be permuted randomly to get the meaning.</p></li>
</ul>
<p>A related idea is the use of convolution across a 1-D temporal sequence. The convolution operation allows a network to share parameters across time but is shallow. The output of convolution is a sequence where each output is a function of a small number of neighboring inputs. The idea of parameter sharing manifests in applying the same convolution kernel at each time step. Recurrent networks share parameters in a diﬀerent way. Each output is a function of the previous hidden layer, always produced using the same model and weights. This recurrent formulation results in the sharing of parameters through a very deep computational graph.</p>
</div>
<div class="section" id="video-2-rnn-basic-architectures">
<h3>Video 2: RNN: Basic Architectures<a class="headerlink" href="#video-2-rnn-basic-architectures" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "b680b950cce444c383a1e4bfccda56f9"}
</script></div>
</div>
<p>The following provides more data than the video (but can be skipped for now). For more detail, see the sources, the <a class="reference external" href="https://www.deeplearningbook.org/contents/rnn.html">deep learning book</a>, and <a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/rnn.html">d2l.ai</a></p>
<p>When the recurrent network is trained to perform a task that requires predicting the future from the past, the network typically learns to use a hidden state at time step <span class="math notranslate nohighlight">\(t\)</span>, <span class="math notranslate nohighlight">\(H_t\)</span> as a kind of lossy summary of the task-relevant aspects of the past sequence of inputs up to <span class="math notranslate nohighlight">\(t\)</span>. This summary is in general necessarily lossy, since it maps an arbitrary length sequence <span class="math notranslate nohighlight">\((X_t, X_{t-1}, X_{t-2}, \dots , X_{2}, X_{1})\)</span> to a ﬁxed length vector <span class="math notranslate nohighlight">\(H_t\)</span>.</p>
<p>We can represent the unfolded recurrence after <span class="math notranslate nohighlight">\(t\)</span> steps with a function <span class="math notranslate nohighlight">\(G_t\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-65ccc753-7539-4039-a24c-804a8eb0a5be">
<span class="eqno">(97)<a class="headerlink" href="#equation-65ccc753-7539-4039-a24c-804a8eb0a5be" title="Permalink to this equation">¶</a></span>\[\begin{equation}
H_t=G_t(X_t, X_{t-1}, X_{t-2}, \dots , X_{2}, X_{1}) = f(H_{t−1}, X_{t}; \theta)
\end{equation}\]</div>
<br/>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnn-2.gif"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnn-2.gif" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnn-2.gif" style="width: 700px;"/></a>
<br/>
<p>The function <span class="math notranslate nohighlight">\(g_t\)</span> takes the whole past sequence <span class="math notranslate nohighlight">\((X_t, X_{t-1}, X_{t-2}, \dots , X_{2}, X_{1})\)</span> as input and produces the current state, but the unfolded recurrent structure allows us to factorize <span class="math notranslate nohighlight">\(g_t\)</span> into repeated application of a function <span class="math notranslate nohighlight">\(f\)</span>. The unfolding process thus introduces two major advantages:</p>
<ul class="simple">
<li><p>Regardless of the sequence length, the learned model always has the same input size, because it is speciﬁed in terms of transition from one state to another state, rather than speciﬁed in terms of a variable-length history of states.</p></li>
<li><p>It is possible to use the same transition function <span class="math notranslate nohighlight">\(f\)</span> with the same parameters at every time step.</p></li>
</ul>
<p>We will now formally write down the equations of a recurrent unit-</p>
<p>Assume that we have a minibatch of inputs <span class="math notranslate nohighlight">\(X_t \in R^{n \times d}\)</span> at time step <span class="math notranslate nohighlight">\(t\)</span>. In other words, for a minibatch of <span class="math notranslate nohighlight">\(n\)</span> sequence examples, each row of <span class="math notranslate nohighlight">\(X_t\)</span> corresponds to one example at time step <span class="math notranslate nohighlight">\(t\)</span> from the sequence. Next, we denote by <span class="math notranslate nohighlight">\(H_t \in R^{n \times h}\)</span> the hidden variable of time step <span class="math notranslate nohighlight">\(t\)</span>. Unlike the MLP, here we save the hidden variable <span class="math notranslate nohighlight">\(H_{t-1}\)</span> from the previous time step and introduce a new weight parameter <span class="math notranslate nohighlight">\(W_{hh} \in R^{h \times h}\)</span> to describe how to use the hidden variable of the previous time step in the current time step. Specifically, the calculation of the hidden variable of the current time step is determined by the input of the current time step together with the hidden variable of the previous time step:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e32c2b57-0bef-4e6a-80bd-e4add3803f8a">
<span class="eqno">(98)<a class="headerlink" href="#equation-e32c2b57-0bef-4e6a-80bd-e4add3803f8a" title="Permalink to this equation">¶</a></span>\[\begin{equation}
H_t = \phi(X_t W_{xh} + H_{t-1}W_{hh} + b_h)
\end{equation}\]</div>
<p>For time step <span class="math notranslate nohighlight">\(t\)</span>, the output of the output layer is similar to the computation in the MLP:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5190ac0d-cb74-4248-83d2-ce8835c7c98a">
<span class="eqno">(99)<a class="headerlink" href="#equation-5190ac0d-cb74-4248-83d2-ce8835c7c98a" title="Permalink to this equation">¶</a></span>\[\begin{equation}
O_t = H_t W_{hq} + b_q
\end{equation}\]</div>
<p>Parameters of the RNN include the weights <span class="math notranslate nohighlight">\(W_{xh} \in R^{d \times h}, W_{hh} \in R^{h \times h}\)</span> , and the bias <span class="math notranslate nohighlight">\(b_h \in R^{1 \times h}\)</span> of the hidden layer, together with the weights <span class="math notranslate nohighlight">\(W_{hq} \in R^{h \times q}\)</span> and the bias <span class="math notranslate nohighlight">\(b_q \in R^{1 \times q}\)</span> of the output layer. It is worth mentioning that even at different time steps, RNNs always use these model parameters. Therefore, the parameterization cost of an RNN does not grow as the number of time steps increases.</p>
<br/>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnn.svg"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnn.svg" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnn.svg" width="700"/></a>
</div>
<div class="section" id="dataset">
<h3>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<p>We will use the IMDB dataset from <insert link="">, which consists of a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. We will use torchtext to download the dataset and prepare it for training, validation and testing. Our goal is to build a model that performs binary classification between positive and negative movie reviews.</insert></p>
<p>We use <code class="docutils literal notranslate"><span class="pre">fix_length</span></code> argument to pad sentences of length less than <code class="docutils literal notranslate"><span class="pre">sentence_length</span></code> or truncate sentences of length greater than <code class="docutils literal notranslate"><span class="pre">sentence_length</span></code>.</p>
<div class="section" id="load-dataset-function">
<h4>Load dataset function<a class="headerlink" href="#load-dataset-function" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Load dataset function</span>

<span class="k">def</span> <span class="nf">download_osf</span><span class="p">():</span>
  <span class="c1"># Download IMDB dataset from OSF</span>
  <span class="kn">import</span> <span class="nn">tarfile</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">os</span>
  <span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/dvse9/download"</span>
  <span class="n">fname</span> <span class="o">=</span> <span class="s2">"aclImdb_v1.tar.gz"</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'Downloading Started...'</span><span class="p">)</span>
  <span class="c1"># Downloading the file by sending the request to the URL</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="c1"># Writing the file to the local file system</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Downloading Completed.'</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="c1"># extracting all the files</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Extracting all the files now...'</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">'.data/imdb'</span><span class="p">)</span>  <span class="c1"># specify which folder to extract to</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Done!'</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">sentence_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">2021</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Dataset Loader</span>

<span class="sd">  Args:</span>
<span class="sd">    sentence_length: int</span>
<span class="sd">      Length of sentence</span>
<span class="sd">    seed: int</span>
<span class="sd">      Set seed for reproducibility</span>
<span class="sd">    batch_size: int</span>
<span class="sd">      Batch size</span>

<span class="sd">  Returns:</span>
<span class="sd">    TEXT: Field instance</span>
<span class="sd">      Text</span>
<span class="sd">    vocab_size: int</span>
<span class="sd">      Specifies size of TEXT</span>
<span class="sd">    train_iter: BucketIterator</span>
<span class="sd">      Training iterator</span>
<span class="sd">    valid_iter: BucketIterator</span>
<span class="sd">      Validation iterator</span>
<span class="sd">    test_iter: BucketIterator</span>
<span class="sd">      Test iterator</span>
<span class="sd">  """</span>
  <span class="n">download_osf</span><span class="p">()</span>
  <span class="n">TEXT</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">sequential</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">tokenize</span><span class="o">=</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">,</span>
                    <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">include_lengths</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">fix_length</span><span class="o">=</span><span class="n">sentence_length</span><span class="p">)</span>
  <span class="n">LABEL</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">LabelField</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>

  <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IMDB</span><span class="o">.</span><span class="n">splits</span><span class="p">(</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">LABEL</span><span class="p">)</span>

  <span class="c1"># If no specific vector embeddings are specified,</span>
  <span class="c1"># Torchtext initializes random vector embeddings</span>
  <span class="c1"># which would get updated during training through backpropagation.</span>
  <span class="n">TEXT</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
  <span class="n">LABEL</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

  <span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">split_ratio</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span>
                                            <span class="n">random_state</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span>
  <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">BucketIterator</span><span class="o">.</span><span class="n">splits</span><span class="p">((</span><span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">),</span>
                                                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sort_key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">),</span>
                                                                  <span class="n">repeat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Data loading is completed. Sentence length: </span><span class="si">{</span><span class="n">sentence_length</span><span class="si">}</span><span class="s2">, "</span>
        <span class="sa">f</span><span class="s2">"Batch size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">, and seed: </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">TEXT</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">test_iter</span>
</pre></div>
</div>
</div>
</div>
<p>The cell below can take 15-30 secs to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TEXT</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Started...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Completed.
Extracting all the files now...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data loading is completed. Sentence length: 50, Batch size: 32, and seed: 2021
</pre></div>
</div>
</div>
</div>
<p>Let’s see what the data looks like. The words in the reviews are tokenized using the NLTK <code class="docutils literal notranslate"><span class="pre">word_tokenize</span></code> function.</p>
</div>
<div class="section" id="explore-dataset">
<h4>Explore Dataset<a class="headerlink" href="#explore-dataset" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Explore Dataset</span>

<span class="k">def</span> <span class="nf">text_from_dict</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">):</span>
  <span class="n">text</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">arr</span><span class="p">:</span>
    <span class="n">text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dictionary</span><span class="p">[</span><span class="n">element</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">text</span>


<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_iter</span><span class="p">):</span>
  <span class="n">text</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span>

  <span class="k">for</span> <span class="n">itr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">30</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Review: '</span><span class="p">,</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_from_dict</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="n">itr</span><span class="p">],</span> <span class="n">TEXT</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Label: '</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="n">itr</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'[0: Negative Review, 1: Positive Review]'</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Review:  if you have trouble dreaming you may give this movie a low rating . but you just have to realize this movie was not made to please everyone , &lt; br / &gt; &lt; br / &gt; just people with a sense of humor. &lt; br / &gt; &lt; br
Label:  1 

Review:  i found 'time at the top ' an entertaining and stimulating experience . the acting , while not generally brilliant , was perfectly acceptable and sometimes very good . as a film obviously aimed at the younger demographic , it is certainly one of the better works in the genre
Label:  1 

Review:  wang bianlian is an old street performer who is known as a 'king of masks ' for his mastery of sichuan change art . liang is a famous opera performer of sichuan art and respects wang as an artist and as a person . liang is worried that a precious
Label:  1 

Review:  i gave this film 2 stars only because dominic monaghan actually put effort through in his acting . everything else about this film is extremely amateur . everything associated with the direction of this film was very poorly executed . not only should the director rethink what she is doing
Label:  0 

Review:  a pretty obvious thriller-by-numbers , in which the only possible twist turns out to be a hiding to nothing . i was watching principally for the english-language performance by isabelle huppert . it was n't great , but then it was a strange role . i would n't be surprised
Label:  0 

[0: Negative Review, 1: Positive Review]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h4>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper Functions</span>
<span class="c1"># @markdown * `train(model, device, train_iter, valid_iter, epochs, learning_rate)`</span>

<span class="c1"># @markdown * `test(model, device, test_iter)`</span>

<span class="c1"># @markdown * `plot_train_val(x, train, val, train_label, val_label, title)`</span>


<span class="c1"># training</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

  <span class="n">train_loss</span><span class="p">,</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">train_acc</span><span class="p">,</span> <span class="n">validation_acc</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># train</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_iter</span><span class="p">):</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span>
      <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
      <span class="n">text</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="c1"># add micro for coding training loop</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
      <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

      <span class="c1"># get accuracy</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_iter</span><span class="p">))</span>
    <span class="n">train_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch: </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s1">,  Training Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">train_iter</span><span class="p">)</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Training Accuracy: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

    <span class="c1"># evaluate on validation data</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="n">correct</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">text</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># get accuracy</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">validation_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">))</span>
    <span class="n">validation_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="p">)</span>

    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">'Validation Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_iter</span><span class="p">)</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Validation Accuracy: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">correct</span><span class="o">/</span><span class="n">total</span><span class="si">:</span><span class="s1"> .2f</span><span class="si">}</span><span class="s1">% </span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">validation_loss</span><span class="p">,</span> <span class="n">validation_acc</span>


<span class="c1"># testing</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">):</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_iter</span><span class="p">):</span>
      <span class="n">text</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span>
      <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
      <span class="n">text</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="k">return</span> <span class="n">acc</span>


<span class="c1"># helpers</span>
<span class="k">def</span> <span class="nf">plot_train_val</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span> <span class="n">val_label</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">train_label</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">val_label</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'lower right'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epoch'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'accuracy'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
  <span class="n">parameters</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">parameters</span>


<span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">):</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-2-1d-cnn">
<h2>Section 1.2: 1D CNN<a class="headerlink" href="#section-1-2-1d-cnn" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-3-time-series">
<h3>Video 3: Time Series<a class="headerlink" href="#video-3-time-series" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "a74adbe2bdc44a6b944309ea578b9f3f"}
</script></div>
</div>
<p>Over the last tutorials, you were introduced to CNNs and used them to work on a range of interesting deep learning applications in vision. You also discussed where else these networks might be useful. Can we apply CNNs to language?</p>
<p>Before we jump into RNNs we will create a CNN model for the text classification task. Let us understand how a one-dimensional convolutional layer works.</p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/conv1d.svg"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/conv1d.svg" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/conv1d.svg" width="700"/></a>
<p>The above figure shows one-dimensional cross-correlation operation. The shaded parts are the first output element as well as the input and kernel array elements used in its calculation: <span class="math notranslate nohighlight">\(0 \cdot 1 + 1 \cdot 2 = 2\)</span>.</p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/conv1d-channel.svg"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/conv1d-channel.svg" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/conv1d-channel.svg" width="700"/></a>
<p>The above figure shows one-dimensional cross-correlation operation with three input channels. The shaded parts are the first output element as well as the input and kernel array elements used in its calculation: <span class="math notranslate nohighlight">\(0 \cdot 1 + 1 \cdot 2 \cdot 1 \cdot 3 + 2 \cdot 4 + 2 \cdot (−1) + 3 \cdot (−3) = 2\)</span>.</p>
<p>Similarly, we have a one-dimensional pooling layer. The max-over-time pooling layer used in CNN actually corresponds to a one-dimensional global maximum pooling layer. Assuming that the input contains multiple channels, and each channel consists of values on different time steps, the output of each channel will be the largest value of all time steps in the channel. Therefore, the input of the max-over-time pooling layer can have different time steps on each channel.</p>
<p>Fitting all the pieces together a 1D CNN architecture looks like the image below.</p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/textcnn.svg"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/textcnn.svg" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/textcnn.svg" width="700"/></a>
<p>In this figure, we have an input sequence of 11 words, each with 6 channels. Our model consists of two Conv1D layers applied to this input: one of kernel size 2 having 4 output channels and one of kernel size 4 having 5 output channels.  The max-over-time pooling is applied to each of the output channels. The max-pooled outputs for each output channel of the Conv1D layers are concatenated to form 1x4 and 1x5 vectors respectively. Finally these outputs are further concatenated to form a vector of 1x9 and this is passed to a fully connected layer of size 2 for binary classification.</p>
<p>The intuition of using a max-pooling over different channels here is to capture the most important features over time in an input sequence.</p>
</div>
<div class="section" id="coding-exercise-1-implement-a-1d-cnn">
<h3>Coding Exercise 1: Implement a 1D CNN<a class="headerlink" href="#coding-exercise-1-implement-a-1d-cnn" title="Permalink to this headline">¶</a></h3>
<p>Now it’s your turn to implement a 1D CNN.</p>
<ul class="simple">
<li><p>Here we will use <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code class="docutils literal notranslate"><span class="pre">nn.Embedding</span></code></a>  layer instead of pretrained word embeddings. This is a design choice. Using <code class="docutils literal notranslate"><span class="pre">nn.Embedding</span></code> layer in the network allows us to train word embeddings specific to the problem at hand. You are given the <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code> which is the size of the dictionary of embeddings, and the <code class="docutils literal notranslate"><span class="pre">embed_size</span></code> which is the size of each embedding vector.</p></li>
<li><p>The 1D CNN should work for any number kernel size and corresponsing number of channels. Both <code class="docutils literal notranslate"><span class="pre">kernel_sizes</span></code> and <code class="docutils literal notranslate"><span class="pre">num_channels</span></code> are lists. Each element of these lists corresponds to the kernel size and output channels of a Conv1D layer.</p></li>
<li><p>Use <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool1d.html">adaptive max pooling</a></p></li>
<li><p>Determine the size of inputs and outputs to the fully-connected layer using the reference example given above.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TextCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">kernel_sizes</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TextCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"TextCNN"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
    <span class="c1"># This for loop adds the Conv1D layers to your network</span>
    <span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">kernel_sizes</span><span class="p">):</span>
      <span class="c1"># Conv1d(in_channels, out_channels, kernel_size)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Concatenating the average-pooled outputs</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">embeddings</span><span class="p">))),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">conv</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">convs</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>


<span class="c1">## Uncomment to test</span>
<span class="c1"># sampleCNN = TextCNN(1000, 300, [1, 2, 3], [10, 20, 30])</span>
<span class="c1"># print(sampleCNN)</span>

<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 1: Implement a 1D CNN'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Sample output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">TextCNN</span><span class="p">(</span>
  <span class="p">(</span><span class="n">embedding</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
  <span class="p">(</span><span class="n">fc</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">pool</span><span class="p">):</span> <span class="n">AdaptiveMaxPool1d</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="p">(</span><span class="n">relu</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">()</span>
  <span class="p">(</span><span class="n">convs</span><span class="p">):</span> <span class="n">ModuleList</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Conv1d</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Conv1d</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Conv1d</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/solutions/W2D5_Tutorial2_Solution_673f6dee.py"><em>Click for solution</em></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model hyperparameters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.00001</span>
<span class="n">embedding_length</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">kernel_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">nums_channels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Initialize model, training and testing</span>
<span class="n">cnn_model</span> <span class="o">=</span> <span class="n">TextCNN</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_length</span><span class="p">,</span> <span class="n">kernel_sizes</span><span class="p">,</span> <span class="n">nums_channels</span><span class="p">)</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">cnn_model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="n">cnn_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">cnn_train_loss</span><span class="p">,</span> <span class="n">cnn_train_acc</span><span class="p">,</span> <span class="n">cnn_validation_loss</span><span class="p">,</span> <span class="n">cnn_validation_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--- Time taken to train = </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">cnn_start_time</span><span class="si">}</span><span class="s2"> seconds ---"</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

<span class="c1"># Plot accuracies</span>
<span class="n">plot_train_val</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span>
               <span class="n">cnn_train_acc</span><span class="p">,</span>
               <span class="n">cnn_validation_acc</span><span class="p">,</span>
               <span class="s1">'training_accuracy'</span><span class="p">,</span>
               <span class="s1">'validation_accuracy'</span><span class="p">,</span>
               <span class="s1">'CNN on IMDB text classification'</span><span class="p">)</span>

<span class="c1"># Number of parameters in model</span>
<span class="n">paramters</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n\n</span><span class="s1">Number of parameters = </span><span class="si">{</span><span class="n">paramters</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<div class="section" id="section-1-3-vanilla-rnn">
<h2>Section 1.3: Vanilla RNN<a class="headerlink" href="#section-1-3-vanilla-rnn" title="Permalink to this headline">¶</a></h2>
<div class="section" id="coding-exercise-2-implement-a-vanilla-rnn">
<h3>Coding Exercise 2: Implement a Vanilla RNN<a class="headerlink" href="#coding-exercise-2-implement-a-vanilla-rnn" title="Permalink to this headline">¶</a></h3>
<p>Now it’s your turn to write a Vanilla RNN using PyTorch.</p>
<ul class="simple">
<li><p>Once again we will use <code class="docutils literal notranslate"><span class="pre">nn.Embedding</span></code>. You are given the <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code> which is the size of the dictionary of embeddings, and the <code class="docutils literal notranslate"><span class="pre">embed_size</span></code> which is the size of each embedding vector.</p></li>
<li><p>Add 2 <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.RNN.html">RNN</a> layers. This would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results.</p></li>
<li><p>Determine the size of inputs and outputs to the fully-connected layer.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">VanillaRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">VanillaRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Vanilla RNN"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_embeddings</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">h_0</span> <span class="o">=</span>  <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">))</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">h_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h_0</span><span class="p">)</span>
    <span class="n">h_n</span> <span class="o">=</span> <span class="n">h_n</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">h_n</span> <span class="o">=</span> <span class="n">h_n</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">h_n</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">h_n</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">h_n</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">h_n</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">logits</span>


<span class="c1">## Uncomment to test</span>
<span class="c1"># sampleRNN = VanillaRNN(10, 50, 1000, 300)</span>
<span class="c1"># print(sampleRNN)</span>

<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 2: Implement a Vanilla RNN'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Sample output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">VanillaRNN</span><span class="p">(</span>
  <span class="p">(</span><span class="n">word_embeddings</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
  <span class="p">(</span><span class="n">fc</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/solutions/W2D5_Tutorial2_Solution_374cc479.py"><em>Click for solution</em></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model hyperparamters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">embedding_length</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Initialize model, training and testing</span>
<span class="n">vanilla_rnn_model</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_length</span><span class="p">)</span>
<span class="n">vanilla_rnn_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">vanilla_rnn_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">vanilla_train_loss</span><span class="p">,</span> <span class="n">vanilla_train_acc</span><span class="p">,</span> <span class="n">vanilla_validation_loss</span><span class="p">,</span> <span class="n">vanilla_validation_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">vanilla_rnn_model</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--- Time taken to train = </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">vanilla_rnn_start_time</span><span class="si">}</span><span class="s2"> seconds ---"</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">vanilla_rnn_model</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

<span class="c1"># Plot accuracy curves</span>
<span class="n">plot_train_val</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">),</span> <span class="n">vanilla_train_acc</span><span class="p">,</span> <span class="n">vanilla_validation_acc</span><span class="p">,</span>
               <span class="s1">'training_accuracy'</span><span class="p">,</span> <span class="s1">'validation_accuracy'</span><span class="p">,</span>
               <span class="s1">'Vanilla RNN on IMDB text classification'</span><span class="p">)</span>

<span class="c1"># Number of model parameters</span>
<span class="n">paramters</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">vanilla_rnn_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n\n</span><span class="s1">Number of parameters = </span><span class="si">{</span><span class="n">paramters</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
</div>
<div class="section" id="section-2-rnn-applications-and-language-models">
<h1>Section 2: RNN applications and Language Models<a class="headerlink" href="#section-2-rnn-applications-and-language-models" title="Permalink to this headline">¶</a></h1>
<p><em>Time estimate: ~40 mins</em></p>
<div class="section" id="important">
<h2><strong>Important!</strong><a class="headerlink" href="#important" title="Permalink to this headline">¶</a></h2>
<p>In this section, you will use your knowledge of recurrent neural networks and build some interesting NLP applications! For the remainder of the tutorial we will be switching from word-level models to character-level models; which means the text will be tokenized at the character level. We do this in the interest of simplifying our task by limiting our vocabulary (which is now a set of characters instead of words).</p>
</div>
<div class="section" id="video-4-rnn-architectures-for-nlp">
<h2>Video 4: RNN Architectures for NLP<a class="headerlink" href="#video-4-rnn-architectures-for-nlp" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "47cbc55ba9754ac4bbbf3681d3c04f22"}
</script></div>
</div>
</div>
<div class="section" id="section-2-1-text-generation-and-language-modelling">
<h2>Section 2.1: Text Generation and Language Modelling<a class="headerlink" href="#section-2-1-text-generation-and-language-modelling" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-5-sequence-modeling">
<h3>Video 5: Sequence Modeling<a class="headerlink" href="#video-5-sequence-modeling" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "a7f405ca85b141fa877aeb44f1d45840"}
</script></div>
</div>
<p>The first application we will discuss in this section is that of text generation using neural language models. In linguistic theory, a language model is a probability distribution over sequences of words. The task for the model is posed as follows: given a history or context of words, can you predict the next word in the sequence?</p>
<p>Recurrent neural networks are a natural choice for this task, since they have the ability to capture information from past observations through the hidden state. Andrej Karpathy’s <a class="reference external" href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">blog post</a> is an excellent read for developing intuition for this task. For this exercise, you will train a character-level text generation model, give it an initial “start” string, and watch how it generates characters!</p>
<p>At any given time step, the model takes one character and a hidden state as input. We convert the output of the model to a probability distribution over the possible characters, and pick a character from this distribution as the next prediction. This “generated” character is then passed to the model as the input in the next time step. This process is repeated for a fixed number of time steps.  (In real generation, these is often a special “stop character” that determines when to stop generation.</p>
<br/>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnnW2D5T2.png"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnnW2D5T2.png" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/rnnW2D5T2.png" style="width: 700px;"/></a>
<p><strong>Note:</strong> Language models are generally evaluated using a metric known as <a class="reference external" href="https://towardsdatascience.com/perplexity-intuition-and-derivation-105dd481c8f3">perplexity</a>, which is 2 to the entropy of the probability distribution of the language model, measured in bits.</p>
<p>References:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html">RNN PyTorch tutorial</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/rnn.html#rnn-based-character-level-language-models">RNN d2l.ai tutorial</a></p></li>
</ul>
<p>Preparing the input (run me)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Preparing the input (run me)</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/f6z3p/download"</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s2">"1522-0.txt"</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"The file '</span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">' has been downloaded."</span><span class="p">)</span>


<span class="c1"># Print a random chunk from the training data</span>
<span class="k">def</span> <span class="nf">random_chunk</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">):</span>
  <span class="n">start_index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">file_len</span> <span class="o">-</span> <span class="n">chunk_len</span><span class="p">)</span>
  <span class="n">end_index</span> <span class="o">=</span> <span class="n">start_index</span> <span class="o">+</span> <span class="n">chunk_len</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">file</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]</span>


<span class="c1"># Turn string into list of longs</span>
<span class="k">def</span> <span class="nf">char_tensor</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
  <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">)):</span>
    <span class="n">tensor</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_characters</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">string</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">tensor</span>


<span class="c1"># Get a random chunk from the traning data,</span>
<span class="c1"># Convert its first n-1 chars into input char tensor</span>
<span class="c1"># Convert its last n-1 chars into target char tensor</span>
<span class="k">def</span> <span class="nf">random_training_set</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">):</span>
  <span class="n">chunk</span> <span class="o">=</span> <span class="n">random_chunk</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">)</span>
  <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">chunk</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">target</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">chunk</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
  <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span>


<span class="c1"># Read the input training file - Julius Caesar</span>
<span class="n">file</span> <span class="o">=</span> <span class="n">unidecode</span><span class="o">.</span><span class="n">unidecode</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s1">'1522-0.txt'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">file</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">'[^a-z]+'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
<span class="n">file_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Length of </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s1"> file is </span><span class="si">{</span><span class="n">file_len</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="n">chunk_len</span> <span class="o">=</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Random chunk: </span><span class="si">{</span><span class="n">random_chunk</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Get all printable characters for generation</span>
<span class="c1"># all_characters = string.printable</span>
<span class="n">all_characters</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span>
<span class="n">all_characters</span> <span class="o">+=</span> <span class="s1">' '</span>
<span class="n">n_characters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_characters</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The file '1522-0.txt' has been downloaded.

Length of 1522-0.txt file is 127899

Random chunk:  was the noblest roman of them all all the conspirators save only he did that they did in envy of gre
</pre></div>
</div>
</div>
</div>
<p><strong>Network</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GenerationRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GenerationRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

  <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-3-implement-text-generation">
<h3>Coding Exercise 3: Implement Text generation<a class="headerlink" href="#coding-exercise-3-implement-text-generation" title="Permalink to this headline">¶</a></h3>
<p>Examine the network example above and write the function below that:</p>
<ul class="simple">
<li><p>Takes in a <code class="docutils literal notranslate"><span class="pre">prime_str</span></code> and builds up a hidden state</p></li>
<li><p>Uses the built up hidden state to iteratively generate <code class="docutils literal notranslate"><span class="pre">predict_len</span></code> number of characters from the model</p></li>
<li><p>To predict the next state, softmax the output from the model and pick the character with the maximum probability</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">all_characters</span><span class="p">,</span> <span class="n">prime_str</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">):</span>
  <span class="n">hidden</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
  <span class="n">predicted</span> <span class="o">=</span> <span class="n">prime_str</span>

  <span class="c1"># "Building up" the hidden state</span>
  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prime_str</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">prime_str</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>

  <span class="c1"># Tensorize of the last character</span>
  <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">prime_str</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="c1"># For every index to predict</span>
  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">predict_len</span><span class="p">):</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Generation"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Pass the inputs to the model</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Pick the character with the highest probability</span>
    <span class="n">top_i</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Add predicted character to string and use as next input</span>
    <span class="n">predicted_char</span> <span class="o">=</span> <span class="n">all_characters</span><span class="p">[</span><span class="n">top_i</span><span class="p">]</span>
    <span class="n">predicted</span> <span class="o">+=</span> <span class="n">predicted_char</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">predicted_char</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">predicted</span>


<span class="c1">## Uncomment to run</span>
<span class="c1"># sampleDecoder = GenerationRNN(27, 100, 27, 1)</span>
<span class="c1"># text = evaluate(sampleDecoder, all_characters, 'hi', 10)</span>
<span class="c1"># if text.startswith('hi') and len(text) == 12:</span>
<span class="c1">#   print('Success!')</span>
<span class="c1"># else:</span>
<span class="c1">#   print('Need to change.')</span>

<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 3: Implement Text generation'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/solutions/W2D5_Tutorial2_Solution_afcb2da5.py"><em>Click for solution</em></a></p>
<p>Run this cell to train the model</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Run this cell to train the model</span>

<span class="k">def</span> <span class="nf">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
  <span class="sd">"""Clip the gradient."""</span>
  <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>

  <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="n">theta</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">[:]</span> <span class="o">*=</span> <span class="n">theta</span> <span class="o">/</span> <span class="n">norm</span>


<span class="c1"># Single training step</span>
<span class="k">def</span> <span class="nf">train_gen</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">chunk_len</span><span class="p">):</span>
  <span class="c1"># Initialize hidden state, zero the gradients of decoder</span>
  <span class="n">hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
  <span class="n">decoder</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="c1"># For each character in our chunk (except last), compute the hidden and ouput</span>
  <span class="c1"># Using each output, compute the loss with the corresponding target</span>
  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">):</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

  <span class="c1"># Backpropagate, clip gradient and optimize</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
  <span class="n">grad_clipping</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="c1"># Return average loss</span>
  <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">chunk_len</span>


<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0005</span>
<span class="n">print_every</span><span class="p">,</span> <span class="n">plot_every</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">10</span>

<span class="c1"># Create model, optimizer and loss function</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">GenerationRNN</span><span class="p">(</span><span class="n">n_characters</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_characters</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For every epoch</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
  <span class="c1"># Get a random (input, target) pair from training set and perform one training iteration</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">train_gen</span><span class="p">(</span><span class="o">*</span><span class="n">random_training_set</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">),</span> <span class="n">chunk_len</span><span class="p">)</span>
  <span class="n">loss_avg</span> <span class="o">+=</span> <span class="n">loss</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="n">all_characters</span><span class="p">,</span> <span class="s1">'th'</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> --------------------</span><span class="se">\n\t</span><span class="s1"> </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_avg</span> <span class="o">/</span> <span class="n">plot_every</span><span class="p">)</span>
    <span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training loss for text generation'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<div class="section" id="section-2-2-sequence-tagging">
<h2>Section 2.2: Sequence Tagging<a class="headerlink" href="#section-2-2-sequence-tagging" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-6-tagging">
<h3>Video 6: Tagging<a class="headerlink" href="#video-6-tagging" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "c624ac75e5b6475dbeb9be1b2a9b77ae"}
</script></div>
</div>
<p>Sequence tagging is a task in machine learning whose goal is to assign a label (or category) to each unit of a sequence processed in a model. In natural language processing, some popular tagging tasks include parts-of-speech tagging and named entity recognition.</p>
<p>Formally, we study tagging as a different task from language modeling or text generation, but there are similarities between them. Instead of choosing the next best character from the output model, we pass the hidden state of each recurrent unit from the model to a fully connected layer and assign it a label.</p>
<p>Build the dataloader (run me!)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Build the dataloader (run me!)</span>
<span class="k">class</span> <span class="nc">TaggingDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
  <span class="s1">'Characterizes a dataset for PyTorch'</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_data</span><span class="p">):</span>
    <span class="s1">'Initialization'</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">raw_data</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vowels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'a'</span><span class="p">,</span> <span class="s1">'e'</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="s1">'o'</span><span class="p">,</span> <span class="s1">'u'</span><span class="p">,</span> <span class="s1">'A'</span><span class="p">,</span> <span class="s1">'E'</span><span class="p">,</span> <span class="s1">'I'</span><span class="p">,</span> <span class="s1">'O'</span><span class="p">,</span> <span class="s1">'U'</span><span class="p">]</span>

  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s1">'Denotes the total number of samples'</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="s1">'Generates one sample of data'</span>
    <span class="c1"># Select sample</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">target</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">1</span><span class="p">:]:</span>
      <span class="k">if</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vowels</span><span class="p">:</span>
        <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">elif</span> <span class="n">c</span> <span class="o">==</span> <span class="s1">' '</span><span class="p">:</span>
        <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># print(self.data[index][:-1], target)</span>
    <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span>


<span class="c1"># Data loaders</span>
<span class="n">raw_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
  <span class="n">raw_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_chunk</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">TaggingDataset</span><span class="p">(</span><span class="n">raw_data</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-4-implement-sequence-labelling">
<h3>Coding Exercise 4: Implement Sequence Labelling<a class="headerlink" href="#coding-exercise-4-implement-sequence-labelling" title="Permalink to this headline">¶</a></h3>
<p>For this exercise, you will train a character-level sequence labeling model on the same dataset as the previous exercise.</p>
<p>The model takes in a character and a hidden state vector as input and predicts whether the <strong>next</strong> character in the sequence will be a vowel (V), space (S), or other (O). Much of the code for this task is identical to the code for text generation, so you will be making the most critical tweaks in the text generation pipeline that will give you a tagging pipeline. Note that the task becomes simpler since we are reducing the prediction space to just three classes.</p>
<p>Structurally, the tagging model looks similar to the text generation one, except the Linear layer must map to the number of tags or labels defined for your task. Functionally, the hidden state (instead of the output) must be mapped to the Linear layer to perform the classification of the required unit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TaggingRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TaggingRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Tagging Init"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># https://pytorch.org/docs/stable/generated/torch.nn.RNN.html</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="o">...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span>

  <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
<span class="c1">## Uncomment to run</span>
<span class="c1"># sampleTagger = TaggingRNN(20, 100, 10, 2)</span>
<span class="c1"># print(sampleTagger)</span>

<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 4: Implement Sequence Labelling'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Sample output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">TaggingRNN</span><span class="p">(</span>
  <span class="p">(</span><span class="n">embedding</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
  <span class="p">(</span><span class="n">linear</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/solutions/W2D5_Tutorial2_Solution_de81767a.py"><em>Click for solution</em></a></p>
</div>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h3>
<p>Here is a function that performs the “Vowel/Space/Other” tagging task for each character of the given string. You don’t need to code anything.</p>
<p><strong>Bonus task:</strong> notice the similarities between it and the evaluation code for the text generation task.</p>
<p>Evaluation function</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Evaluation function</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prime_str</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">):</span>
  <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Vowel'</span><span class="p">,</span> <span class="s1">'Space'</span><span class="p">,</span> <span class="s1">'Other'</span><span class="p">]</span>

  <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
  <span class="n">prime_input</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">prime_str</span><span class="p">)</span>
  <span class="n">build_up</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prime_str</span><span class="p">)</span> <span class="o">-</span> <span class="n">predict_len</span>
  <span class="n">predicted</span> <span class="o">=</span> <span class="n">prime_str</span><span class="p">[:</span><span class="n">build_up</span><span class="p">]</span>

  <span class="c1"># Use priming string to "build up" hidden state</span>
  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">build_up</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">prime_input</span><span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>

  <span class="n">column_width</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="s1">'milan_is_a_nice_place'</span><span class="p">)</span><span class="o">+</span><span class="mi">2</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'Text </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'Next Character is ...</span><span class="se">\n</span><span class="s1">-------------------------'</span><span class="p">)</span>

  <span class="c1"># For each character remaining to be tagged</span>
  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">):</span>
    <span class="c1"># Get it's input tensor</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">prime_input</span><span class="p">[</span><span class="n">build_up</span> <span class="o">+</span> <span class="n">p</span><span class="p">]</span>
    <span class="n">next_char</span> <span class="o">=</span> <span class="n">prime_str</span><span class="p">[</span><span class="n">build_up</span> <span class="o">+</span> <span class="n">p</span><span class="p">]</span>
    <span class="n">predicted</span> <span class="o">+=</span> <span class="n">next_char</span>

    <span class="c1"># Pass the input and the previous hidden state to the model</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>

    <span class="c1"># Softmax the output and find the best tag</span>
    <span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">)</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="n">text</span> <span class="o">=</span> <span class="n">predicted</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">'_'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>Run this cell to train the model!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Run this cell to train the model!</span>

<span class="c1"># Single training step</span>
<span class="k">def</span> <span class="nf">train_simple</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">chunk_len</span><span class="p">):</span>
  <span class="c1"># Initialize hidden state, zero the gradients of decoder</span>
  <span class="n">hidden</span> <span class="o">=</span> <span class="n">tagger</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
  <span class="n">tagger</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># For each character in our chunk (except last), compute the hidden and ouput</span>
  <span class="c1"># Using each output, compute the loss with the corresponding target</span>
  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">):</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">tagger</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

  <span class="c1"># Backpropagate and optimize</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
  <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="c1"># Return average loss</span>
  <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">chunk_len</span>


<span class="c1"># Define the parameters</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.005</span>

<span class="n">print_every</span><span class="p">,</span> <span class="n">plot_every</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span>

<span class="c1"># Create model, optimizer and loss function</span>
<span class="n">tagger</span> <span class="o">=</span> <span class="n">TaggingRNN</span><span class="p">(</span><span class="n">n_characters</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_characters</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">tagger</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For every epoch</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">train_simple</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">chunk_len</span><span class="p">)</span>
    <span class="n">loss_avg</span> <span class="o">+=</span> <span class="n">loss</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">------ Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">evaluate</span><span class="p">(</span><span class="n">tagger</span><span class="p">,</span> <span class="s1">'milan is a nice place'</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_avg</span> <span class="o">/</span> <span class="n">plot_every</span><span class="p">)</span>
    <span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Cross Entropy Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training loss for sequence labelling'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<div class="section" id="section-2-3-sequence-to-sequence">
<h2>Section 2.3: Sequence to Sequence<a class="headerlink" href="#section-2-3-sequence-to-sequence" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-7-seq2seq">
<h3>Video 7: Seq2Seq<a class="headerlink" href="#video-7-seq2seq" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "ddeea2c16d774be0b33164beadb8f70e"}
</script></div>
</div>
<p>Sequence-to-sequence models take in a sequence of items (words, characters, etc) as input and produces another sequence of items as output. The most
simple seq2seq models are composed of two parts: the encoder, the context (“state” in the figure) and the decoder. The encoder and decoder usually consist of recurrent units that we’ve seen before (RNNs, GRUs or LSTMs). A high-level schematic of the architecture is as follows:</p>
<br/>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/encdecW2D5T2.png"><img alt="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/encdecW2D5T2.png" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl//main/tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/static/encdecW2D5T2.png" style="width: 700px;"/></a>
<p>The encoder’s recurrent unit processes the input one item at a time. Once the entire sequence is processed, the final hidden state vector produced is known as a context vector. The size of the context vector is defined while setting up the model, and is equal to the number of hidden states used in the encoder RNN. The encoder then passes the context to the decoder. The decoder’s recurrent unit uses the context to produce the items for the output sequence one by one.</p>
<p>Sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html">d2l.ai on encoders</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-modern/seq2seq.html">d2l.ai on seq2seq</a></p></li>
<li><p><a class="reference external" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Jalammar’s blog</a></p></li>
</ul>
<p>One of the most popular applications of seq2seq models is “machine translation”: the task of taking in a sentence in one language (the source) and producing its translation in another language (the target), with words in both languages being the sequence units. This is a supervised learning task and requires the dataset to have “parallel sentences”, i.e., each sentence in the source language must be labelled with its translation in the target language.</p>
<p><a class="reference external" href="https://i.imgur.com/HJ6t8up.mp4">Here</a> is an intuitive visualization for understanding <strong>seq2seq</strong> models for machine translation from English to French.</p>
<p>Since the vocabulary of an entire language is huge, training such models to give meaningful performance requires significant time and resources. In this section, you will train a seq2seq model to perform machine translation from English to <a class="reference external" href="https://en.wikipedia.org/wiki/Pig_Latin">Pig-Latin</a>. We will modify the task to perform character-level machine translation so that vocabulary size does not grow exponentially.</p>
</div>
<div class="section" id="data-download-and-preprocessing">
<h3>Data download and Preprocessing<a class="headerlink" href="#data-download-and-preprocessing" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Data download and Preprocessing</span>

<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">zipfile</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">io</span>

<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/fkg3y/download"</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s2">"wordlist-en_US-large-2020.12.07.zip"</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Downloading Started...'</span><span class="p">)</span>
<span class="c1"># Downloading the file by sending the request to the URL</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Writing the file to the local file system</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Downloading Completed.'</span><span class="p">)</span>

<span class="c1"># opening the zip file in READ mode</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">zipObj</span><span class="p">:</span>
  <span class="c1"># extracting all the files</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Extracting all the files now...'</span><span class="p">)</span>
  <span class="n">zipObj</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Done!'</span><span class="p">)</span>
  <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">t</span><span class="p">(</span><span class="nb">str</span><span class="p">):</span>
  <span class="k">return</span> <span class="nb">str</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">str</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">pig_latinize</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
  <span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'sh'</span><span class="p">,</span> <span class="s1">'gl'</span><span class="p">,</span> <span class="s1">'ch'</span><span class="p">,</span> <span class="s1">'ph'</span><span class="p">,</span> <span class="s1">'tr'</span><span class="p">,</span> <span class="s1">'br'</span><span class="p">,</span> <span class="s1">'fr'</span><span class="p">,</span> <span class="s1">'bl'</span><span class="p">,</span> <span class="s1">'gr'</span><span class="p">,</span> <span class="s1">'st'</span><span class="p">,</span> <span class="s1">'sl'</span><span class="p">,</span> <span class="s1">'cl'</span><span class="p">,</span> <span class="s1">'pl'</span><span class="p">,</span> <span class="s1">'fl'</span><span class="p">]</span>

  <span class="n">i</span> <span class="o">=</span> <span class="n">word</span>
  <span class="k">if</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'a'</span><span class="p">,</span> <span class="s1">'e'</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="s1">'o'</span><span class="p">,</span> <span class="s1">'u'</span><span class="p">]:</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="s1">'ay'</span>
  <span class="k">elif</span> <span class="n">t</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">lst</span><span class="p">:</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">+</span> <span class="n">i</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="s1">'ay'</span>
  <span class="k">elif</span> <span class="n">i</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">i</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">'ay'</span>
  <span class="k">return</span> <span class="n">word</span>

<span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">'en_US-large.txt'</span><span class="p">):</span>
  <span class="n">word_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">word_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
  <span class="n">clean_wordlist</span> <span class="o">=</span> <span class="p">[</span><span class="n">unidecode</span><span class="o">.</span><span class="n">unidecode</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_list</span> <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">]</span>
  <span class="n">clean_data</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">clean_wordlist</span><span class="p">:</span>
    <span class="n">clean_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">pig_latinize</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">clean_data</span>


<span class="k">def</span> <span class="nf">tokenize_nmt</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""Tokenize the English-French dataset."""</span>
  <span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">source_char_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="n">target_char_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">num_examples</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="n">num_examples</span><span class="p">:</span>
      <span class="k">break</span>
    <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)</span>
    <span class="c1"># parts = line.split('\t')</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">src_txt</span><span class="p">,</span> <span class="n">tgt_txt</span> <span class="o">=</span> <span class="n">parts</span>
      <span class="n">cur_src</span><span class="p">,</span> <span class="n">cur_tgt</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">src_txt</span><span class="p">:</span>
        <span class="n">cur_src</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">source_char_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tgt_txt</span><span class="p">:</span>
        <span class="n">cur_tgt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">target_char_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
      <span class="n">source</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_src</span><span class="p">)</span>
      <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_tgt</span><span class="p">)</span>

  <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">,</span> <span class="s1">'&lt;bos&gt;'</span><span class="p">,</span> <span class="s1">'&lt;pad&gt;'</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">:</span>
    <span class="n">source_char_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
    <span class="n">target_char_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">source_char_set</span><span class="p">)),</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">target_char_set</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Started...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Completed.
Extracting all the files now...
Done!
</pre></div>
</div>
</div>
</div>
<p>The following cell retrieves about 29,000 random English words and the corresponding Pig Latin translations. We then tokenize each word and its translation; in this case, our tokens are characters. We also create vocabularies for the source and target languages; and a two-way mapping for each (index to token and token to index). Finally, we pick the value for <code class="docutils literal notranslate"><span class="pre">NUM_STEPS</span></code> as the size of the largest sequence in either language. This value would mark the maximum size of the sequence accepted by our models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clean_data</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">()</span>

<span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">,</span> <span class="n">target_vocab</span> <span class="o">=</span> <span class="n">tokenize_nmt</span><span class="p">(</span><span class="n">clean_data</span><span class="p">)</span>

<span class="n">source_idx2token</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">char</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_vocab</span><span class="p">))</span>
<span class="n">target_idx2token</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">char</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_vocab</span><span class="p">))</span>
<span class="n">source_vocab</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">char</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_vocab</span><span class="p">))</span>
<span class="n">target_vocab</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">char</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_vocab</span><span class="p">))</span>

<span class="n">NUM_STEPS</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">source</span><span class="p">]),</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">target</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="padding">
<h3>Padding<a class="headerlink" href="#padding" title="Permalink to this headline">¶</a></h3>
<p>The input sequences to our model can vary in length, so it is often convenient to have a consistent length among all inputs to the model (This is not required by recurrent models, but makes it easier to control minibatch size). If our defined maximum sequence length is <span class="math notranslate nohighlight">\(M\)</span> and a given input sequence is less than that, then we pad it with zeros (until its length becomes <span class="math notranslate nohighlight">\(M\)</span>).</p>
<p>Padding function</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Padding function</span>
<span class="k">def</span> <span class="nf">truncate_pad</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">padding_token</span><span class="p">):</span>
  <span class="sd">"""Truncate or pad sequences."""</span>
  <span class="c1"># Truncate</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_steps</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">line</span><span class="p">[:</span><span class="n">num_steps</span><span class="p">]</span>

  <span class="c1"># Pad</span>
  <span class="n">number_of_pad_tokens</span> <span class="o">=</span> <span class="n">num_steps</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
  <span class="n">padding_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">padding_token</span><span class="p">]</span> <span class="o">*</span> <span class="n">number_of_pad_tokens</span>

  <span class="k">return</span> <span class="n">line</span> <span class="o">+</span> <span class="n">padding_list</span>


<span class="c1"># Test the function</span>
<span class="n">word</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'e'</span><span class="p">,</span> <span class="s1">'t'</span><span class="p">,</span> <span class="s1">'u'</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="s1">'s'</span><span class="p">]</span>
<span class="nb">input</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_vocab</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">word</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Input test: '</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
<span class="n">o1</span> <span class="o">=</span> <span class="n">truncate_pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_idx2token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">o1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">o1</span> <span class="o">=</span> <span class="n">truncate_pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_idx2token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">o1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">o1</span> <span class="o">=</span> <span class="n">truncate_pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_idx2token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">o1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input test:  ['e', 't', 'u', 'i', 's']
['e', 't', 'u', 'i', 's', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;']
['e']
['e', 't', 'u', 'i', 's']
</pre></div>
</div>
</div>
</div>
<p>Build the dataloaders</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Build the dataloaders</span>

<span class="k">def</span> <span class="nf">build_array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
  <span class="sd">"""Transform text sequences of machine translation into minibatches."""</span>
  <span class="n">complete_data</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">lines</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
    <span class="n">lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">])</span>
    <span class="n">array</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">truncate_pad</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">]))</span>
    <span class="n">valid_len</span> <span class="o">=</span> <span class="p">(</span><span class="n">array</span> <span class="o">!=</span> <span class="n">vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">complete_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
    <span class="n">lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_len</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">complete_data</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MTDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
  <span class="s1">'Characterizes a dataset for PyTorch'</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="s1">'Initialization'</span>
    <span class="n">source_data</span><span class="p">,</span> <span class="n">source_lens</span> <span class="o">=</span> <span class="n">build_array</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">,</span> <span class="n">NUM_STEPS</span><span class="p">)</span>
    <span class="n">target_data</span><span class="p">,</span> <span class="n">target_lens</span> <span class="o">=</span> <span class="n">build_array</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">target_vocab</span><span class="p">,</span> <span class="n">NUM_STEPS</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">source_data</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">source_len</span> <span class="o">=</span> <span class="n">source_lens</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target_data</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_len</span> <span class="o">=</span> <span class="n">target_lens</span>

  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s1">'Denotes the total number of samples'</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="s1">'Generates one sample of data'</span>
    <span class="c1"># Select sample</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">source_len</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_len</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="encoder-and-decoder-architecture">
<h3>Encoder and Decoder Architecture<a class="headerlink" href="#encoder-and-decoder-architecture" title="Permalink to this headline">¶</a></h3>
<div class="section" id="coding-exercise-5-implement-encoder-and-decoder">
<h4>Coding Exercise 5: Implement Encoder and Decoder<a class="headerlink" href="#coding-exercise-5-implement-encoder-and-decoder" title="Permalink to this headline">¶</a></h4>
<p>Implement the forward functions for the Encoder and Decoder of the seq2seq model as directed.</p>
<p>The Encoder model is very similar to what you have seen so far:</p>
<ul class="simple">
<li><p>Get the embedding of the input <code class="docutils literal notranslate"><span class="pre">X</span></code></p></li>
<li><p>Pass <code class="docutils literal notranslate"><span class="pre">X</span></code> through the recurrent unit. You can define your own initial hidden state or omit it (in which case a tensor of zeros is used).</p></li>
<li><p>There is no linear layer</p></li>
</ul>
<p>You will notice that the Decoder also contains an embedding layer; something that we did not mention during the initial explanation of the seq2seq model, as we want to apply “teacher forcing” to this problem. Teacher forcing is a strategy for training RNNs that uses the model output from a previous time step as an input. Specifically,</p>
<ul class="simple">
<li><p>Get the embedding of <code class="docutils literal notranslate"><span class="pre">X</span></code> (which is output from the previous time step)</p></li>
<li><p>Concatenate it with the previous hidden state</p></li>
<li><p>To the recurrent unit of the Decoder, pass this concatenation as “input”; and pass the previous hidden state as “hidden”</p></li>
<li><p>Pass the output of the recurrent unit through the linear layer</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">"""The RNN encoder for sequence to sequence learning."""</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1"># Embedding layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                      <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="c1"># Hint: always make sure your sizes are correct</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Encoder Forward"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># In RNN models, the first axis corresponds to time steps</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># When state is not mentioned, it defaults to zeros</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)</span>
    <span class="c1"># `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">"""The RNN decoder for sequence to sequence learning."""</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                      <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="c1"># Hint: always make sure your sizes are correct</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Decoder Forward"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># The output `X` shape: (`num_steps`, `batch_size`, `embed_size`)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Broadcast `context` so it has the same `num_steps` as `X`</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Concatenate X and context</span>
    <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Recurrent unit</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="c1"># Linear layer</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># `output` shape: (`batch_size`, `num_steps`, `vocab_size`)</span>
    <span class="c1"># `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)</span>

    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>


<span class="c1">## Uncomment to run</span>
<span class="c1"># encoder = Encoder(1000, 300, 100, 2, 0.1)</span>
<span class="c1"># decoder = Decoder(1000, 300, 100, 2, 0.1)</span>
<span class="c1"># print(encoder)</span>
<span class="c1"># print(decoder)</span>

<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 5: Implement Encoder and Decoder'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Sample output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Encoder</span><span class="p">(</span>
  <span class="p">(</span><span class="n">embedding</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">Decoder</span><span class="p">(</span>
  <span class="p">(</span><span class="n">embedding</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">RNN</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="p">(</span><span class="n">dense</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="n">dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/solutions/W2D5_Tutorial2_Solution_750f0205.py"><em>Click for solution</em></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">"""The base class for the encoder-decoder architecture."""</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EncoderDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_X</span><span class="p">,</span> <span class="n">dec_X</span><span class="p">):</span>
    <span class="n">enc_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">)</span>
    <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Masked Loss Function</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Masked Loss Function</span>
<span class="k">def</span> <span class="nf">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="sd">"""Mask irrelevant entries in sequences."""</span>
  <span class="n">maxlen</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">((</span><span class="n">maxlen</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                      <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;</span> <span class="n">valid_len</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
  <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
  <span class="k">return</span> <span class="n">X</span>


<span class="k">class</span> <span class="nc">MaskedSoftmaxCELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">):</span>
  <span class="sd">"""The softmax cross-entropy loss with masks."""</span>
  <span class="c1"># `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)</span>
  <span class="c1"># `label` shape: (`batch_size`, `num_steps`)</span>
  <span class="c1"># `valid_len` shape: (`batch_size`,)</span>
  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">sequence_mask</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span>
    <span class="n">unweighted_loss</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MaskedSoftmaxCELoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
        <span class="n">pred</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">label</span>
        <span class="p">)</span>
    <span class="n">weighted_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">unweighted_loss</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weighted_loss</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">train_seq2seq(model,</span> <span class="pre">data_loader,</span> <span class="pre">lr,</span> <span class="pre">num_epochs,</span> <span class="pre">tgt_vocab,</span> <span class="pre">device)</span></code></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown `train_seq2seq(model, data_loader, lr, num_epochs, tgt_vocab, device)`</span>

<span class="k">def</span> <span class="nf">train_seq2seq</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
  <span class="sd">"""Train a model for sequence to sequence."""</span>
  <span class="k">def</span> <span class="nf">xavier_init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
      <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">_flat_weights_names</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">"weight"</span> <span class="ow">in</span> <span class="n">param</span><span class="p">:</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>
  <span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">xavier_init_weights</span><span class="p">)</span>
  <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">MaskedSoftmaxCELoss</span><span class="p">()</span>

  <span class="n">dataset</span> <span class="o">=</span> <span class="n">MTDataset</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
  <span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'epoch'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'loss'</span><span class="p">,</span>
                          <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># TODO: without d2l?</span>
    <span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Sum of training loss, no. of tokens</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
      <span class="n">X</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
      <span class="n">bos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">'&lt;bos&gt;'</span><span class="p">]]</span> <span class="o">*</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                          <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

      <span class="n">dec_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">bos</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Teacher forcing</span>
      <span class="n">Y_hat</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>
      <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span><span class="p">)</span>
      <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Make the loss scalar for `backward`</span>

      <span class="n">grad_clipping</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">Y_valid_len</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">num_tokens</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'loss </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> '</span>
        <span class="sa">f</span><span class="s1">'tokens/sec on </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This cell below, takes about 10 minutes to run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span>

<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="n">DEVICE</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">MTDataset</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">target_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<div class="section" id="id1">
<h3>Evaluation<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>How do we know that we have obtained a good translation? BLEU (Bilingual Evaluation Understudy) is a metric that was developed specifically for this purpose. If you’re curious, you can check out the details of the metric <a class="reference external" href="https://d2l.ai/chapter_recurrent-modern/seq2seq.html?highlight=bleu#evaluation-of-predicted-sequences">here</a>. For now, all you need to know is that a BLEU score lies between 0 and 1. The closer you are to 1, the better your translation is.</p>
<p>Compute BLEU</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Compute BLEU</span>
<span class="k">def</span> <span class="nf">bleu</span><span class="p">(</span><span class="n">pred_seq</span><span class="p">,</span> <span class="n">label_seq</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="sd">"""Compute the BLEU."""</span>
  <span class="n">pred_tokens</span><span class="p">,</span> <span class="n">label_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">pred_seq</span><span class="p">],</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">label_seq</span><span class="p">]</span>
  <span class="n">len_pred</span><span class="p">,</span> <span class="n">len_label</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">)</span>
  <span class="n">score</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">len_label</span> <span class="o">/</span> <span class="n">len_pred</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">num_matches</span><span class="p">,</span> <span class="n">label_subs</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_label</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">label_subs</span><span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">len_pred</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">label_subs</span><span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">num_matches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">label_subs</span><span class="p">[</span><span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">n</span><span class="p">])]</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="n">score</span> <span class="o">*=</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">num_matches</span> <span class="o">/</span> <span class="p">(</span><span class="n">len_pred</span> <span class="o">-</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">score</span>
</pre></div>
</div>
</div>
</div>
<p>Implementing a function to make a translation of a given word.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">):</span>
  <span class="sd">"""Predict for sequence to sequence."""</span>
  <span class="c1"># Set `net` to eval mode for inference</span>
  <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="n">src_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_vocab</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">src_sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()]</span> <span class="o">+</span> <span class="p">[</span><span class="n">source_vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">]]</span>
  <span class="c1"># enc_valid_len = torch.tensor([len(src_tokens)], device=device)</span>
  <span class="n">src_tokens</span> <span class="o">=</span> <span class="n">truncate_pad</span><span class="p">(</span><span class="n">src_tokens</span><span class="p">,</span> <span class="n">NUM_STEPS</span><span class="p">,</span> <span class="n">source_vocab</span><span class="p">[</span><span class="s1">'&lt;pad&gt;'</span><span class="p">])</span>
  <span class="c1"># Add the batch axis</span>
  <span class="n">enc_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">src_tokens</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">enc_outputs</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">)</span>
  <span class="n">dec_state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">)</span>
  <span class="c1"># Add the batch axis</span>
  <span class="n">dec_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">target_vocab</span><span class="p">[</span><span class="s1">'&lt;bos&gt;'</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">output_seq</span><span class="p">,</span> <span class="n">attention_weight_seq</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_STEPS</span><span class="p">):</span>
    <span class="n">Y</span><span class="p">,</span> <span class="n">dec_state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)</span>
    <span class="c1"># We use the token with the highest prediction likelihood as the input</span>
    <span class="c1"># of the decoder at the next time step</span>
    <span class="n">dec_X</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">dec_X</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="c1"># Once the end-of-sequence token is predicted, the generation of the</span>
    <span class="c1"># output sequence is complete</span>
    <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="n">target_vocab</span><span class="p">[</span><span class="s1">'&lt;eos&gt;'</span><span class="p">]:</span>
      <span class="k">break</span>
    <span class="n">output_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">output_seq</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'middle'</span><span class="p">,</span> <span class="s1">'funny'</span><span class="p">,</span> <span class="s1">'hour'</span><span class="p">,</span> <span class="s1">'igloo'</span><span class="p">,</span> <span class="s1">'vendor'</span><span class="p">,</span> <span class="s1">'moody'</span><span class="p">]</span>
<span class="n">pig_latin</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'iddlemay'</span><span class="p">,</span> <span class="s1">'unnyfay'</span><span class="p">,</span> <span class="s1">'ourhay'</span><span class="p">,</span> <span class="s1">'iglooway'</span><span class="p">,</span> <span class="s1">'endorvay'</span><span class="p">,</span> <span class="s1">'oodymay'</span><span class="p">]</span>

<span class="n">column_width</span> <span class="o">=</span> <span class="mi">18</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'English'</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'Pig Latin'</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'Translation'</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'BLEU</span><span class="se">\n</span><span class="s1">--------------------------------------------------------------'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">pig</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">pig_latin</span><span class="p">):</span>
  <span class="n">translation</span> <span class="o">=</span> <span class="n">predict_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">)</span>
  <span class="n">translation</span> <span class="o">=</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_idx2token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translation</span><span class="p">])</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">eng</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="n">pig</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="n">translation</span><span class="o">.</span><span class="n">ljust</span><span class="p">(</span><span class="n">column_width</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'</span><span class="si">%.3f</span><span class="s1">'</span> <span class="o">%</span> <span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span> <span class="n">pig</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-8-summary">
<h2>Video 8: Summary<a class="headerlink" href="#video-8-summary" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "9c06417c3bb44bb8bd53c50d45d6e50e"}
</script></div>
</div>
<p>In this tutorial, we went through applications of Recurrent Neural Networks for Natural Language Processing.</p>
<p>We introduced a basic RNN architecture and how it compares with CNNs to demonstrate the advantage of recurrence. The downside of RNNs is that they’re prone to the issue of vanishing gradients while processing long-range dependencies. More complex architectures of RNNs are used in practice to tackle this problem, such as Gated Recurrent Units(GRU) <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html">[PyTorch - nn.GRU()]</a> and Long Short-term Memory (LSTM) <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html">[PyTorch - nn.LSTM()]</a>.</p>
<p>Finally, we explored three applications:</p>
<ul class="simple">
<li><p>Text Generation</p></li>
<li><p>Sequence Tagging</p></li>
<li><p>Language Translation</p></li>
</ul>
</div>
<div class="section" id="airtable-submission-link">
<h2>Airtable Submission Link<a class="headerlink" href="#airtable-submission-link" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Airtable Submission Link</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPydisplay</span>
<span class="n">IPydisplay</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span>
   <span class="sa">f</span><span class="s2">"""</span>
<span class="s2"> &lt;div&gt;</span>
<span class="s2">   &lt;a href= "</span><span class="si">{</span><span class="n">atform</span><span class="o">.</span><span class="n">url</span><span class="p">()</span><span class="si">}</span><span class="s2">" target="_blank"&gt;</span>
<span class="s2">   &lt;img src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1"</span>
<span class="s2"> alt="button link end of day Survey" style="width:410px"&gt;&lt;/a&gt;</span>
<span class="s2">   &lt;/div&gt;"""</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
<a href="https://portal.neuromatchacademy.org/api/redirect/to/b4d16463-cbc0-4a8c-b0b6-1cbaa428ee7c?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzJENV9UMiIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTY1OTAwOTY3Mi43NzExNTM3fSwgeyJldmVudCI6ICJWaWRlbyAxOiBSTk5zIiwgInRzIjogMTY1OTAwOTY3OS43NTE4NDE4fSwgeyJldmVudCI6ICJWaWRlbyAyOiBSTk5zOiBCYXNpYyBBcmNoaXRlY3R1cmVzIiwgInRzIjogMTY1OTAwOTY3OS44MjUzMjJ9LCB7ImV2ZW50IjogIlZpZGVvIDM6IFRpbWUgU2VyaWVzIiwgInRzIjogMTY1OTAwOTc4Ni45MDc2MDg1fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgMTogSW1wbGVtZW50IGEgMUQgQ05OIiwgInRzIjogMTY1OTAwOTc4Ni45MjcyNDk3fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgMjogSW1wbGVtZW50IGEgVmFuaWxsYSBSTk4iLCAidHMiOiAxNjU5MDA5Nzg3LjE0Njg4Mn0sIHsiZXZlbnQiOiAiVmlkZW8gNDogUk5OIEFyY2hpdGVjdHVyZXMgZm9yIE5MUCIsICJ0cyI6IDE2NTkwMDk3ODcuMjQwNjk4M30sIHsiZXZlbnQiOiAiVmlkZW8gNTogU2VxdWVuY2UgTW9kZWxpbmciLCAidHMiOiAxNjU5MDA5Nzg3LjM0NDM3NzN9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSAzOiBJbXBsZW1lbnQgVGV4dCBnZW5lcmF0aW9uIiwgInRzIjogMTY1OTAwOTc4OC4yMzAwNTgyfSwgeyJldmVudCI6ICJWaWRlbyA2OiBUYWdnaW5nIiwgInRzIjogMTY1OTAwOTgwNi4xMjQ3MTk0fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgNDogSW1wbGVtZW50IFNlcXVlbmNlIExhYmVsbGluZyIsICJ0cyI6IDE2NTkwMDk4MDYuMTU0MDE0OH0sIHsiZXZlbnQiOiAiVmlkZW8gNzogc2VxMnNlcSIsICJ0cyI6IDE2NTkwMDk4MDYuMjYxMzg4NX0sIHsiZXZlbnQiOiAiQ29kaW5nIEV4ZXJjaXNlIDU6IEltcGxlbWVudCBFbmNvZGVyIGFuZCBEZWNvZGVyIiwgInRzIjogMTY1OTAwOTgwNy4zOTM2MjF9LCB7ImV2ZW50IjogIlZpZGVvIDg6IFN1bW1hcnkiLCAidHMiOiAxNjU5MDA5ODA5LjQyNTMyOTJ9LCB7ImV2ZW50IjogInVybCBnZW5lcmF0ZWQiLCAidHMiOiAxNjU5MDA5ODA5LjQ0NDU5OTZ9XX0%3D" target="_blank">
<img alt="button link end of day Survey" src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1" style="width:410px"/></a>
</div></div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-1-exploring-input-length-for-rnns">
<h1>Bonus 1: Exploring input length for RNNs<a class="headerlink" href="#bonus-1-exploring-input-length-for-rnns" title="Permalink to this headline">¶</a></h1>
<p>Let’s further explore how do different models perform based on length of the text we use as input. We’ll use the IMDB dataset and the Vanilla RNN model defined in Section 1.</p>
<p>Let’s increase the <code class="docutils literal notranslate"><span class="pre">sentence_length</span></code> to see how RNN performs when long reviews are allowed. We have set the length to 200 words, feel free to experiment with the length!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TEXT</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">TEXT_long</span><span class="p">,</span> <span class="n">vocab_size_long</span><span class="p">,</span> <span class="n">train_iter_long</span><span class="p">,</span> <span class="n">valid_iter_long</span><span class="p">,</span> <span class="n">test_iter_long</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Started...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Completed.
Extracting all the files now...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data loading is completed. Sentence length: 50, Batch size: 32, and seed: 2021
Downloading Started...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading Completed.
Extracting all the files now...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data loading is completed. Sentence length: 200, Batch size: 32, and seed: 2021
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model hyperparamters</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">embedding_length</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Train the Vanilla RNN on the datasets</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Training Vanilla RNN on sentence_length = 50</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="c1"># Initialize model, training and testing</span>
<span class="n">vanilla_rnn_model</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_length</span><span class="p">)</span>
<span class="n">vanilla_rnn_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">vanilla_rnn_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">vanilla_train_loss</span><span class="p">,</span> <span class="n">vanilla_train_acc</span><span class="p">,</span> <span class="n">vanilla_validation_loss</span><span class="p">,</span> <span class="n">vanilla_validation_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">vanilla_rnn_model</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--- Time taken to train = </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">vanilla_rnn_start_time</span><span class="si">}</span><span class="s2"> seconds ---"</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">vanilla_rnn_model</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>
<span class="c1"># Number of model parameters</span>
<span class="n">paramters</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">vanilla_rnn_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of parameters = </span><span class="si">{</span><span class="n">paramters</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Training Vanilla RNN on sentence_length = 200</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="c1"># Initialize model, training, testing</span>
<span class="n">vanilla_rnn_model_long</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size_long</span><span class="p">,</span> <span class="n">embedding_length</span><span class="p">)</span>
<span class="n">vanilla_rnn_model_long</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">vanilla_rnn_start_time_long</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">vanilla_train_loss_long</span><span class="p">,</span> <span class="n">vanilla_train_acc_long</span><span class="p">,</span> <span class="n">vanilla_validation_loss_long</span><span class="p">,</span> <span class="n">vanilla_validation_acc_long</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">vanilla_rnn_model_long</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">train_iter_long</span><span class="p">,</span> <span class="n">valid_iter_long</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"--- Time taken to train = </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">vanilla_rnn_start_time</span><span class="si">}</span><span class="s2"> seconds ---"</span><span class="p">)</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">vanilla_rnn_model_long</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">test_iter_long</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>
<span class="c1"># Number of parameters</span>
<span class="n">paramters</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">vanilla_rnn_model_long</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Number of parameters = </span><span class="si">{</span><span class="n">paramters</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare accuracies of model trained on different sentence lengths</span>

<span class="n">x_ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span> <span class="n">vanilla_train_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train accuracy,len=50'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span> <span class="n">vanilla_train_acc_long</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'train accuracy,len=200'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span> <span class="n">vanilla_validation_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'validation accuracy,len=50'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">,</span> <span class="n">vanilla_validation_acc_long</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'validation accuracy,len=200'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'upper left'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"Training and Validation Accuracy for Sentence Lengths 50 and 200"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-2-improving-text-generation">
<h1>Bonus 2: Improving Text Generation<a class="headerlink" href="#bonus-2-improving-text-generation" title="Permalink to this headline">¶</a></h1>
<p>As seen in Section 2.1, choosing the character with the highest probability at each time step did not fully allow us to explore language variability. For this, we must also let the model “explore” other character choices. One of the ways to do this is to sample from a probability distribution.</p>
<p>Implement the function to generate text again, but we cast the output to a probability distribution this time. Your task is to sample a character from this distribution. Use the PyTorch <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.multinomial.html">multinomial function</a>.</p>
<p><strong>Network</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GenerationRNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">GenerationRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">hidden</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>

  <span class="k">def</span> <span class="nf">init_hidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="bonus-coding-exercise-1-improving-text-generation">
<h2>Bonus Coding Exercise 1: Improving Text Generation<a class="headerlink" href="#bonus-coding-exercise-1-improving-text-generation" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluateMultinomial</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">prime_str</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
  <span class="n">hidden</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
  <span class="n">predicted</span> <span class="o">=</span> <span class="n">prime_str</span>

  <span class="c1"># "Building up" the hidden state</span>
  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prime_str</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">prime_str</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>

  <span class="c1"># Tensorize of the last character</span>
  <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">prime_str</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

  <span class="c1"># For every index to predict</span>
  <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">predict_len</span><span class="p">):</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Generation Improve"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Pass the character + previous hidden state to the model</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Sample from the network as a multinomial distribution</span>
    <span class="n">output_dist</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
    <span class="n">top_i</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Add predicted character to string and use as next input</span>
    <span class="n">predicted_char</span> <span class="o">=</span> <span class="n">all_characters</span><span class="p">[</span><span class="n">top_i</span><span class="p">]</span>
    <span class="n">predicted</span> <span class="o">+=</span> <span class="n">predicted_char</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">char_tensor</span><span class="p">(</span><span class="n">predicted_char</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">predicted</span>


<span class="c1">## Uncomment to run</span>
<span class="c1"># sampleDecoder = GenerationRNN(27, 100, 27, 1)</span>
<span class="c1"># text = evaluateMultinomial(sampleDecoder, 'hi', 10)</span>
<span class="c1"># if text.startswith('hi') and len(text) == 12:</span>
<span class="c1">#   print('Success!')</span>
<span class="c1"># else:</span>
<span class="c1">#   print('Need to change.')</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/solutions/W2D5_Tutorial2_Solution_2af79004.py"><em>Click for solution</em></a></p>
<div class="section" id="execute-cell-to-train-the-model">
<h3>Execute cell to train the model<a class="headerlink" href="#execute-cell-to-train-the-model" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Execute cell to train the model</span>

<span class="k">def</span> <span class="nf">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
  <span class="sd">"""Clip the gradient."""</span>
  <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>

  <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="n">theta</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">[:]</span> <span class="o">*=</span> <span class="n">theta</span> <span class="o">/</span> <span class="n">norm</span>


<span class="c1"># Single training step</span>
<span class="k">def</span> <span class="nf">train_simple2</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">chunk_len</span><span class="p">):</span>
  <span class="c1"># Initialize hidden state, zero the gradients of decoder</span>
  <span class="n">hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_hidden</span><span class="p">()</span>
  <span class="n">decoder</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># For each character in our chunk (except last), compute the hidden and ouput</span>
  <span class="c1"># Using each output, compute the loss with the corresponding target</span>
  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">):</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">inp</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

  <span class="c1"># Backpropagate, clip gradient and optimize</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
  <span class="n">grad_clipping</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="c1"># Return average loss</span>
  <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="n">chunk_len</span>


<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0005</span>
<span class="n">print_every</span><span class="p">,</span> <span class="n">plot_every</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">10</span>

<span class="c1"># Create model, optimizer and loss function</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">GenerationRNN</span><span class="p">(</span><span class="n">n_characters</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_characters</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">)</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For every epoch</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
  <span class="c1"># Get a random (input, target) pair from training set and perform one training iteration</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">train_simple2</span><span class="p">(</span><span class="o">*</span><span class="n">random_training_set</span><span class="p">(</span><span class="n">chunk_len</span><span class="p">),</span> <span class="n">chunk_len</span><span class="p">)</span>
  <span class="n">loss_avg</span> <span class="o">+=</span> <span class="n">loss</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">evaluateMultinomial</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="s1">'th'</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1"> --------------------</span><span class="se">\n\t</span><span class="s1"> </span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">plot_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_avg</span> <span class="o">/</span> <span class="n">plot_every</span><span class="p">)</span>
    <span class="n">loss_avg</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">all_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Epochs'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training loss for text generation'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {"fe5dae7ef2c24842a2d5fb8fed28dd86": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "32ed30287ad8431eb1fde7e905030401": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_fe5dae7ef2c24842a2d5fb8fed28dd86", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f99ae50d9d0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "65ad71ddb0004bc4ab720c8ded038fb3": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f8a588551f824403beeca195785afb0d": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_65ad71ddb0004bc4ab720c8ded038fb3", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=LSMPdQvkXuk\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99ae50de90>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/LSMPdQvkXuk?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "cbf3b1675dcd44d6a32767236e840e28": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5124f46fa8bd4d2aba386feac7b9193a": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_f8a588551f824403beeca195785afb0d", "IPY_MODEL_32ed30287ad8431eb1fde7e905030401"], "layout": "IPY_MODEL_cbf3b1675dcd44d6a32767236e840e28", "selected_index": 0}}, "b3676fa3819c474ab308917db3e437fb": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "21ed9d37753e41bd88057c2326b4e9a5": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_b3676fa3819c474ab308917db3e437fb", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f99ae4c1510>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "834209a5ed2b44e6bdde42a5d216c0b4": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "037e10284ddd425ba25d6dd20d63462b": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_834209a5ed2b44e6bdde42a5d216c0b4", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=T2jzzdSVJI0\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99ae4c10d0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/T2jzzdSVJI0?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "2dfb690b215e4177ae60e709082e0dd2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b680b950cce444c383a1e4bfccda56f9": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_037e10284ddd425ba25d6dd20d63462b", "IPY_MODEL_21ed9d37753e41bd88057c2326b4e9a5"], "layout": "IPY_MODEL_2dfb690b215e4177ae60e709082e0dd2", "selected_index": 0}}, "c9fad5d9c99f47968058dfd0726f49d6": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "aab1cbd63cc64823841a672dd479d12e": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_c9fad5d9c99f47968058dfd0726f49d6", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f99ae45ce10>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "46eea17e47a043d886be145ff529b667": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9911de048fad435985e44199d0a78b58": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_46eea17e47a043d886be145ff529b667", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=JAjuG0o4_Xc\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99ae54ca50>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/JAjuG0o4_Xc?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "17052f79b5c841e18286af44a0fbb70d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a74adbe2bdc44a6b944309ea578b9f3f": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_9911de048fad435985e44199d0a78b58", "IPY_MODEL_aab1cbd63cc64823841a672dd479d12e"], "layout": "IPY_MODEL_17052f79b5c841e18286af44a0fbb70d", "selected_index": 0}}, "fc4547759ea84464977ffeffe0a34664": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "824a25340ba4438d9e4492555ba5b9ad": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_fc4547759ea84464977ffeffe0a34664", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f9aaaa15cd0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "78fe8c954975473a8974f1a6cb3138e7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "94c4734944f7405aa1fa1934aa46507c": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_78fe8c954975473a8974f1a6cb3138e7", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=R3Dg7wBQQoU\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99ae4cb110>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/R3Dg7wBQQoU?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "4aec89b255b0441aa00e20e72d2e3d93": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "47cbc55ba9754ac4bbbf3681d3c04f22": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_94c4734944f7405aa1fa1934aa46507c", "IPY_MODEL_824a25340ba4438d9e4492555ba5b9ad"], "layout": "IPY_MODEL_4aec89b255b0441aa00e20e72d2e3d93", "selected_index": 0}}, "bb91eb6af2c24aa4ae0f4d972e0cd81c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "cc103ba603ba491fa735c5b8b6e5dc39": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_bb91eb6af2c24aa4ae0f4d972e0cd81c", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f99a03713d0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "1950578a380c426ba853570e547ec29a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "59a3438980b8439a81f292466a5c37c8": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_1950578a380c426ba853570e547ec29a", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=wYuvMGQdpI4\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99aec6bbd0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/wYuvMGQdpI4?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhwZGBoeHRsfIi0lIyIiJDglKCgmMjc9MC8wMS01SFBCNT9LOTctRGFFS1NWW11bMkFlbWRYbFBZW1cBERISGRYZLxsbLVc3ODdXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXZFdXV1dXV1dXV1dXV1dXV1dXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAgMBAQAAAAAAAAAAAAAAAwQBBQYCB//EAEoQAAIBAgMDBwkFBQcCBgMAAAABAgMRBBIhEzFRBRdBUlOS0RQiM2FxcpGx0gYyQoGhFlRiorIjNHOCk5TBFUMHRGN0s8IkNfD/xAAZAQEBAQEBAQAAAAAAAAAAAAAAAQIDBAX/xAAeEQEBAAIDAQEBAQAAAAAAAAAAAQIRAxIxQSETBP/aAAwDAQACEQMRAD8A+fgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6ql/4f42UYyUqNpJNee+n8j1zeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwHN5jutQ778AOTB1nN5jutQ778BzeY7rUO+/ADkwdZzeY7rUO+/Ac3mO61DvvwA5MHWc3mO61DvvwMP/AMPcclfNQ778AOUBs1yFVf4ofF+Bn/oNXrQ+L8ANWDbL7PVn+Kn8X4HuP2Zrv8VP4vwA0wN9D7J4h7p0vjLwJo/YnFP8dHvS+kJtzYOn/YXF9pQ70vpPMvsRil+Oj3pfSDbmgdE/sZievR70vpMfsdievR70vpCueB0P7HYnr0e9L6TEvshiF+Oj8ZfSB9YwXoaXuR+ROQYL0NL3I/InAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAean3X7GejzP7r9gHzmktES5D3CG72EmUzR5pRsTxRimiWMQJ8PE2dKOhQw61NjTNRNPdiKoiKtyhCEnHe1vIY8oRbsybb/ndbe5RPDR58upOagpNyk7LzXb42sTNETWkTRDXWhYaIq0fNYHQ4L0NL3I/InIMF6Gl7kfkTmkanGY2tLFLC0JUqclTVRyqRc8121aMU1e1tXfpRbw9WrCnOWLdKOS7zxbUXFK+ZqX3enS73FLlieGlNU8Xh5Sja8amzc436UpRu4vdwNYsNVnhaypbaVCNenOkqibqOnFxlNJT1aum0pb7AdDheUaNaTjCd5WvZpxbXFKSV160Q1OWsNFzUq0VkvmdnlTW9ZrWv6r3KmGy169KW3rzdO8lejkirrLaTyrj931eo1tTERo8k1sLOE1WhRqRktnJpys255rZbP7179PHQDqI4iDns1JZ8qnb+FuyfxTPEsbSUJzc4qEG4yk9EmtGjWVK6oY1VKinknhoxUowlNZoyba81Ozs17SlUo1JUHUUKkVDGyqyjkvPJraSi73s2pW9XEDf4XH0qzahK8o6uLTjJJ7nlkk7esgp8t4aTgo1k9pZRaTytvcs1rJ+reVsGo1cRGoq1WpKnCSvKlkjaVrpvKrvRO3qKscPNcj4aGSWdeTXjbVWqQb09WtwNxi+U6NGShUnaTV8qTk1Hi0k7L1vQzV5RowhCbqJqprDLebkt94qN29OBrqeIWFxOKdaM0qsozhOMJTTioKOXzU7NNPT+LTpI8W5RxUK7dWlSnQUE1TUnCV3JxkrNxumu7r0AbrDYmFWCnTkpRd1dcVo0+D9RVjjrYmvTm4xp0qVOpmelsznmu91kor9TzyRSitrUjOpPazu3OGS7SUbpWWlktemxUxm2hXx06MG5+TUsnm3TknUukulq609gGww3KdCrPJCd5NZkmnG64xulmXrRTwfL9JwbrzjCSqVIuyeWKjOUY5nqo3SW9or0/OxOEcKtatFOeaU4Wy3g97UVa/D5EeDxkKWFq0qlKq5yqV7Q2UntFKpK1na2vrf6AbzFY2nRUdpKzl91JOUpcbRV2yrjeU0sOq1CUZp1acO9UjCSa3pq7/M1ccNVw88PKrUqRSwsKLnCG0y1I6yvo2lLTX+HXoPeIw98PUqU5VajqYihJ5qeS+WcE5KNlpZb/UBtvLlCVd1Z0406Tjqr3SaT87o3vo6DOH5ToVKmzhUTna6Vmsy4xb0kvWrmo5ToSlHlFKEnmlSt5rebzY3txNljqbeLwjSbSdS7S0V4dL6APVTlrDQlOMq0U4aSeuWLXQ5br+q9y7CSkk1qmrr2HMeUKjybXwtSnU20adVSWzbjK+Z589stnvvf1bzosH6Gn7kfkBOAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeZ7n7D0eZ7n7AOHit3sPeUxBbvYe7GKRmmiSKMQRJBalFmgiXGSaoVHFtNRdmtGiOmSYqTVGbik2lez3aav9Ck9cpHFyjVamk4t23a39r3ktXESVVqL0WltLeJFNU9pGWik3v/UsxpUZVHNpOSd77zOL2WXTY4KV7J9EkbRxNDRm9rGSXmqcV8WdAzpp5M/yonEirLzWTyIqv3X7BYzK3eC9DS9yPyJyDBehpe5H5E5FYBkACHF4aNalUpTvlqRcZW32as7EwA8xVklwPQAGDIAAwZAAwZAAAADBkAAABra/I8amaM61d0pNuVJzWV3d2r2zW9Wa3RuNikZAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8z3P2Ho8z+6/YBxUOj2EhFB7iVGLFe4IkiVcbidhRnVavkV7br9BzVT7YVfw0oL2tvwNaHaqdkc1R+17q1VT2K2c2o6ytJX0bb6enTQ09T7V4qW5wj7I+NyDA8l1m1NvZJWabXnabrR8TUjGWUxm7Wwx02pShlvLpXTvJsHipRSUouMW+kixcE5qU5Sd1rJ738CWCg15rb6NeBiR6O25G+hX8nwtWsoxc0nJX4L/wDmaTkbl+tVxfnydp71mbircIt2Rfm82HcG3aUcn5PQ0+D5JnRrwmpKUenoeuh1xxtm483JyY4Zdcrqu6jO55qbmQUZ3SZLJlG9wXoaXuR+ROQYL0NL3I/InObYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB5nufsPR5nufsA4eD0RYiRRwGI0/sandZ6q0q8N2HrTfBQfzLpFH7UStganrcV+qf/AAcGjs+W8NjsRR2awdRLMnpFt6XNPg/s3jdrDNhaySkm/MfRqDyNjyfyfTowi8qdW13J62fq4FiTuWHyViewq91nj/pOKf8A2KndZ6p1kfHznJnd3ajWopnuhh8jXB7y6+SMR2FTusx/0nE9hU7rOWXHjbvb18P+jk451uOypUVlFfmeM1kSx5KxK/7FTuszU5LxOXShU7rOuHXGa283NeTlz7WLXJ9fNBp74v8AQvqWhrOT8DiYVHmoVUno/NZtI4Wr2c+6zllqV7+C24avx0OC9DS9yPyJyDBehpe5H5E5xegAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYBkAAAAAAAAAAAAMS3MyYluYEOC9DS9yPyJyDBehpe5H5E4AAAACtjMXstmlCU3UnkSTS1yuWt3wiwLIKXllT93n34eI8sqfu8+/DxJuJtdBQjja2t8NJa6WqRenr10PXllX93l34eI3Da6DX1OUZwWaWHmo3SbzRdru3H1mwLtQAAAa+lylOcVKOHm4vc80Vp8T15bU/d59+HiTcTa8ChLG1tLYaT11vUitPVrqZ8tqfu8+/DxG4bXgUfLan7vPvw8SbB4raqXmODjLK02nrZPo9qG1WAAUAU62OcarpRpSm1CM200laTklvf8ACzHllT93n34eJNw2ugovGVejDy78fExHG1rLNhpJ9NqkWr+26G4m18FHyyr+7y78PE9UsbJ1IwnRlDMnZuUWtPYxuKuAAoAAAAAAAAAp1cbJVJQjSlPKk21KKWvtfqMeWVP3effh4k3Da6CjLG1bO2Gk30XnFK/tuFjattcNK/vx8RuJteBR8tq/u8+/DxPVDGuVVU5UpQbi5Jtpq0Wk9z/iQ3FXAAUAAAAAAAAAAAAAAAAAAAMS3MyYluYEOC9DS9yPyJyDBehpe5H5E4AAADX8p+kwv+O//iqGwNfyn6TC/wCO/wD4qhL4VZMNpK70SMmq+0c5vD7Cl6TESVFO18ql96T9Sjc4RzRch8sVMRUnGrCMFKO1oWveVFycU3fp0T/zI3RzWLoYnDyw+IqSounQag1ShKL2U7Re9vRea/yOlNZFVOUvQv2x/qRsjV8rwzYecbtZsqvF2avJap9DIP2cX77jv9w/A3h41i3ZBQxlKpKcYTjKVN5ZxT1i/WjV/s4v33Hf7h+BpsB9i6kcdPEzxNWMVO8LTvUmv4p8Hw+Rtp0XJf8Ad6Xulsqcl/3el7paPPfXOtNy1yxUw9WEacIyjCO0rt3vGlmUbxt0/ef+Vm5TOawmGxOJ8orwlRjTxLcctWnKUtlG8I7pKyau/wDMbL7PVJ+TqlVvtKEnRk+OX7sl7Y2Zqz8K2ZDyb96v/jf/AFiTGnhyOq9bET8pxVP+1tlpVXCP3I9BcPVxdAQVsZSpzhTnOMZ1L5E3bNa10vXqjV/s2v33H/7h+BpuXvsXUxE6MaeJrSgs2eVeo6mXdbLHi9fgdW3R/wDnav8AgUv6qpaNVyXgvJ606W0qVctCl51R5pPzqvTw9RtTjn6xl6p8rYx4fDzqRWaasoR605PLFfFo8cj42Vek3VUY1qc5U6kY7lOL6L9DVmvaUuV41a+Lo0aLititvKU4uUM33YKya1+8/wAkecDCvQx0lXcJLFQzXpxcYqpTstU29XF/yjX4nxvivU/vFH/P8iwUOUcNtp0qeepTvm86nLJJWs9GMfSetsDR/s2v33H/AO4fgP2bX77j/wDcPwOzo3gNH+za/fcf/uH4D9m1++4//cPwA3gNH+za/fcf/uH4D9m1++4//cPwA3hBLGUlVVFziqrjmUG7Nrddcdxq/wBm1++4/wD3D8DS8q/YmpXxVOUcTV2UYq9SrN1JqV3pHgB00P7xW9kPkycp4KhsqlSnnnPLGms03mk9Hq30sunHL1zy9UeV8bKhRvTSdWco06aluc5OyvboWrfqRnkjGOvh4VJJKprGpFblUi8sl8UzXcoRr18dCNBwisNHO3Ui5RdSeiVk1qo3e/8AEZ5JhWoYytSruEtuttGVOLjDMvNmtW9fuv4jX4vxvSt/5yn/AINT+qmWTV8pYF4jEUYqtWo2p1HmpSyt6wVno9Bh6mPrdg0S+z9VbuUcZ+coy+aC5ExK3cpYj84wf/B2dG5r1404SqVJKMIq8m9yXEUK8KsVOnOM4vdKLun+aOX5d5Ixqwlb/wDPq1Vkf9nsY3n0W01+Bzf2f+y3KkZKpTk8KnvcpWbXrgt/sYH1AFbAUqsKajXqqrNb5qGS/wCV2V+WW4QhiIt/2Es0kumm9J3XTZPN7YoDYg13IzdSE8Q2/wC3lmguhU1pC3tSzf5iPF4OrKpKUYXT3PyyrT6OpFWX5AbDEVlTg5OMpW6IRcn8EVMLyxTqyahCto5Jt0pRinHem2tNxdpJqMU9Gkuly/V6v2s1nJPosT/j1vmwPdDlyjPZu1WMatsk505RhJy+75zVtejiWMXyjSo1KVOpK0qrtDS+ui14atL2tHOYKFV0OT6eIqw8lqQpNOFPK9pFRlTpzk5PR23pK7VtLkmIVTFTxc44epUjJbGjUjKCUdm7uSzSTvtOn+BAdHTxUJVZ0k3npqLkmuiV7Ncdz+BXxHK9Gm5qTk3TlCEssXLz5/dirb3u+KNVU5RUY4blKSyrK6OJXV9vu1Fb/OyHG0HS5PpTqy2VSriqVarN28yUqierenmqy10tEDdvlamqdSpKFWEKcXKTnTlHRcL7y+czyhiITwGMy46OK/sJaRdN5dHr5n/JvMNylh60nGjXpVJJXahOMnbjZMC0YluZkxLcwIcF6Gl7kfkTkGC9DS9yPyJwAAAGv5Vunh5qMpKFa8ssXJpbOcb2Wu9r4mwMAa7y+PZ1/wDRn4Dy+PZ1/wDRn4GxI8S5qnLZJOpZ5VJ2Wbou+BjpGesUKfKlOTkoxrNxeWVqM9HZOz04NfE9eXx7Ov8A6M/A5r7F4LG0sViXVlCcHUca3na7VJSzJW/it0foduOkOsafGYnaU8kada7lHfSml95Pe0bcA1JpZNMgGCq1GCxOzpQhKnWzRVnalN/qkTeXx7Ov/oz8DZAx0jPWNXPlSnFxUo1k5O0b0p6uzdlpwT+B68vj2df/AEZ+BzX2ywWNrYzDOlKEIKajR87XaWzOUlbT7tund6zssO5unF1ElOyzKLulLps+A6Q6xS8vj2df/Rn4Hvku720nGUVKq2s0XF2yxW5670y9YFmMiyaZABpWrr1NnipycKjjKlTScISmrqU215qdt6+J68vj2df/AEZ+BsgZuMqWNa+UI9St/oz8DzS5UpzipRjWlGSTTVGbTT1TWhH9qaOIqYOpTw2VSkmpyk7Whvlb1vd+bKf2GpYiGBhGvldNpSotSu8ktcrXRb/n1E6ROrZeXx7Ov/oz8DFOttK9JxhUSipXcqcoLVcWjZgswkNAANNAAAAAAAANZVrbOvUcoVGpKFnGnKS0TvqkZ8vj2df/AEZ+BsTJm4ypprKnKUIxcpQrKMU226M7JLe9xlcowauoVmn/AOjPwKH23pYieBqRoZVFRcqrbs8kVdpe3/j1k32Ro4ingqdPE5XlS2bi7/2bV0n61u+BOkTrFny+PZ1/9GfgYoVNpioSUKijGlNNyhKCu5QstUuD+BsgWYyLIyADSgAAFbH4R16bp7SUIy0lltdx3ON3uvxWpZAFPEwaqYfI5RgpNOMVdWyu19NF8C2ZAAwkZAGMqta2gStuMgDzlVrWVjMopqzV/aZAHlU4rdFK/qEYJbkl7EegAMS3MyYluYEOC9DS9yPyJyDBehpe5H5E4AAAAAAAPNSainKTUYre27JfmBqOQPS4/wD90/6IG5Oe+zmPoTrYyMa1OUp4lyilNNyjkirrirpnQgAAAAAAAAablz0+A/8Ac/8A0mbk577Q4+jDEYJTrU4uFe8k5pOKySV3wV2jf06kZRUotSi9zTun+YHoAAAAAAAEGN9DU9yXyKn2b/8A1+F/wYf0om5VxNOlQqOpUhBOEknKSjd23alP7LYqnUwOHjCpCUoUoKSjJNxaS0aW4DcAAAAAAAAAAAAAAAA132h/uGL/AMCp/Syxyd/d6P8Ahw+SKX2nxNOGBxKnOMXKjNRUpJOTcXZK+9k/I2Kp1cPS2dSE8sIp5ZKVnbc7bgL4AAAAAV4YnMlKNObTV09N3xLBXwPoKXuR+QV6277Of6eI277Of6eJMAIdu+zn+niNu+zn+niTEUcRCTSU4ttySSau3F2l8Ho+AGNu+zn+niNu+zn+niSt2V3okealSMIuU2oxim227JJb22B4277Of6eI277Of6eJKeY1Iyckmm4u0knudk7P8mn+YHjbvs5/p4jbvs5/p4kp5VSLk4ppyjZtX1V91/gwPG3fZz/TxG3fZz/TxJgBDt32c/08T1CopRurreteK0f6nsgw3o5e9U/qYGcF6Gl7kfkTkGC9DS9yPyJwgAAAAAwcrWrKuni6yc6a86lTSzKMFunl6ZNa36FovX1Mo3TXFWOUwWeOFVKnl21KKpNS3KcfNu/V+JcU1xN4esZ38S7WhiG6do1YqKk3a8VfWOvG2vw9RsORsRKM5YacnK0c9KUneThezi30uLtrwkvWafCcmzoRlTpyzU24yu9JZrrOtOiS+F7bt1/kek5YpSvfYUXCTvdZ5uLtfpaUU/8AMjWXn6xh7+OhABydgAADT8tYmTnHDU5OOaLnUlF2kobkk+hyd9eCfTZm4NDypHJjYze6rSVNPozQcpW9rUm/8rLPUy8UY4mhQU4RjkcGlkUdZOX3Wl+K7vr6nc9yfkjeIpLLFa1oL7sofilZfiS1v02t7K+IwFSdbyhOKnSdqMXucfxZnbRy3eqy9ZLygpbOtFLWqlTpq97zkstrdHgmzt8cJ66syeaccsVHgkj0cHoAAAKvKWM2FCdW2ZpWjHdmk3aK/NtItGt+0FJywsnFNunKFSy1bUJKbSXGyYGnyxpTjUrvPWqPK6rWik90V1I9CX/L1yo0sQtpC6lFtQqx0krdMX0r9H60Yx1DymnGEZRdGprOSd24b0o+3TXgYo4erGnTpys9nKynF5bwVst1uvbR/nxO+vjz7+/W95Ixkq1H+0ttYScJ23Zl0rgmmnb1l41H2djenVrfhrVXKPrioxgn7HluvU0bc413ngACKAEdRyvHKk03513ays9Vx1sresCQEFOdRuOaEUmpZrSvZ3WVLTW6v7LdJOAAAApcrYx0KDnBJ1G1CCe7PJ2V/Ut79SZdNV9oVahGpa6pVI1Je4tJP8k2/wAgVqYqnRnHaNyq1Lp1p75SWtm+jpst2hmEIV1GvTvCf/bqpWlbofri+D3oxyngvKYxpSaVB6zafnSt91Lhrrf1W6STDRqRUXWlHzYtSadouz0lbo0+B318eff1u+SsY69CM5JKesZpblOLyyt6rrT1Fw1n2fi/J9o1bazlUiv4W/N+Ks/zNmcHoAAANVi60qfJ6nGeRqnDztNN2uuhtSlDDqrhYU22k4Q1W/Sz/wCANVyjip0ViFRrymlhZ1btqTpzVsjT/ivLTd5mhYxUqka9OhnqSi6cp3zqEpyvrrpuVtFbf6jaww1OKko04RUneSUUk299+JmvQhUjlqQjOO+0kpK/sYGmpVqs50KVatlTp1JZoSSdRxklG81pfK7tK136kVsBiJwhB03tHmxslu89qo3Hdx9XE6Grh6c4qM4RlFWspRTStu0Z7VOK3JK1+jjvA53HqMuTq0vK51JTwtSds0bStG7ajbRLdZdbXUv8qpLk2vaTklh5+c3dvzX0mwhhqcXKUacE5/eaik5e3iZhRhGGSMIqFrZUko24WA0XKeMqJ4idOUo7BxWs0lmtGVlC3nJppNt332POImoy5RqLESpSpzUopNWT2NOzcfxXatb1aam9nhqcpZ5U4OVrZnFN24X4GZ4anKSlKnByTum4ptPddPjawGkq4qtOrWTlKm6cYOKU4wUU4qTm1Les2aOunme0u8nuTxNZzSU9nRzJO6vaV7eovVcNTm05whJx1i5RTa9l9xIoq7dld72BkAACvhvRy96p/UywV8N6OXvVP6mFZwXoaXuR+ROQYL0NL3I/InCAAAAAAa7HckqrPa05ulVtZySupJblKL3+3R+s2IA0i5IxL0niYRjxp0rS/JylJL4G0weEhQgqdNWitd92297berb4snBbbUkkAARQAACDF4WFam6dSOaL/JprVNNapriicAaSXI+IjpDEwcf/AFaWaXxjKKfwLWB5JVOe1qTdWqtE2rRinvyxW72u79ZsQXdTrAAEUAAAAAaetyI4tvDVdkpO7pyjnp36XFXTj7E7eo8x5DnU0xNZTh0wpw2cZeqTbba9Sa9ZugXdTrPWIxSSSVktEkZAIoAAAAAAAAAABhoyANNPkOUP7tVVOHZzhnhH3bNNL1Xa4WFPkOU2vKaqqRX/AG4RyQfvXbcvZe3FM3ILup1jBkAigAAGuniXRwcKqSajGm5X6IaZ3+Ubv8jYlXC01PDQjJXjKmk1xTVmBQfLE71YqC9JGFF6+deezk2v4ZKT0/DYhhXrOrRVOahF4mvGSeaeZRz9Llpu3bk7W0VjZw5Lox2DUNcOmqWr81NZX7dOIlybSeXSSy1JVE1Jp5pXzfk7vQDW4DE14Qpybg6UsRUpuLTc9ak0nmvbR20tu6S/yriqlKMHTjo5WnPI6mSNnrki03rZabr3Jo4GmoqCTyxm6i1f3nJyv8WzOJwkajTcpxcU0nCbjo997PXd+QFKGNrVZRpUZUc2zVSVWzlDLJtQyxTV75ZPfpbpuU6mIqYt4aneEU51XVi4uSkqMnB21XmuTi7ez1p7OfJNFqKipwyQ2adOcoPJwbT1+a14ktLA0oOOSCjkhs4pblDR2S/JfADUcm4rEbOhFTpzlXdScW4u0aK1Vlm1tenZXWj/ADJMNyniH5PKoqWSrOcGoxd7RU3tE76J5V5tn95amwwvJtKjkyKX9nB04Xk5ZYOzsr+7H4HqjgKUFSUY6UoOEFdu0XZfnuWr9fEChTx+JcaFRqko4icVGm088Yvzm3K9m8iellZ9LtriPLMs9eElH/8AGzTrTW7Z6uOVX+80mnwcX6i1R5GowyZc/wDZ32adSTULpx81N6aNpcDGK5HpzoypwWRujOlFpvRTWt+Out3rv4sChQhXdWmlOKq7KVaq53lGM6jSglFNXSUZxWq3X3m15LxLrYalVkknUgpabtVfS56hhI+dKS8+pCMJtN7leyXD70vieKEnGq6MFFU6dKNlfW7bSXstH9QI8JNvF4mP4VGl32pX/TJ8SxhvRy96p/UzzgMK6UHmalUnJzqSW5yfD1JJJepI9Yb0cveqf1MKzgvQ0vcj8icgwXoaXuR+ROEAAAAAAAAYzK9r677eoyVJ/wB6h/hT/qiWwAAAAAAYIsXn2ctn99K8fW1rb8935mvhjZzlHLLza8k6TtuhF+f8Yq694DbGDV4XE1JTjeau5tSg5Lcr6KNr3W/eYoTqShRbqze1pyvu32umtANqZKnJTTw1K0syyR1vfo3aFsAAAABhq6te3rAGTS4OranQg6zhBwd5XSedW8y9tLJt236e02OAqynSjKTu9bS3ZoptRl+as/zAsgAAAAAAAAjdeCdnKKaaVr63e5fmIV4SaUZxbd2knfc7P4PQCQAAACrj6rhT0bTclFO6VrvpbTsvyAtA1NGvUk4w2jttZRbTTbShmte3HptcQxErwjOs4RzVVn0Tk4StFNtW3Xfrt7QNrGSeqd16jJT5Kd6Cd7+dPXj5z1LgAAACtTw84xUVU0ikl5q3IsgCHZ1O0/lQ2dTtP5UTACHZ1O0/lQ2dTtP5UTACHZ1O0/lQ2dTtP5UTACHZ1O0/lQ2dTtP5UTACHZ1O0/lQ2dTtP5UTACHZ1O0/lRjZT7Rd1E4Ah2dTtP5UZp08kGr33u/rbb/5JTEtzAhwXoaXuR+ROQYL0NL3I/InAAAAAAAAAxYyAAAAAAAYFjIAxZXvbUWMgDCVtxkAAAAAAA85VwRkyAAAAAAAAAMWCR4r1VCEpvdGLk/YlcgnylTTt5+9LSEtG5KKvppq1+WoFsFaOPpO1pXvayUXd31TWm7R67tGKmMhF66LR3eiW99PBRbAsmGiu8dT4u7V7OLT6Ur3Wl2mlff0GJY+mutfTTK768OPRuvvAspBpcCB4ymlB5tJq8Wk3dcdNy1Wr4kX/VKW95klveV2WilvXRZ71oBcMlepjacbat3bXmpyd1dPRa700JYyCSd7qUc0Wtbr1Javf0ICwCrLH01q5ebZNSWqs9ejgrNvg0ZeOpJtZtU7aJu7vZ2svOs9Ha9gLIK9PGQk8qbveS1i/wALs3u3esilyila8JrNHNHd527RK998ktbAXQUKnKsIaShNPW97K1pRhZu9vxJ+wmeMWSEknLO7RUWnd2b33tuTe/oAsgo0OVKdSoqcVK8oqSvZaNZr2ve3Re1r6byV42CSk7pZpRu+hwun/SwLIKvl9LS0m7u256a5fOv93VPfwfAeX0rXzcXud7KzbtbdqvigLQKrx9NZruSUbXbhJWvrw9Tvw6T08bTu1m1TtZJu7vbTTXVPcBYBUp8o05KLu1mta6vvUX0Xt96K14ntY2m4zlF3UI5nZb1rZq+9Ozs9zAsArVcbGNSFOzcpq61S+F2r+xX+RGuUo3ipQnHNNwTdmk1ffZ6K6t7WgLpiW5lTD8p06kMyzJWlKzW6KbV30K+V2uWr+butpuAiwXoaXuR+ROarCV5bKnr+CPyJtvPiBfBQ28+sNvPrAXwUNvPrDbz6wF8FDbz6w28+IF8FDbz6w28+sBfBQ28+sNvPrAXwUNvPrDbz6wF8FDbz6w28+sBfBQ28+sNvPrAXwUNvPrDbz6wF8FDbz6w28+sBfBQ28+sNvPrAXwUNvPrDbz6wF8FDbz6w28+sBfBQ28+sQ4jHyppedq3ZXdlwu30K7XxQG1BznKPKmIp0nKOao7bqcLNKTtGSk7pta6etbunY0sTUau3bhZ3uuh7gL9WmpxlGW6SafsehDUwUJNyd7tp6PpTTT+MUQ7efWG3nxAU+S6agoycpWUVdvoje1uG9vjrvJ5YODzZrvMmnd8Uov9F8yDbz4jbz4gSywEG05OUt17y32bcb+xtsU8BTjLMk73uteLv8yLbz4jbz4gKnJq8xQk4xilG2r81W03/w9N974u8v/T6dnGzyuOVq73Wyv9EvgRbeXEbeXECT/p8LtpyTu5JqT0bbbt+bfxM+QQtG2ZZVaLzO8dy0+H6viRbeXEbeXED1Lk2FlFOUYpNNJu7TSjq9+5GZ8m02mmnZ30vdJSd5JJ8XqeNvLiNvLiBJPk6nLR5rXbSvub32e/j8TMsDBynJ5m5pJ+c+jdbhbfp06kW3lxG3lxAmWCgrWcsyUvOzPN5zTbv7UvluMLAU0kkrNO+dPzr63eb85fFkW3lxG3lxA9x5MpJ/duuq3eP3cl7P+FJHryCnd77O7y3dk3vaXr/5fEi28uI28uIErwFO7dnq7tXdn5zlqva38TFPk+nFWSe5x39Dtf8ApRHt5cRt5cQMy5KpOOVp5bWtfS1mn7NJNabuixLLBQbT1TTbTT1Tbu/m/iQ7eXEbeXECWHJ9OKSSeiS3t7stv6I/Aio8mRWZTammlGKs/NirpJXbd/Oeo28uI28uIE0sFF2zSm0mnZydnZ3V/YxVwNOcXGUbxeZtXf4tWQ7eXEw8RLpkBK+T6eZSs9G2teltt/k7vTd8EWpbmUPKJdYSrys9QK2E9FT9yPyKGNr1aU601GbjlhKL0cbxu5Rs3dOWkdFvaNvhKa2NPT8EfkibZR4Ac7JY1ax3ys3uaTyrSz/CndO1np+ZLyjTrudRU4zcatOEYuMklCSlLM3dprSS1V/um92UeA2UeAHPYiviqacpytBy10gnGOaSSjfR6ZN/r6TxQr46cYvK45qcNWo/eag28u9b6is+B0mzXAbNcAKGwntYz2ssihlcLKzl1r8TVVsJXpqpKgpuW0m45qjksuyeTSTt6Sx0mzjwGyjwA5+r5bFtReda6tRTSzxs168jnv081fnjlOliJ0aTipuok3KMHlTlbTM1OLXtTduD0Oh2UeA2UeAGig8Y5yUrRW0SVlF2hm3q/wDDvv0/Ajj5YvNSslB2dlLWz33ad81um1v06HZR4DZR4AaLFVMX5NB04Pba3u4vcnlvolZu2628xKWMV3q05S0ioXjBVLRy33tw11+ZvtlHgNlHgBz8sPiXTwzi5RqQTlNSlpJ20jO17p7tL23kFCjilh50pRq7SVOnabmmlJRSkrqV73vu+J0+yjwGyjwA12Aw0qUHGc87zNrfonuSzNu3tZZLGyjwGyjwArgsbKPAbKPACuCxso8Bso8AK4LGyjwGyjwArgsbKPAbKPACuCxso8Bso8AK5q+VMXGnOCacs0lTdoZlFtxld9FrJ/obzZR4HieGhJptbr21dtVZ6dOgGn+5KL1k3JvZyknKO+yil72/oj7C/Qp5KcIb8sUr+xWLMMNCP3YpezTdov0PeyjwArgsbOPAbOPACuCxs48Bs48AK4LGzjwGzjwArgsbOPAbOPACuCxs48Bs48AK4LGzjwGzjwArgsbOPAbOPACuCxs48Bs48AK4LGzjwGzjwArgsbOPAbOPACuCxs48Bs48AK4LGzjwGzjwArlXFYeUpxlG2itr0ap33O+7dp0flstnHgNnHgBrMFh5U272tZLi27u7eite/r6fztS3Ms7OPAxKnGz0A84P0NP3I/JExDg/Q0/cj8kTAADAGQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADEtzMmJbmBFg/Q0/cj8kTHzKn9v8XGMYqnQtFJLzZdGnWPXOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSwfNOcLGdnh+7L6hzhYzs8P3ZfUB9LB805wsZ2eH7svqHOFjOzw/dl9QH0sHzTnCxnZ4fuy+oc4WM7PD92X1AfSzEtzPmvOFjOzw/dl9Qf/AIhYzs8P3ZfUByYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/2Q==\n"}}]}}, "b34de7650b61492aa066480f3639ade8": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a7f405ca85b141fa877aeb44f1d45840": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_59a3438980b8439a81f292466a5c37c8", "IPY_MODEL_cc103ba603ba491fa735c5b8b6e5dc39"], "layout": "IPY_MODEL_b34de7650b61492aa066480f3639ade8", "selected_index": 0}}, "06da4bde71ed4ef3b89b4989ff928691": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1f82d987f646463b959957b83f4f4926": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_06da4bde71ed4ef3b89b4989ff928691", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f99aec6bed0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "1ea337da04ba466ea096f568f7fed33f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3fac9880dc084e34ac9fe7c4755f0dfd": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_1ea337da04ba466ea096f568f7fed33f", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=Wnj9XZdtV7I\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99b02fffd0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/Wnj9XZdtV7I?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "5c290f8447be45b6b22cb3aa83ed9d6e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c624ac75e5b6475dbeb9be1b2a9b77ae": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_3fac9880dc084e34ac9fe7c4755f0dfd", "IPY_MODEL_1f82d987f646463b959957b83f4f4926"], "layout": "IPY_MODEL_5c290f8447be45b6b22cb3aa83ed9d6e", "selected_index": 0}}, "dcc2834e4d7543e7960ec875c10b168d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "be7cae66826048548f85ea53c9203733": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_dcc2834e4d7543e7960ec875c10b168d", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f99a4048bd0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "87a7af1dfbd147208a519a74e5beae2c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ba2d80606e794860a87c578938c8c967": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_87a7af1dfbd147208a519a74e5beae2c", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=6uJHra_esJU\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f99a01df450>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/6uJHra_esJU?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "36e244c5d24740b682badc13462e8bbd": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ddeea2c16d774be0b33164beadb8f70e": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_ba2d80606e794860a87c578938c8c967", "IPY_MODEL_be7cae66826048548f85ea53c9203733"], "layout": "IPY_MODEL_36e244c5d24740b682badc13462e8bbd", "selected_index": 0}}, "86f640b9abc249fb86391d2a77fbc3b7": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fd36eed98f344dd6ad863075789aa38f": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_86f640b9abc249fb86391d2a77fbc3b7", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f9aaa9cd750>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "23f4b66e5f81408a9577804af66dfd60": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e8b9c22976c74e63a211eb6254b6af5d": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_23f4b66e5f81408a9577804af66dfd60", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=J4zok8b2SUA\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f997604fe50>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/J4zok8b2SUA?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "7583bd944e9c43cf912ac2a31e6d1789": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9c06417c3bb44bb8bd53c50d45d6e50e": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_e8b9c22976c74e63a211eb6254b6af5d", "IPY_MODEL_fd36eed98f344dd6ad863075789aa38f"], "layout": "IPY_MODEL_7583bd944e9c43cf912ac2a31e6d1789", "selected_index": 0}}}, "version_major": 2, "version_minor": 0}
</script>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W2D5_TimeSeriesAndNaturalLanguageProcessing/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W2D5_Tutorial1.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 1: Introduction to processing time series</p>
</div>
</a>
<a class="right-next" href="W2D5_Tutorial3.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">(Bonus) Tutorial 3: Multilingual Embeddings</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br>
  
      © Copyright 2021.<br>
</br></br></p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>